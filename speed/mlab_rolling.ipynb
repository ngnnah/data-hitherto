{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bda95c29-43a9-423f-ac6e-cea070c1cc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nhat/anaconda3/envs/py39/lib/python3.9/site-packages/geopandas/_compat.py:111: UserWarning: The Shapely GEOS version (3.10.0-CAPI-1.16.0) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 249 µs (started: 2022-04-01 03:31:21 -04:00)\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from tobler.area_weighted import area_interpolate\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "ES_DEV = Elasticsearch(['YOUR ES HOST'], http_auth=('ES LOGIN', 'ES PASS'), timeout=30)\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96582ed8-ee59-4719-a62c-f581a844eb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.05 ms (started: 2022-04-01 03:31:24 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# 5 cols\n",
    "NTIA_INIT_COLS = [\n",
    "'numISPfiber', 'numISPother', 'numISPwireless',\n",
    "'MaxConsumerDown98', 'MaxConsumerUp98',\n",
    "]\n",
    "# 7 cols\n",
    "NTIA_END_COLS = [\n",
    "'numISPfiber', 'numISPother', 'numISPwireless',\n",
    "'MaxConsumerDown98', 'MaxConsumerUp98',\n",
    "'speedCatNtia', 'speedSourceNtia',\n",
    "]\n",
    "# 11 cols\n",
    "OOKLA_INIT_COLS = [\n",
    "'maxDownloadMbpsOokla', 'maxUploadMbpsOokla',\n",
    "'meanDownloadMbpsOokla', 'meanUploadMbpsOokla',\n",
    "'medDownloadMbpsOokla', 'medUploadMbpsOokla',\n",
    "'minDownloadMbpsOokla', 'minUploadMbpsOokla',\n",
    "'latencyOokla',\n",
    "'numDeviceOokla', 'numTestOokla',\n",
    "]\n",
    "# 13 cols\n",
    "OOKLA_END_COLS = [\n",
    "'maxDownloadMbpsOokla', 'maxUploadMbpsOokla',\n",
    "'meanDownloadMbpsOokla', 'meanUploadMbpsOokla',\n",
    "'medDownloadMbpsOokla', 'medUploadMbpsOokla',\n",
    "'minDownloadMbpsOokla', 'minUploadMbpsOokla',\n",
    "'latencyOokla',\n",
    "'numDeviceOokla', 'numTestOokla',\n",
    "'speedCatOokla', 'speedSourceOokla',\n",
    "]\n",
    "# 8 cols: max, min, device, test\n",
    "MLAB_INIT_COLS = [\n",
    "'maxDownloadMbpsMlab', 'maxUploadMbpsMlab',\n",
    "'minDownloadMbpsMlab', 'minUploadMbpsMlab',\n",
    "'numDeviceDownloadMlab', 'numDeviceUploadMlab',\n",
    "'numTestDownloadMlab', 'numTestUploadMlab',\n",
    "]\n",
    "# 14 cols\n",
    "MLAB_MID_COLS = [\n",
    "'maxDownloadMbpsMlab', 'maxUploadMbpsMlab',\n",
    "'minDownloadMbpsMlab', 'minUploadMbpsMlab',\n",
    "'numDeviceDownloadMlab', 'numDeviceUploadMlab',\n",
    "'numTestDownloadMlab', 'numTestUploadMlab',\n",
    "'meanDownloadMbpsMlab', 'meanUploadMbpsMlab',\n",
    "'medDownloadMbpsMlab', 'medUploadMbpsMlab',\n",
    "'latencyMlab', 'lossrateMlab',\n",
    "] \n",
    "# 16 cols\n",
    "MLAB_END_COLS = [\n",
    "'maxDownloadMbpsMlab', 'maxUploadMbpsMlab',\n",
    "'minDownloadMbpsMlab', 'minUploadMbpsMlab',\n",
    "'numDeviceDownloadMlab', 'numDeviceUploadMlab',\n",
    "'numTestDownloadMlab', 'numTestUploadMlab',\n",
    "'meanDownloadMbpsMlab', 'meanUploadMbpsMlab',\n",
    "'medDownloadMbpsMlab', 'medUploadMbpsMlab',\n",
    "'latencyMlab', 'lossrateMlab',\n",
    "'speedCatMlab','speedSourceMlab',\n",
    "]\n",
    "\n",
    "# 49 COLS\n",
    "MLAB_PREDICTION_COLS = [\n",
    "    'CMC', 'Education', 'Health', \n",
    "    'POP2019', 'Public Admin', 'age65overper', 'asianper', 'bachelorper', \n",
    "    'blackper', 'hh2020', 'hu2020', 'landareaSqmi', 'lengthMile', \n",
    "    'maxadownFiber', 'maxadownOther', 'maxadownWireless', 'maxadupFiber', 'maxadupOther', 'maxadupWireless',\n",
    "    'mhincome', 'nativeper', 'nocomputerper_ct', 'nointernetper', 'nointernetper_ct', \n",
    "    'numISPcomm', 'numISPresi', 'num_household', 'num_household_ct', 'num_housingunit', 'otherraceper', \n",
    "    'parcelNumAgri', 'parcelNumCommer', 'parcelNumInfra', 'parcelNumResi', \n",
    "    'parcelNumRem', 'parcelNumValid', 'parcelNumTotal',\n",
    "    'parcelBuildingCount', 'parcelBuildingFootprint',\n",
    "    \"cafiiLocation\", 'pop2020', 'povertybelow15', 'povertybelow15_ct', \n",
    "    'povertybelow20_ct', 'povertyper', 'povertyper_ct', \n",
    "    'rdofLocation', 'rdofReserve', 'whiteper'] \n",
    "\n",
    "\n",
    "SPEED_TEST_INDEX_BASE_COLS = ['GEOID', 'statefips']\n",
    "\n",
    "QUARTER_PREFIX_COLS = set(NTIA_END_COLS + OOKLA_END_COLS + MLAB_END_COLS + ['speedRankReadyRaw'])\n",
    "\n",
    "\n",
    "CBG_median_groups = [\n",
    "    'CMC', 'MaxConsumerDown98', 'MaxConsumerUp98', \n",
    "    'age65overper', 'asianper', 'bachelorper', 'blackper', \n",
    "    'cafiiLocation', \n",
    "    'latencyOokla', 'maxDownloadMbpsOokla', 'maxUploadMbpsOokla', \n",
    "    'maxadownFiber', 'maxadownOther', 'maxadownWireless', 'maxadupFiber', \n",
    "    'maxadupOther', 'maxadupWireless', 'meanDownloadMbpsOokla', 'meanUploadMbpsOokla', \n",
    "    'medDownloadMbpsOokla', 'medUploadMbpsOokla', 'mhincome', \n",
    "    'minDownloadMbpsOokla', 'minUploadMbpsOokla', 'nativeper', \n",
    "    'nocomputerper_ct', 'nointernetper', 'nointernetper_ct', \n",
    "    'otherraceper', 'povertybelow15', 'povertybelow15_ct', 'povertybelow20_ct', 'povertyper', 'povertyper_ct', \n",
    "    'rdofLocation', 'rdofReserve', 'whiteper']\n",
    "\n",
    "CBG_sum_groups = [\n",
    "    'Education', 'Health', 'POP2019', 'Public Admin', 'hh2020', 'hu2020', \n",
    "    'landareaSqmi', 'lengthMile', 'numDeviceOokla', \n",
    "    'numISPcomm', 'numISPfiber', 'numISPother', 'numISPresi', 'numISPwireless', \n",
    "    'numTestOokla', 'num_household', 'num_household_ct', 'num_housingunit', \n",
    "    'parcelBuildingCount', 'parcelBuildingFootprint', 'parcelNumAgri', \n",
    "    'parcelNumCommer', 'parcelNumInfra', 'parcelNumRem', 'parcelNumResi', \n",
    "    'parcelNumTotal', 'parcelNumValid', 'pop2020']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42abaf7e-78ff-492b-9a07-671a04fb4e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 898 µs (started: 2022-04-01 03:31:26 -04:00)\n"
     ]
    }
   ],
   "source": [
    "SF52 = { '01': 'AL', '02': 'AK', '04': 'AZ', '05': 'AR', \n",
    "                      '06': 'CA', '08': 'CO', '09': 'CT', '10': 'DE', \n",
    "                      '11': 'DC', '12': 'FL', '13': 'GA', '15': 'HI', \n",
    "                      '16': 'ID', '17': 'IL', '18': 'IN', '19': 'IA', \n",
    "                      '20': 'KS', '21': 'KY', '22': 'LA', '23': 'ME', \n",
    "                      '24': 'MD', '25': 'MA', '26': 'MI', '27': 'MN', \n",
    "                      '28': 'MS', '29': 'MO', '30': 'MT', '31': 'NE', \n",
    "                      '32': 'NV', '33': 'NH', '34': 'NJ', '35': 'NM', \n",
    "                      '36': 'NY', '37': 'NC', '38': 'ND', '39': 'OH', \n",
    "                      '40': 'OK', '41': 'OR', '42': 'PA', '44': 'RI', \n",
    "                      '45': 'SC', '46': 'SD', '47': 'TN', '48': 'TX', \n",
    "                      '49': 'UT', '50': 'VT', '51': 'VA', '53': 'WA', \n",
    "                      '54': 'WV', '55': 'WI', '56': 'WY', '72': 'PR'}\n",
    "\n",
    "SF52R = {v: k for (k,v) in SF52.items()}\n",
    "\n",
    "STATE_LENGTH, COUNTY_LENGTH, CT_LENGTH, CBG_LENGTH, CB_LENGTH = 2, 5, 11, 12, 15\n",
    "CRS_TIGER, CRS_OOKLA, CRS_COORDS = 4269, 4326, 3857\n",
    "# 3857: WGS 84 / Pseudo-Mercator -- Spherical Mercator, Google Maps, OpenStreetMap, Bing, ArcGIS, ESRI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9c8b5e-5116-4acd-8f1c-44f9a6c79eab",
   "metadata": {},
   "source": [
    "### OVERVIEW: for each quarter:\n",
    "- HAVE (training dataset): 12% CBG\n",
    "- NEED (prediction dataset): 88% CBG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be0db4e-28f6-433c-8601-3837fd09d03a",
   "metadata": {},
   "source": [
    "### Get raw Mlab data from BigQuery\n",
    "- query bigquery @ project: https://console.cloud.google.com/bigquery?project=measurement-lab\n",
    "    - INSIDE bigquery-sql folder: find speeds, and numDevice, numTest separately because numDevice/numTest SQL is more simple (less processing steps)\n",
    "    - Afterward, merge the Speed dataframe with the numDeviceNumTest dataframe.\n",
    "- NTIA bigquery: https://console.cloud.google.com/bigquery?project=measurement-lab&ws=!1m5!1m4!1m3!1smeasurement-lab!2sbquxjob_4b16ab25_17c9bd44f76!3sUS&j=bq:US:bquxjob_4b16ab25_17c9bd44f76&page=queryresults\n",
    "- using nhatn1507@gmail acc (which subscribed to MLAB mailing list) for free\n",
    "- save result to Google Drive, download to and read files from this VM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ee248f-1cc9-4e0d-838a-c586ae992fb8",
   "metadata": {},
   "source": [
    "### Time-series origin: 2021Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c31a2c1-5c1e-4f0a-be40-8f4fe2ed4119",
   "metadata": {},
   "source": [
    "### Impute CBG (need 100%) from CB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e4451576-4769-40f9-9be1-a8f5b638bd8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021Q4'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.62 ms (started: 2022-04-01 07:07:33 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: QUARTER must be a quarter at or after '2021Q1'\n",
    "# QUARTER = '2021Q1' # ....Change to 2021Q3, or 2021Q4, etc. on following runs\n",
    "QUARTER = '2021Q4'\n",
    "QUARTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "40757920-fbae-4e22-9915-b6a4ba53baea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2021Q4', (220334, 65), 0)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 40s (started: 2022-04-01 07:07:44 -04:00)\n"
     ]
    }
   ],
   "source": [
    "all_cbg = []\n",
    "for sf in SF52:\n",
    "    index_name = f'bossdata{sf}'\n",
    "    abbrv = SF52[sf]\n",
    "    \n",
    "    # PART A - CENSUS BLOCK LEVEL\n",
    "    # 100% filled\n",
    "    CB_ookla_ntia = pd.read_csv(f\"ookla_ntia/{QUARTER}_CB_{sf}.csv\")\n",
    "    # fill 100%\n",
    "    CB_mlab_pred_df = pd.read_csv(f'Elasticsearch/mlab_prediction_{index_name}.csv')\n",
    "    CB_mlab_pred_df['cafiiLocation'].fillna(0, inplace=True)\n",
    "    for col in set(CB_mlab_pred_df):\n",
    "        CB_mlab_pred_df[col].fillna(CB_mlab_pred_df[col].median(), inplace = True)\n",
    "    # NOTE: both CB_ookla_ntia and CB_mlab_pred_df have GEOID col with int64 type     \n",
    "    CB_df = CB_ookla_ntia.merge(CB_mlab_pred_df, on='GEOID', how='inner')\n",
    "    # print(CB_ookla_ntia.shape, CB_mlab_pred_df.shape, CB_df.shape, CB_df.isnull().sum().sum())\n",
    "    \n",
    "    if CB_df.isnull().sum().sum() > 0:\n",
    "        print(\"ALERT 1: contain nulls\")\n",
    "    if len(CB_df.select_dtypes('number')) != len(CB_df):\n",
    "        print(\"ALERT 2: not all columns are numeric type\")\n",
    "        \n",
    "    CB_df.GEOID = CB_df.GEOID.astype(str).str.zfill(CB_LENGTH)\n",
    "    CB_df['GEOID_cbg'] = CB_df.GEOID.str[:CBG_LENGTH] \n",
    "    CBG_count_before = len(CB_df.GEOID_cbg.unique())\n",
    "    \n",
    "    # PART B - CENSUS BLOCK GROUP LEVEL\n",
    "    CBG_df_medians = CB_df[CBG_median_groups + ['GEOID_cbg']].groupby('GEOID_cbg').median()\n",
    "    CBG_df_sums = CB_df[CBG_sum_groups + ['GEOID_cbg']].groupby('GEOID_cbg').sum()\n",
    "    \n",
    "    if ((not (len(CBG_df_medians) == len(CBG_df_sums) == len(set(CB_df.GEOID_cbg)))) or\n",
    "        (len(set(CBG_df_medians.index) - set(CBG_df_sums.index)) + len(set(CBG_df_sums.index) - set(CBG_df_medians.index)) != 0)\n",
    "       ):\n",
    "        print(\"ALERT 3: diff groupby GEOID_cbg\")   \n",
    "\n",
    "    CBG_df = CBG_df_medians.join(CBG_df_sums, how='left')\n",
    "    del CB_df, CB_ookla_ntia, CB_mlab_pred_df, CBG_df_medians, CBG_df_sums\n",
    "    \n",
    "    # UPDATE CBG_df with data from ookla CBG\n",
    "    ookla_cbg = pd.read_csv(f\"ookla_state_tiles/{QUARTER}_CBG_{sf}.csv\")\n",
    "    ookla_cbg.GEOID_cbg = ookla_cbg.GEOID_cbg.astype(str).str.zfill(CBG_LENGTH)\n",
    "    ookla_cbg.set_index('GEOID_cbg', inplace=True)\n",
    "    \n",
    "    # speedSourceOokla is not numeric\n",
    "    if set(ookla_cbg) - set(CBG_df) != {'speedSourceOokla'}:\n",
    "        print(\"ALERT 4: ookla_cbg should not contain more cols than CBG_df!\")   \n",
    "    \n",
    "    # UPDATE with ookla actual CBG speeds\n",
    "    CBG_df.update(ookla_cbg)\n",
    "    if CBG_df.isnull().sum().sum() != 0:\n",
    "        print(f\"ALERT 5: {CBG_df.isnull().sum().sum()=}\", )\n",
    "        \n",
    "    CBG_count_after = len(CBG_df)\n",
    "    if CBG_count_before != CBG_count_after:\n",
    "        print(\"ALERT 6: CBG before and after should be the same: \", CBG_count_before, CBG_count_after)\n",
    "    \n",
    "    all_cbg.append(CBG_df)\n",
    "    \n",
    "all_cbg = pd.concat(all_cbg, ignore_index=False)\n",
    "# # NUMBER OF CBG in bossdata* = 220,334 !\n",
    "QUARTER, all_cbg.shape, all_cbg.isnull().sum().sum()  # ALWAYS = ((220334, 65), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5148e2a7-5e3d-4620-ae70-814ca79dd1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### RUN ONCE: CBG Tiger geom: add lat and lon and geometry columns to all_cbg\n",
    "TIGER_CBG_52 = []\n",
    "for sf in SF52:\n",
    "    # TIGER data has CRS = <Geographic 2D CRS: EPSG:4269> : \n",
    "    census_year = 2019\n",
    "    tiger_cbg = gp.read_file(f\"https://www2.census.gov/geo/tiger/TIGER{census_year}/BG/tl_{census_year}_{sf}_bg.zip\"\n",
    "                            )[['GEOID', 'geometry']].to_crs(CRS_COORDS)\n",
    "    # centroid could be inaccurate, but the GPS coords are only used as proxy in the RF model\n",
    "    tiger_cbg['lat'] = tiger_cbg['geometry'].centroid.x\n",
    "    tiger_cbg['lon'] = tiger_cbg['geometry'].centroid.y\n",
    "    tiger_cbg['GEOID_cbg'] = tiger_cbg['GEOID'].astype(str).str.zfill(CBG_LENGTH)\n",
    "    # tiger_cbg = pd.DataFrame(tiger_cbg.drop(columns=['geometry', 'GEOID']))\n",
    "    TIGER_CBG_52.append(tiger_cbg[['GEOID_cbg', 'lat', 'lon', 'geometry']])\n",
    "\n",
    "TIGER_CBG_52 = pd.concat(TIGER_CBG_52, ignore_index=True)\n",
    "%store TIGER_CBG_52\n",
    "print('NUMBER OF CBG from TIGER CENSUS2019: ', TIGER_CBG_52.shape) # (220333, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9121bd22-ff73-40c0-876a-4363edca35ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALERT: all_cbg has nulls geometry    73\n",
      "dtype: int64\n",
      "time: 466 ms (started: 2022-04-01 07:09:25 -04:00)\n"
     ]
    }
   ],
   "source": [
    "all_cbg = TIGER_CBG_52.merge(all_cbg, on='GEOID_cbg', how='right')\n",
    "\n",
    "# Median fills for lat, lon\n",
    "for col in sorted(set(all_cbg)):\n",
    "    if col != 'geometry' and all_cbg[col].isnull().sum():\n",
    "        all_cbg[col].fillna(all_cbg[col].median(), inplace=True)\n",
    "        \n",
    "s = all_cbg.isnull().sum()\n",
    "if s.sum(): \n",
    "    # 73 CBG have no geometry, but it's ok \n",
    "    print(\"ALERT: all_cbg has nulls\", s[s>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1d7dbf5f-c938-4ad4-8330-1fbd6308140a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220333, 220334)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 211 ms (started: 2022-04-01 05:54:15 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# NOTE: bossdata* has 220,334 CBG, while 2019TIGER has 220333 CBG\n",
    "# TODO later: need a resolution for CBG <> CB , bossdata <> TIGER2019\n",
    "len(set(TIGER_CBG_52.GEOID_cbg) - set(all_cbg.index)), len(set(all_cbg.index) - set(TIGER_CBG_52.GEOID_cbg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f6d5e8b-e0fe-49aa-ac8e-b5506af4dbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.3 ms (started: 2022-04-01 03:40:25 -04:00)\n"
     ]
    }
   ],
   "source": [
    "## Combine speed + device dataframes: FloorCap, and remove invalid latency and lossrate\n",
    "def merge_mlab_dfs(speed_df, device_df, idCol):\n",
    "    new_mlab_mappings = {\n",
    "        'download_MIN'   :  'minDownloadMbpsMlab',\n",
    "        'download_MED'   :  'medDownloadMbpsMlab',\n",
    "        'download_AVG'   :  'meanDownloadMbpsMlab',\n",
    "        'download_MAX'   :  'maxDownloadMbpsMlab',\n",
    "        'upload_MIN'     :  'minUploadMbpsMlab',\n",
    "        'upload_MED'     :  'medUploadMbpsMlab',\n",
    "        'upload_AVG'     :  'meanUploadMbpsMlab',\n",
    "        'upload_MAX'     :  'maxUploadMbpsMlab',\n",
    "        'num_test_down'  :  'numTestDownloadMlab',\n",
    "        'num_device_down':  'numDeviceDownloadMlab',\n",
    "        'num_test_up'    :  'numTestUploadMlab',\n",
    "        'num_device_up'  :  'numDeviceUploadMlab',\n",
    "        'latency'        :  'latencyMlab',\n",
    "        'lossrate'       :  'lossrateMlab', \n",
    "    }    \n",
    "    merged_df = pd.merge(speed_df, device_df, how='left', on=idCol).rename(columns = new_mlab_mappings)\n",
    "    # Change of unit to percentage\n",
    "    merged_df['lossrateMlab'] = merged_df['lossrateMlab'] * 100 \n",
    "    # Fill missing values, mostly numTest/device\n",
    "    for col in new_mlab_mappings.values():\n",
    "        merged_df[col].fillna(merged_df[col].median(), inplace=True)\n",
    "        \n",
    "    # CLEAN DATA: remove rows with invalid latency or lossrate\n",
    "    \n",
    "    # 0.5 ms < latency <= 300ms\n",
    "    merged_df = merged_df[(merged_df.latencyMlab > 0.5) & (merged_df.latencyMlab <= 300)]\n",
    "    # All test instances where a unit’s packet loss exceeded 10% were removed\n",
    "    merged_df = merged_df[(merged_df.lossrateMlab <= 10)]\n",
    "    \n",
    "    # Quantile-based Flooring and Capping\n",
    "    for col in new_mlab_mappings.values():\n",
    "        floor_rate = 0.01\n",
    "        # set higher floor_rate for these values (due to non-uniform distributions of tests and latency)\n",
    "        if col in ['numTestDownloadMlab', 'numDeviceDownloadMlab', 'numTestUploadMlab',\n",
    "                   'numDeviceUploadMlab', 'latencyMlab',]: \n",
    "            floor_rate = 0.05\n",
    "        cap_rate = 1 - floor_rate\n",
    "        floor_value = merged_df[col].quantile(floor_rate) \n",
    "        cap_value = merged_df[col].quantile(cap_rate)\n",
    "        \n",
    "        # # Show the number of rows floored/capped\n",
    "        # print(merged_df.shape, merged_df[merged_df[col] < floor_value].shape, merged_df[merged_df[col] > cap_value].shape)\n",
    "        # Skewness value explains the extent to which the data is normally distributed. \n",
    "        # print(\"*** COL = \", col, \", initial skew: \", merged_df[col].skew())\n",
    "        merged_df[col] = np.where(\n",
    "            merged_df[col] < floor_value, floor_value, merged_df[col])\n",
    "        merged_df[col] = np.where(\n",
    "            merged_df[col] > cap_value, cap_value, merged_df[col])\n",
    "        # print(\"Improved skew: \", merged_df[col].skew())\n",
    "    \n",
    "    s = merged_df.isnull().sum()\n",
    "    if s.sum(): print(s[s>0])\n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5c9ba6be-52ff-496e-9d73-9f77e4234217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.78 s (started: 2022-04-01 07:09:25 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# COUNTY\n",
    "county_speed = pd.read_csv(f'mlab_speeds/{QUARTER}-county-speed.csv')\n",
    "county_speed = county_speed.rename(columns = {'GEOID' : 'GEOID_c'})\n",
    "county_speed['GEOID_c'] = county_speed['GEOID_c'].astype(str).str.zfill(COUNTY_LENGTH)\n",
    "county_device = pd.read_csv(f'mlab_speeds/{QUARTER}-county-device.csv')\n",
    "county_device = county_device.rename(columns = {'GEOID' : 'GEOID_c'})\n",
    "county_device['GEOID_c'] = county_device['GEOID_c'].astype(str).str.zfill(COUNTY_LENGTH)\n",
    "mlab_county = merge_mlab_dfs(county_speed, county_device, 'GEOID_c') # MERGE \n",
    "# add TIGER geom to mlab_county\n",
    "tiger_county = gp.read_file('https://www2.census.gov/geo/tiger/TIGER2019/COUNTY/tl_2019_us_county.zip')[['GEOID', 'geometry']].to_crs(CRS_COORDS)\n",
    "tiger_county['GEOID_c'] = tiger_county['GEOID'].astype(str).str.zfill(COUNTY_LENGTH)\n",
    "tiger_county = tiger_county[['GEOID_c', 'geometry']]\n",
    "mlab_county = tiger_county.merge(mlab_county, on='GEOID_c', how='left')\n",
    "\n",
    "del tiger_county, county_speed, county_device\n",
    "\n",
    "# There are a few TIGER counties without Mlab speeds: impute\n",
    "for col in set(mlab_county) - set(['geometry', 'GEOID_c']):\n",
    "    mlab_county[col].fillna(mlab_county[col].median(), inplace=True)\n",
    "\n",
    "s = mlab_county.isnull().sum()\n",
    "if s.sum(): \n",
    "    print(s[s>0]) \n",
    "if set(all_cbg).intersection(set(mlab_county)) != {'geometry'}:\n",
    "    print(\"ALERT: all_cbg should not have any mlab speed cols\")\n",
    "if mlab_county.crs != all_cbg.crs:\n",
    "    print(\"ALERT: Check crs values\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "af003666-2128-45bd-a595-8511de7a51ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2min 26s (started: 2022-04-01 07:09:35 -04:00)\n"
     ]
    }
   ],
   "source": [
    "### Area-interpolate COUNTY >> CBG (mlab #test #devices)\n",
    "device_cols = ['numTestDownloadMlab', 'numDeviceDownloadMlab', \n",
    "                               'numTestUploadMlab', 'numDeviceUploadMlab', ]\n",
    "# 2.5min: AREA INTERPOLATION #device and #test\n",
    "county_to_cbg_area_interpolation = area_interpolate(\n",
    "    source_df = mlab_county,  \n",
    "    target_df = all_cbg,  \n",
    "    extensive_variables = device_cols,\n",
    "    # categorical_variables = [],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f23879ed-39b5-4ab6-a0ab-bad080bddc5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220334, 77)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 487 ms (started: 2022-04-01 07:12:02 -04:00)\n"
     ]
    }
   ],
   "source": [
    "all_cbg_NEW = pd.concat([all_cbg,\n",
    "          county_to_cbg_area_interpolation[device_cols].round(0).astype(int)],\n",
    "          axis = 1)\n",
    "\n",
    "# Copy Mlab max/min speeds\n",
    "minmax_cols = [ 'maxDownloadMbpsMlab', 'maxUploadMbpsMlab', \n",
    "               'minDownloadMbpsMlab', 'minUploadMbpsMlab',]\n",
    "\n",
    "all_cbg_NEW['GEOID_c'] = all_cbg_NEW.GEOID_cbg.str[:COUNTY_LENGTH]\n",
    "all_cbg_NEW = all_cbg_NEW.merge(mlab_county[minmax_cols + ['GEOID_c']], \n",
    "                                      how='left', on='GEOID_c').drop(columns='geometry')\n",
    "\n",
    "# TURN GEOID cols to INTEGER type in order for RF model to work\n",
    "all_cbg_NEW[['GEOID_cbg', 'GEOID_c']] = all_cbg_NEW[['GEOID_cbg', 'GEOID_c']].astype(int)\n",
    "\n",
    "for col in minmax_cols:\n",
    "    all_cbg_NEW[col].fillna(all_cbg_NEW[col].median(), inplace=True)\n",
    "\n",
    "s = all_cbg_NEW.isnull().sum()\n",
    "if s.sum(): print(f\"ALERT: {s[s>0]}\")\n",
    "# always = (220334, 77) QoQ\n",
    "all_cbg_NEW.shape # same number of CBG, same number of columns: (220334, 77)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8620e108-cc41-4f93-9b62-c706c4a83d2e",
   "metadata": {},
   "source": [
    "### Mlab CBG = Mlab training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "53d2c3b6-e84c-4854-a459-8603cb8dc6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 151 ms (started: 2022-04-01 07:12:02 -04:00)\n"
     ]
    }
   ],
   "source": [
    "cbg_speed = pd.read_csv(f'mlab_speeds/{QUARTER}-cbg-speed.csv')\n",
    "cbg_speed = cbg_speed.rename(columns = {'GEOID' : 'GEOID_cbg'})\n",
    "cbg_speed['GEOID_cbg'] = cbg_speed['GEOID_cbg'].astype(str).str.zfill(CBG_LENGTH)\n",
    "cbg_device = pd.read_csv(f'mlab_speeds/{QUARTER}-cbg-device.csv')\n",
    "cbg_device = cbg_device.rename(columns = {'GEOID' : 'GEOID_cbg'})\n",
    "cbg_device['GEOID_cbg'] = cbg_device['GEOID_cbg'].astype(str).str.zfill(CBG_LENGTH)\n",
    "# MERGE \n",
    "mlab_cbg_combined = merge_mlab_dfs(cbg_speed, cbg_device, 'GEOID_cbg')\n",
    "\n",
    "del cbg_speed, cbg_device\n",
    "\n",
    "mlab_cbg_combined_ids = set(mlab_cbg_combined.GEOID_cbg)\n",
    "# RF model only works with Numeric type\n",
    "mlab_cbg_combined['GEOID_cbg'] = mlab_cbg_combined['GEOID_cbg'].astype(int)\n",
    "\n",
    "s = mlab_cbg_combined.isnull().sum()\n",
    "if s.sum():\n",
    "    print(f\"ALERT mlab_cbg_combined has nulls {s[s>0]}\")\n",
    "if set(mlab_cbg_combined) - set(mlab_cbg_combined.select_dtypes('number')):\n",
    "    print(f\"ALERT mlab_cbg_combined should contain only numberic cols\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "dba115a9-0e69-4b93-bfe1-4812bdfaa99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIZE OF training v.s. prediction set  (26742, 83) (220334, 77)\n",
      "time: 137 ms (started: 2022-04-01 07:12:02 -04:00)\n"
     ]
    }
   ],
   "source": [
    "mlab_free_df = all_cbg_NEW.drop(MLAB_END_COLS, axis=1, errors='ignore')\n",
    "if set(mlab_free_df.select_dtypes('object')):\n",
    "    print(\"ALERT: mlab_free_df has non-numeric cols\", set(mlab_free_df.select_dtypes('object')))\n",
    "    \n",
    "## INNER JOIN: even if there are cbg with mlab data, remove them if no ES/demographic/ookla data available\n",
    "cbg_training_df = mlab_cbg_combined.merge(mlab_free_df, how='inner', on='GEOID_cbg') \n",
    "del mlab_free_df\n",
    "\n",
    "s = cbg_training_df.isnull().sum()\n",
    "if s.sum():\n",
    "    print(f\"ALERT cbg_training_df has nulls {s[s>0]}\")\n",
    "\n",
    "# 2021Q1: (26596, 83) (220334, 77) ; 2021Q2: (26973, 83) (220334, 77)\n",
    "# 2021Q3: (26578, 83) (220334, 77) ; 2021Q4: (26742, 83) (220334, 77)\n",
    "print(\"SIZE OF training v.s. prediction set \", cbg_training_df.shape, all_cbg_NEW.shape)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3269b842-1e30-4966-8e42-96969773ed2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False None\n",
      "False None\n",
      "time: 12.5 ms (started: 2022-04-01 07:12:03 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# MORE CHECKS\n",
    "need_to_predict_cols = {'meanDownloadMbpsMlab','meanUploadMbpsMlab',\n",
    "                     'medDownloadMbpsMlab','medUploadMbpsMlab', \n",
    "                        'latencyMlab', 'lossrateMlab'}\n",
    "if set(cbg_training_df) - set(all_cbg_NEW) != need_to_predict_cols:\n",
    "    print(\"ALERT: cbg_training_df is missing cols\")\n",
    "if cbg_training_df.shape[1] != cbg_training_df.select_dtypes('number').shape[1]:\n",
    "    print(\"ALERT: cbg_training_df has non-numeric cols\")   \n",
    "    \n",
    "# CONFIRM there are no views lurking: we don't want to accidentally update all_cbg_NEW (PREDICTION) with cbg_training_df (TRAINING) later. \n",
    "print(cbg_training_df._is_view, cbg_training_df._is_copy) # (False, None)\n",
    "print(all_cbg_NEW._is_view, all_cbg_NEW._is_copy) # (False, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "33bc409c-58fe-4331-8436-9175b737353a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.11 ms (started: 2022-04-01 07:12:03 -04:00)\n"
     ]
    }
   ],
   "source": [
    "CBG_TRAINING_COLS = ['CMC', 'Education', 'GEOID_c', 'GEOID_cbg', 'Health', 'MaxConsumerDown98', 'MaxConsumerUp98', 'POP2019', 'Public Admin', 'age65overper', 'asianper', 'bachelorper', 'blackper', 'cafiiLocation', 'hh2020', 'hu2020', 'landareaSqmi', 'lat', 'latencyMlab', 'latencyOokla', 'lengthMile', 'lon', 'lossrateMlab', 'maxDownloadMbpsMlab', 'maxDownloadMbpsOokla', 'maxUploadMbpsMlab', 'maxUploadMbpsOokla', 'maxadownFiber', 'maxadownOther', 'maxadownWireless', 'maxadupFiber', 'maxadupOther', 'maxadupWireless', 'meanDownloadMbpsMlab', 'meanDownloadMbpsOokla', 'meanUploadMbpsMlab', 'meanUploadMbpsOokla', 'medDownloadMbpsMlab', 'medDownloadMbpsOokla', 'medUploadMbpsMlab', 'medUploadMbpsOokla', 'mhincome', 'minDownloadMbpsMlab', 'minDownloadMbpsOokla', 'minUploadMbpsMlab', 'minUploadMbpsOokla', 'nativeper', 'nocomputerper_ct', 'nointernetper', 'nointernetper_ct', 'numDeviceDownloadMlab', 'numDeviceOokla', 'numDeviceUploadMlab', 'numISPcomm', 'numISPfiber', 'numISPother', 'numISPresi', 'numISPwireless', 'numTestDownloadMlab', 'numTestOokla', 'numTestUploadMlab', 'num_household', 'num_household_ct', 'num_housingunit', 'otherraceper', 'parcelBuildingCount', 'parcelBuildingFootprint', 'parcelNumAgri', 'parcelNumCommer', 'parcelNumInfra', 'parcelNumRem', 'parcelNumResi', 'parcelNumTotal', 'parcelNumValid', 'pop2020', 'povertybelow15', 'povertybelow15_ct', 'povertybelow20_ct', 'povertyper', 'povertyper_ct', 'rdofLocation', 'rdofReserve', 'whiteper']\n",
    "len(CBG_TRAINING_COLS) # 83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "38c7f434-8b36-4669-92e6-3077453b940a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 996 ms (started: 2022-04-01 07:12:03 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# Save current quarter training_df\n",
    "if set(cbg_training_df) != set(CBG_TRAINING_COLS):\n",
    "    print(\"ALERT: CHECK cols of cbg_training_df\")\n",
    "    \n",
    "cbg_training_df.to_csv(f'mlab_speeds/{QUARTER}-TRAINING-CBG.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2235d074-eb28-4a50-ba41-518eb36d9521",
   "metadata": {},
   "source": [
    "## ROLLING QUARTER: addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "956b395d-f124-4fc8-b5fc-33862c20b8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021Q4 ['2021Q1', '2021Q2', '2021Q3']\n",
      "time: 903 µs (started: 2022-04-01 07:12:04 -04:00)\n"
     ]
    }
   ],
   "source": [
    "year, qrtr = QUARTER.split('Q')\n",
    "year, qrtr = int(year), int(qrtr)\n",
    "\n",
    "all_prev_quarters = []\n",
    "if year >= 2021 and qrtr in [1,2,3,4]:\n",
    "    # all four quarters of past years\n",
    "    for y in range(2021, year):\n",
    "        for q in range(1, 5):\n",
    "            all_prev_quarters.append(str(y)+'Q'+str(q))\n",
    "    # quarters of current year  \n",
    "    for q in range(1, qrtr):\n",
    "        all_prev_quarters.append(str(year)+'Q'+str(q)) \n",
    "        \n",
    "print(QUARTER, all_prev_quarters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2fc2d74f-d9e0-4710-a656-a2d50a2e46e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 612 ms (started: 2022-04-01 07:12:04 -04:00)\n"
     ]
    }
   ],
   "source": [
    "additional_cbg_training = []\n",
    "for PREV_QUARTER in all_prev_quarters:\n",
    "    df = pd.read_csv(f'mlab_speeds/{PREV_QUARTER}-TRAINING-CBG.csv')\n",
    "    if set(df) != set(CBG_TRAINING_COLS):\n",
    "        print(f\"ALERT: check cols of {PREV_QUARTER} training df\")\n",
    "    additional_cbg_training.append(df)\n",
    "\n",
    "if len(additional_cbg_training):    \n",
    "    additional_cbg_training = pd.concat(additional_cbg_training, ignore_index=False)\n",
    "    if cbg_training_df.GEOID_cbg.dtype != additional_cbg_training.GEOID_cbg.dtype:\n",
    "        print(\"ALERT: GEOID_cbg dtype mismatched\")    \n",
    "    cbg_training_df_combined = pd.concat([cbg_training_df, additional_cbg_training], ignore_index=True)\n",
    "else:\n",
    "    cbg_training_df_combined = cbg_training_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b3cc9fa6-9773-445a-ae45-8b405e44b9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26742, 83), (80147, 83), (106889, 83))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.49 ms (started: 2022-04-01 07:12:04 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# 2021Q3: ((26578, 83), (53569, 83), (80147, 83))\n",
    "# 2021Q4: ((26742, 83), (80147, 83), (106889, 83))\n",
    "cbg_training_df.shape, additional_cbg_training.shape, cbg_training_df_combined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3f41cb-bf66-450e-80e9-3c052a08d7a2",
   "metadata": {},
   "source": [
    "### PREDICTIONS with RANDOM FOREST models\n",
    "- NOTE: For meanSpeed and medSpeed: The Random Forest MLAB models's predictions are CONSERVATIVE (i.e. most PREDICTED VALUES concentrate (have low skew) and are OPTIMISTIC (have higher mean and medians)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "04c9ccb4-8989-49d6-bab6-5396354aa832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.31 ms (started: 2022-04-01 04:40:21 -04:00)\n"
     ]
    }
   ],
   "source": [
    "def evaluate_reg_model(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    # print('Model Performance', model)\n",
    "    print('Average Error: {:0.4f} Mbps.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    # print('Mean Absolute Error MAE:', metrics.mean_absolute_error(test_labels, predictions))  \n",
    "    model_test_pred = pd.DataFrame({'Observed': test_labels.flatten(), 'Predicted': predictions.flatten()})\n",
    "    # print(model_test_pred.sample(frac=0.1, random_state=1).head(6))\n",
    "    return accuracy\n",
    "\n",
    "def show_feature_importances(model, predictors):\n",
    "    # Get numerical feature importances\n",
    "    importances = list(model.feature_importances_)\n",
    "    # List of tuples with variable and importance\n",
    "    feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(predictors, importances) if importance > 0.1]\n",
    "    feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "    # The feature and importances \n",
    "    for pair in feature_importances:\n",
    "        print('Variable: {} Importance: {}'.format(*pair))\n",
    "        \n",
    "def build_rf_model(training_df, exclude_attributes, response):\n",
    "    scaler =  StandardScaler()\n",
    "    predictors = sorted(list(set(training_df) - set(exclude_attributes)))\n",
    "\n",
    "    X = training_df[predictors].values\n",
    "    y = training_df[response].values \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "    # Build the model: SLOW\n",
    "    rf_model = RandomForestRegressor(n_estimators=200, random_state = 0) \n",
    "    \n",
    "    # Normalization after train_test_split\n",
    "    X_train_norm = scaler.fit_transform(X_train)\n",
    "    rf_model.fit(X_train_norm, y_train)\n",
    "\n",
    "    X_test_norm = scaler.transform(X_test) \n",
    "    # evaluation PREDICTIONS on test data\n",
    "    evaluate_reg_model(rf_model, X_test_norm, y_test)\n",
    "    # Feature importances\n",
    "    show_feature_importances(rf_model, predictors)\n",
    "\n",
    "    return rf_model, scaler, predictors\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b3ad67-cda8-4346-a452-545f0022a8cc",
   "metadata": {},
   "source": [
    "### Build models: latency, lossrate, meanUp, meanDown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c4b446-17fa-4190-a4d8-946469483b59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building RF model for  latencyMlab\n"
     ]
    }
   ],
   "source": [
    "# 50 min to complete building 6 models\n",
    "all_model_results = []\n",
    "\n",
    "for cur_response in ['latencyMlab', 'lossrateMlab', \n",
    "        'meanUploadMbpsMlab', 'meanDownloadMbpsMlab', \n",
    "         'medDownloadMbpsMlab', 'medUploadMbpsMlab',]:\n",
    "    \n",
    "    exclude_attributes = {\n",
    "        'meanDownloadMbpsMlab', 'meanUploadMbpsMlab',\n",
    "        'medDownloadMbpsMlab', 'medUploadMbpsMlab', 'latencyMlab', 'lossrateMlab', } \n",
    "    if cur_response in ['medDownloadMbpsMlab', 'medUploadMbpsMlab',]:\n",
    "        # use Mlab [newly predicted] mean speeds as predictors\n",
    "        exclude_attributes = {\n",
    "        'medDownloadMbpsMlab', 'medUploadMbpsMlab',  'latencyMlab', 'lossrateMlab',} \n",
    "    print(\"Building RF model for \", cur_response)  \n",
    "    # BEFORE in mlab_init: train on cbg_training_df\n",
    "    # cur_model, cur_scaler, cur_predictor = build_rf_model(cbg_training_df, exclude_attributes, predictor_col)\n",
    "    # NOW in mlab_rolling: train on cbg_training_df_combined\n",
    "    cur_model, cur_scaler, cur_predictor = build_rf_model(cbg_training_df_combined, exclude_attributes, cur_response)\n",
    "    all_model_results.append([cur_response, cur_model, cur_scaler, cur_predictor])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1b7156-52e7-4f0b-a139-22f38de89d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2021Q1 (init), vs 2021Q2, Q3, Q4 RESULTS = \n",
    "# 'latencyMlab',  accuracy=65%, 68%, 69%, \n",
    "#  'lossrateMlab', Average Error: 1.1758 Mbps, 1.09 Mbps, 1.07 Mbps, \n",
    "# 'meanUploadMbpsMlab', accuracy=60%, 61%, 61%, \n",
    "#  'meanDownloadMbpsMlab', accuracy=70%, 72%, 73%\n",
    "# 'medDownloadMbpsMlab', accuracy=90%, 88%, 89%\n",
    "#  'medUploadMbpsMlab', accuracy=80%, 80%, 80%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "82e36c5b-ac9a-451e-8048-ef5bdf68bafd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latencyMlab 77 77 79\n",
      "lossrateMlab 77 77 79\n",
      "meanUploadMbpsMlab 77 77 79\n",
      "meanDownloadMbpsMlab 77 77 79\n",
      "medDownloadMbpsMlab 79 79 79\n",
      "medUploadMbpsMlab 79 79 79\n",
      "time: 1.01 ms (started: 2022-04-01 05:15:57 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# Number of features seen during fit.\n",
    "for (cur_response, cur_model, cur_scaler, cur_predictors) in all_model_results:\n",
    "    print(cur_response, cur_model.n_features_in_, cur_scaler.n_features_in_, len(cur_predictor))\n",
    "# latencyMlab 77 77 79\n",
    "# lossrateMlab 77 77 79\n",
    "# meanUploadMbpsMlab 77 77 79\n",
    "# meanDownloadMbpsMlab 77 77 79\n",
    "# medDownloadMbpsMlab 79 79 79\n",
    "# medUploadMbpsMlab 79 79 79    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fbe416-7dab-4e20-a8b1-74a804d8f477",
   "metadata": {},
   "source": [
    "## Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c296c2-e2d2-4abf-b4f8-242372e03708",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cbg_NEW1 = all_cbg_NEW.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b71c7d50-bcc4-42a8-aea9-103becc71933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 44.8 ms (started: 2022-04-01 05:25:56 -04:00)\n"
     ]
    }
   ],
   "source": [
    "all_cbg_NEW = all_cbg_NEW1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabbd2e8-eb89-4fb7-8274-b598e0ea6780",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cur_response, cur_model, cur_scaler, cur_predictors in all_model_results:\n",
    "    X_pred = all_cbg_NEW[cur_predictors].values\n",
    "    X_pred_norm = cur_scaler.transform(X_pred)\n",
    "    all_cbg_NEW[cur_response] = cur_model.predict(X_pred_norm).round(2)\n",
    "\n",
    "    print(cur_response, \"COMPARISON training vs prediction (mean, 50%)\")\n",
    "    print(cbg_training_df[cur_response].describe()[['mean', '50%']].values, 'v.s.', \n",
    "          all_cbg_NEW[cur_response].describe()[['mean', '50%']].values)\n",
    "\n",
    "# 2021Q1 references: \n",
    "# latencyMlab COMPARISON training vs prediction (mean, 50%)\n",
    "# [27.53841466 24.81      ] v.s. [27.32264022 26.47      ]\n",
    "# lossrateMlab COMPARISON training vs prediction (mean, 50%)\n",
    "# [2.23052333 1.66      ] v.s. [3.21274674 3.38      ]\n",
    "# meanUploadMbpsMlab COMPARISON training vs prediction (mean, 50%)\n",
    "# [29.16358677 17.66      ] v.s. [100.70669588 103.79      ]\n",
    "# meanDownloadMbpsMlab COMPARISON training vs prediction (mean, 50%)\n",
    "# [83.77329782 79.24      ] v.s. [144.66818875 153.47      ]\n",
    "# medDownloadMbpsMlab COMPARISON training vs prediction (mean, 50%)\n",
    "# [58.05855318 54.03      ] v.s. [117.51646006 129.78      ]\n",
    "# medUploadMbpsMlab COMPARISON training vs prediction (mean, 50%)\n",
    "# [18.55867215 10.07      ] v.s. [79.64160007 78.84      ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12addb05-def0-4605-a50e-c9e8209fdd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cbg_NEW.shape # ALWAYS (220334, 83)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a5fb38-4ce8-47ce-a60c-54cf2fa20ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAN DATA: invalid values are replaced with NaN, and fill with medians later\n",
    "# in most cases, when the latency and lossrate models make good predictions, then: \n",
    "# all the latencies are valid: 0.5 ms < latency <= 300ms\n",
    "all_cbg_NEW.loc[(all_cbg_NEW['latencyMlab'] <= 0.5) | (all_cbg_NEW['latencyMlab'] > 300),\n",
    "               ['latencyMlab']] = np.nan\n",
    "# All test instances where a unit’s packet loss <= 10% \n",
    "all_cbg_NEW.loc[(all_cbg_NEW['lossrateMlab'] > 10), ['lossrateMlab']] = np.nan\n",
    "\n",
    "# Check skew. Since, most important metrics medDown and medUp have good skew,\n",
    "# there's no need for quantile-based capping/flooring\n",
    "for col in ['medDownloadMbpsMlab', 'medUploadMbpsMlab']:\n",
    "    if abs(all_cbg_NEW[col].skew()) > 3:\n",
    "        print(f\"ALERT: {col} has high skew: {all_cbg_NEW[col].skew()}\")\n",
    "\n",
    "# Check null\n",
    "s = all_cbg_NEW.isnull().sum()\n",
    "if s.sum(): print(s[s>0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fddd7cc-adac-43fb-98f8-bf3415e705c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create speedSourceMlab\n",
    "all_cbg_NEW['speedSourceMlab'] = 'bigQueryCountyRFregressionAtCBG' # 88%\n",
    "cbg_training_df['speedSourceMlab'] = 'bigQueryAtCBG' # 12% \n",
    "\n",
    "# IMPORTANT: overwrite newly predicted all_cbg_NEW values using available cbg_training_df\n",
    "all_cbg_NEW.set_index(\"GEOID_cbg\", inplace=True)\n",
    "cbg_training_df.set_index(\"GEOID_cbg\", inplace=True)\n",
    "all_cbg_NEW.update(cbg_training_df)\n",
    "\n",
    "if cbg_training_df.shape[1] - all_cbg_NEW.shape[1]:\n",
    "    print(\"ALERT: all_cbg_NEW <> cbg_training_df has diff. columns LENGTH\")\n",
    "if set(cbg_training_df) - set(all_cbg_NEW):\n",
    "    print(\"ALERT: all_cbg_NEW <> cbg_training_df has diff. columns NAMES\") \n",
    "\n",
    "\n",
    "s = all_cbg_NEW.isnull().sum()\n",
    "if s.sum(): \n",
    "    print(f\"ALERT all_cbg_NEW has nulls, {s[s>0]}\")\n",
    "    \n",
    "# FILL nulls, just in case -- very unlikely\n",
    "for col in set(all_cbg_NEW.select_dtypes('number')):\n",
    "    all_cbg_NEW[col].fillna(all_cbg_NEW[col].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa1b481-8b1d-4a02-ada7-d787213eacb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cbg_NEW.reset_index(inplace=True)\n",
    "all_cbg_NEW['GEOID_cbg'] = all_cbg_NEW['GEOID_cbg'].astype(str).str.zfill(CBG_LENGTH)\n",
    "path = f'mlab_speeds/{QUARTER}-COMPLETE-CBG.csv'\n",
    "all_cbg_NEW.to_csv(path, index=False)\n",
    "print(f\"SAVED completed CBG-level speed df to {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918a16b1-d03f-42c9-a252-a5a4d98bcd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cbg_NEW.shape # after added speedSourceMlab col, always = (220334, 84) QoQ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e53703-1394-40bc-b6e5-0080a259e390",
   "metadata": {},
   "source": [
    "## FINALLY, from MLAB CBG to CB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b49b8443-2945-45f7-87a0-ebb9d0337980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 504 µs (started: 2022-04-01 05:34:49 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# REUSE cat_OOKLA_speed_conditions for speedCatMlab!\n",
    "def cat_OOKLA_speed_conditions(down, up, latency):\n",
    "    if down < 25 or up < 3:\n",
    "        return 0\n",
    "    if down < 100 or up < 20 or latency > 100: \n",
    "        return 1\n",
    "    return 2\n",
    "cat_speed_OOKLA_vectorize = np.vectorize(cat_OOKLA_speed_conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a6e26a-6a97-4c05-a9ad-ab1a603fcf44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlab_cbg_complete = all_cbg_NEW[['GEOID_cbg', 'speedSourceMlab'] + MLAB_MID_COLS].copy(deep = True)\n",
    "for sf in SF52:\n",
    "# for sf in ['02', '10']:\n",
    "    abbrv = SF52[sf]\n",
    "    # speedCatNtia was calculated (never got modified) in gen_ookla.py\n",
    "    state_cb_upload = pd.read_csv(f\"ookla_ntia/{QUARTER}_CB_{sf}.csv\")\n",
    "    if set(state_cb_upload) != set(OOKLA_END_COLS+NTIA_END_COLS+['GEOID']):\n",
    "        print(\"ALERT: Check column names of state_cb_upload\")\n",
    "\n",
    "    state_cb_upload['GEOID'] = state_cb_upload['GEOID'].astype(str).str.zfill(CB_LENGTH)\n",
    "    state_cb_upload['GEOID_cbg'] = state_cb_upload['GEOID'].str[:CBG_LENGTH]\n",
    "\n",
    "    # print(abbrv, sf, \"Without MLAB fields: \", state_cb_upload.shape) \n",
    "    s = state_cb_upload.isnull().sum()\n",
    "    if s.sum(): \n",
    "        print(\"ALERT: state_cb_upload has nulls \", s[s>0])\n",
    "    \n",
    "    state_cb_upload = state_cb_upload.merge(mlab_cbg_complete, how='left', on='GEOID_cbg').drop(columns='GEOID_cbg')\n",
    "\n",
    "    # maybe later: ANALYSIS \n",
    "    # # - speed change (mlab/ookla) and speedRankReady change from 2021Q3 to 2021Q4\n",
    "    # # - states/counties/CBG with top speeds, and top speed improvement/degrade\n",
    "\n",
    "    # Update speedCatOokla, just in case\n",
    "    state_cb_upload['speedCatOokla']= cat_speed_OOKLA_vectorize(\n",
    "        state_cb_upload['medDownloadMbpsOokla'], state_cb_upload['medUploadMbpsOokla'],  state_cb_upload['latencyOokla'])\n",
    "    # Generate new speedCatMlab col\n",
    "    state_cb_upload['speedCatMlab']= cat_speed_OOKLA_vectorize(\n",
    "        state_cb_upload['medDownloadMbpsMlab'], state_cb_upload['medUploadMbpsMlab'],  state_cb_upload['latencyMlab'])\n",
    "    # Generate new speedRankReadyRaw col\n",
    "    def cat_speedRank_conditions(catNtia, catMlab, catOokla):\n",
    "        if catNtia == 0:                                     return 'UnservedDef'         # (0, -, -)\n",
    "        if catMlab == 0 and catOokla == 0:                   return 'UnservedLikely'      # (1+, 0, 0)\n",
    "        if catMlab == 0 or catOokla == 0:                    return 'UnservedArguably'    # (1+, 0, 1+) (1+, 1+, 0)\n",
    "        if catNtia == 2 and catMlab == 2 and catOokla == 2:  return 'Served'              # (2, 2, 2)\n",
    "        if catNtia == 1:                                     return 'UnderservedDef'      # (1,1+,1+) \n",
    "        if catNtia == 2 and catMlab == 1 and catOokla == 1:  return 'UnderservedLikely'   # (2,1,1)\n",
    "        if catNtia == 2 and catMlab + catOokla == 3:         return 'UnderservedArguably' # (2,1,2) (2,2,1)\n",
    "        print(\"ALERT: SHOULD NOT REACH HERE!\")\n",
    "        return        \n",
    "    cat_speedRank_vectorize = np.vectorize(cat_speedRank_conditions)\n",
    "    state_cb_upload['speedRankReadyRaw']= cat_speedRank_vectorize(state_cb_upload.speedCatNtia, state_cb_upload.speedCatMlab, state_cb_upload.speedCatOokla)\n",
    "\n",
    "    # numTest v.s. numDevice check\n",
    "    # # RARE CASE: when devices > tests, maybe due to (1) Ookla's bad raw data, or (2) our Quantile-based Flooring and Capping process independently created this scenario\n",
    "    # # FIX: set devices = tests\n",
    "    state_cb_upload['numDeviceUploadMlab'] = np.where(state_cb_upload['numDeviceUploadMlab'] > state_cb_upload['numTestUploadMlab'], \n",
    "            state_cb_upload['numTestUploadMlab'], state_cb_upload['numDeviceUploadMlab'])    \n",
    "    state_cb_upload['numDeviceDownloadMlab'] = np.where(state_cb_upload['numDeviceDownloadMlab'] > state_cb_upload['numTestDownloadMlab'], \n",
    "            state_cb_upload['numTestDownloadMlab'], state_cb_upload['numDeviceDownloadMlab'])    \n",
    "        \n",
    "    # print(abbrv, sf, \"With MLAB fields + speedRankReadyRaw: \", state_cb_upload.shape) \n",
    "    s = state_cb_upload.isnull().sum()\n",
    "    if s.sum(): \n",
    "        print(\"ALERT: state_cb_upload has nulls \", s[s>0])\n",
    "    \n",
    "    if set(state_cb_upload) != set(['GEOID', 'speedRankReadyRaw'] + \n",
    "                                   NTIA_END_COLS + OOKLA_END_COLS + MLAB_END_COLS):\n",
    "        print(\"ALERT: check columns in the final state_cb_upload\")\n",
    "        \n",
    "    path = f'speed_ready_upload/{QUARTER}_{sf}.csv'\n",
    "    state_cb_upload.to_csv(path, index=False)\n",
    "    print(abbrv, sf, f\"Saved {state_cb_upload.shape=} to {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac67439b-58e8-4c2d-b21d-4aef33b95d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESULT CHECK\n",
    "s = \"\"\"AL 01 Saved state_cb_upload.shape=(252266, 38) to speed_ready_upload/2021Q1_01.csv\n",
    "AK 02 Saved state_cb_upload.shape=(45292, 38) to speed_ready_upload/2021Q1_02.csv\n",
    "AZ 04 Saved state_cb_upload.shape=(241666, 38) to speed_ready_upload/2021Q1_04.csv\n",
    "AR 05 Saved state_cb_upload.shape=(186211, 38) to speed_ready_upload/2021Q1_05.csv\n",
    "CA 06 Saved state_cb_upload.shape=(710145, 38) to speed_ready_upload/2021Q1_06.csv\n",
    "CO 08 Saved state_cb_upload.shape=(201062, 38) to speed_ready_upload/2021Q1_08.csv\n",
    "CT 09 Saved state_cb_upload.shape=(67578, 38) to speed_ready_upload/2021Q1_09.csv\n",
    "DE 10 Saved state_cb_upload.shape=(24115, 38) to speed_ready_upload/2021Q1_10.csv\n",
    "DC 11 Saved state_cb_upload.shape=(6507, 38) to speed_ready_upload/2021Q1_11.csv\n",
    "FL 12 Saved state_cb_upload.shape=(484481, 38) to speed_ready_upload/2021Q1_12.csv\n",
    "GA 13 Saved state_cb_upload.shape=(291086, 38) to speed_ready_upload/2021Q1_13.csv\n",
    "HI 15 Saved state_cb_upload.shape=(25016, 38) to speed_ready_upload/2021Q1_15.csv\n",
    "ID 16 Saved state_cb_upload.shape=(149842, 38) to speed_ready_upload/2021Q1_16.csv\n",
    "IL 17 Saved state_cb_upload.shape=(451554, 38) to speed_ready_upload/2021Q1_17.csv\n",
    "IN 18 Saved state_cb_upload.shape=(267071, 38) to speed_ready_upload/2021Q1_18.csv\n",
    "IA 19 Saved state_cb_upload.shape=(216007, 38) to speed_ready_upload/2021Q1_19.csv\n",
    "KS 20 Saved state_cb_upload.shape=(238600, 38) to speed_ready_upload/2021Q1_20.csv\n",
    "KY 21 Saved state_cb_upload.shape=(161672, 38) to speed_ready_upload/2021Q1_21.csv\n",
    "LA 22 Saved state_cb_upload.shape=(204447, 38) to speed_ready_upload/2021Q1_22.csv\n",
    "ME 23 Saved state_cb_upload.shape=(69518, 38) to speed_ready_upload/2021Q1_23.csv\n",
    "MD 24 Saved state_cb_upload.shape=(145247, 38) to speed_ready_upload/2021Q1_24.csv\n",
    "MA 25 Saved state_cb_upload.shape=(157508, 38) to speed_ready_upload/2021Q1_25.csv\n",
    "MI 26 Saved state_cb_upload.shape=(329885, 38) to speed_ready_upload/2021Q1_26.csv\n",
    "MN 27 Saved state_cb_upload.shape=(259777, 38) to speed_ready_upload/2021Q1_27.csv\n",
    "MS 28 Saved state_cb_upload.shape=(171778, 38) to speed_ready_upload/2021Q1_28.csv\n",
    "MO 29 Saved state_cb_upload.shape=(343565, 38) to speed_ready_upload/2021Q1_29.csv\n",
    "MT 30 Saved state_cb_upload.shape=(132288, 38) to speed_ready_upload/2021Q1_30.csv\n",
    "NE 31 Saved state_cb_upload.shape=(193352, 38) to speed_ready_upload/2021Q1_31.csv\n",
    "NV 32 Saved state_cb_upload.shape=(84538, 38) to speed_ready_upload/2021Q1_32.csv\n",
    "NH 33 Saved state_cb_upload.shape=(48837, 38) to speed_ready_upload/2021Q1_33.csv\n",
    "NJ 34 Saved state_cb_upload.shape=(169588, 38) to speed_ready_upload/2021Q1_34.csv\n",
    "NM 35 Saved state_cb_upload.shape=(168609, 38) to speed_ready_upload/2021Q1_35.csv\n",
    "NY 36 Saved state_cb_upload.shape=(350169, 38) to speed_ready_upload/2021Q1_36.csv\n",
    "NC 37 Saved state_cb_upload.shape=(288987, 38) to speed_ready_upload/2021Q1_37.csv\n",
    "ND 38 Saved state_cb_upload.shape=(133769, 38) to speed_ready_upload/2021Q1_38.csv\n",
    "OH 39 Saved state_cb_upload.shape=(365344, 38) to speed_ready_upload/2021Q1_39.csv\n",
    "OK 40 Saved state_cb_upload.shape=(269118, 38) to speed_ready_upload/2021Q1_40.csv\n",
    "OR 41 Saved state_cb_upload.shape=(196621, 38) to speed_ready_upload/2021Q1_41.csv\n",
    "PA 42 Saved state_cb_upload.shape=(421545, 38) to speed_ready_upload/2021Q1_42.csv\n",
    "RI 44 Saved state_cb_upload.shape=(25181, 38) to speed_ready_upload/2021Q1_44.csv\n",
    "SC 45 Saved state_cb_upload.shape=(181908, 38) to speed_ready_upload/2021Q1_45.csv\n",
    "SD 46 Saved state_cb_upload.shape=(88360, 38) to speed_ready_upload/2021Q1_46.csv\n",
    "TN 47 Saved state_cb_upload.shape=(240116, 38) to speed_ready_upload/2021Q1_47.csv\n",
    "TX 48 Saved state_cb_upload.shape=(914231, 38) to speed_ready_upload/2021Q1_48.csv\n",
    "UT 49 Saved state_cb_upload.shape=(115406, 38) to speed_ready_upload/2021Q1_49.csv\n",
    "VT 50 Saved state_cb_upload.shape=(32580, 38) to speed_ready_upload/2021Q1_50.csv\n",
    "VA 51 Saved state_cb_upload.shape=(285762, 38) to speed_ready_upload/2021Q1_51.csv\n",
    "WA 53 Saved state_cb_upload.shape=(195574, 38) to speed_ready_upload/2021Q1_53.csv\n",
    "WV 54 Saved state_cb_upload.shape=(135218, 38) to speed_ready_upload/2021Q1_54.csv\n",
    "WI 55 Saved state_cb_upload.shape=(253096, 38) to speed_ready_upload/2021Q1_55.csv\n",
    "WY 56 Saved state_cb_upload.shape=(86204, 38) to speed_ready_upload/2021Q1_56.csv\n",
    "PR 72 Saved state_cb_upload.shape=(77189, 38) to speed_ready_upload/2021Q1_72.csv\"\"\"\n",
    "l = [k.split(')')[0].split('(')[1].split(',')[0] for k in s.split(\"Saved state_cb_upload.shape=\")[1:]]\n",
    "# 11155486 (11,155,486)! ALL census blocks present! ok!\n",
    "sum(int(x) for x in l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8e84bc-3844-438a-b22c-e8d9727da8d5",
   "metadata": {},
   "source": [
    "#### NOTE: Cols count: explained\n",
    "###### before <> after: state_cb_upload.merge(mlab_cbg_complete,...)\n",
    "- state_cb_upload = f\"ookla_ntia/{QUARTER}_CB_{sf}.csv\" \n",
    "    - = 13 NTIA + 7 Ookla + GEOID_cbg + GEOID = 22 cols\n",
    "- merge with mlab_cbg_complete (MLAB_END_COLS - speedCatMlab + GEOID_cbg) = 37 \n",
    "    - minus GEOID_cbg = 36\n",
    "    - plus speedCatMlab + speedRankReadyRaw = 38 = final column count \n",
    "    - = GEOID + speedRankReadyRaw + NTIA_END_COLS#7 + OOKLA_END_COLS#13 + MLAB_END_COLS#16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c93b2e1-35cb-4005-b4c7-0a7d58212490",
   "metadata": {},
   "source": [
    "### Final step: Run upload_speed_test.py: Check results, upload to speed_test\n",
    "- IMPORTANT: update QUARTER inside upload_speed_test.py\n",
    "- by running: $ bash speed/cmds.bash &  (comment other commands in cmds.bash as needed)\n",
    "- NOTE: when complete uploading, check docs count for speed_test index = total number of census block in SF52: 11,155,486"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ebb3c6-3284-493f-b19c-8c3c1e8d28dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK UPLOAD COUNTS\n",
    "cmds_log_string = \"\"\"\n",
    "\"\"\"\n",
    "s1 = cmds_log_string.split('Completed uploading')[1:]\n",
    "s2 = [int(k.split(' records to ')[0].strip()) for k in s1]\n",
    "len(s2), sum(s2) # (52, 11-155-486 YES!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f9beb17b-9ce9-4421-9a01-419ad7f5a1d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.53 ms (started: 2022-04-01 12:34:01 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# CHECK DOWNLOAD COUNTS\n",
    "s = \"\"\"\n",
    "\"\"\"\n",
    "s1 = s.split('Saved ntia_df ')[1:]\n",
    "s2 = [int(k.split(') to  Elasticsearch/')[0].split(', ')[0][1:]) for k in s1]\n",
    "len(s2), sum(s2) # (52, 11-155-486 YES!)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
