{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19dc7e4e-f57c-4c44-a45f-3a6e239cbe80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 345 µs (started: 2022-01-03 11:37:49 -05:00)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import numpy as np\n",
    "import datetime\n",
    "import subprocess\n",
    "import ijson\n",
    "import json\n",
    "from subprocess import getoutput\n",
    "from glob import glob\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os \n",
    "from pathlib import Path\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "es = Elasticsearch(['https://3d6a9dd50c7c49c9ab5d23b6891bc03e.us-central1.gcp.cloud.es.io:9243'], \n",
    "                http_auth=('elastic', 'WMzYk5RXyzE7MRShwPVwHzPX'), timeout=30)\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f9fa5a7-cddb-41b1-917c-3f6e2bf52126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL SIZE:    7.2 KiB\n",
      "       Elasticsearch:    2.0 KiB\n",
      "                Path:    896.0 B\n",
      "                  _i:    552.0 B\n",
      "                 _i1:    552.0 B\n",
      "                 _i2:    531.0 B\n",
      "                 _oh:    232.0 B\n",
      "                 Out:    232.0 B\n",
      "           getoutput:    136.0 B\n",
      "                glob:    136.0 B\n",
      "         load_dotenv:    136.0 B\n",
      "time: 1.89 ms (started: 2021-12-20 13:11:27 -05:00)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "def sizeof_fmt(size):\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(size) < 1024.0:\n",
    "            return f\"{size:3.1f} {unit}B\"\n",
    "        size /= 1024.0\n",
    "    return f\"{size:.1f} YiB\"\n",
    "\n",
    "print(f'TOTAL SIZE: {sizeof_fmt(sum( (sys.getsizeof(value) for value in locals().values() ))):>10}')\n",
    "for nam, size in sorted(((nam, sys.getsizeof(value)) for nam, value in locals().items()), key= lambda x: -x[1])[:10]:\n",
    "    print(f'{nam:>20}: {sizeof_fmt(size):>10}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7c6313d-36b7-41fc-b935-365f55f5d4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 966 µs (started: 2021-12-20 13:11:30 -05:00)\n"
     ]
    }
   ],
   "source": [
    "regridcols = ['cbg', 'lat', 'lon', 'func']\n",
    "parcelNumIndCols = ['parcelNumAgri', 'parcelNumCommer',  \n",
    "                    'parcelNumInfra', 'parcelNumNull', \n",
    "                    'parcelNumResi']\n",
    "\n",
    "BLOCKGROUP_FIPS_LENGTH = 12\n",
    "STATE_FIPS_DICT_52 = { '01': 'AL', '02': 'AK', '04': 'AZ', '05': 'AR', \n",
    "                      '06': 'CA', '08': 'CO', '09': 'CT', '10': 'DE', \n",
    "                      '11': 'DC', '12': 'FL', '13': 'GA', '15': 'HI', \n",
    "                      '16': 'ID', '17': 'IL', '18': 'IN', '19': 'IA', \n",
    "                      '20': 'KS', '21': 'KY', '22': 'LA', '23': 'ME', \n",
    "                      '24': 'MD', '25': 'MA', '26': 'MI', '27': 'MN', \n",
    "                      '28': 'MS', '29': 'MO', '30': 'MT', '31': 'NE', \n",
    "                      '32': 'NV', '33': 'NH', '34': 'NJ', '35': 'NM', \n",
    "                      '36': 'NY', '37': 'NC', '38': 'ND', '39': 'OH', \n",
    "                      '40': 'OK', '41': 'OR', '42': 'PA', '44': 'RI', \n",
    "                      '45': 'SC', '46': 'SD', '47': 'TN', '48': 'TX', \n",
    "                      '49': 'UT', '50': 'VT', '51': 'VA', '53': 'WA', \n",
    "                      '54': 'WV', '55': 'WI', '56': 'WY', '72': 'PR'}\n",
    "\n",
    "REGRID_BUCKET_DIR = '/home/nhat/regrid-bucket/'\n",
    "JQ_JSONS_DIR = '/home/nhat/jq-jsons/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcf965a-264f-497c-a010-815e4071d068",
   "metadata": {},
   "source": [
    "# Update Regrid data / Regrid verse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef9ba0d-2e44-44a9-8792-d16df6c7e040",
   "metadata": {},
   "source": [
    "https://support.regrid.com/articles/verse\n",
    "- Parcelverse metadata\n",
    "- The two critical pieces of information in the verse table are filename_stem and last_refresh. Those two fields tell you the name of the dataset for a county and the last time we did a full data pull from the source, usually the county or a designee.\n",
    "- **To find the latest updates in verse, sort by 'last_refresh' and use the 'filename_stem' column to identify the file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dce625f-d07f-486d-9e28-038334d1986e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 767 ms (started: 2021-12-20 13:11:32 -05:00)\n"
     ]
    }
   ],
   "source": [
    "verse = gp.read_file('~/regrid-bucket/verse.csv.zip')\n",
    "verse.shape # 3232\n",
    "# verse.isnull().sum() # geometry 3232 ALL EMPTY i.e. useless; anyway, better from source: tiger census \n",
    "# verse.dtypes # all object types\n",
    "# verse['county_state'] = verse['county'] + ',' + verse['state'] \n",
    "# len(verse['county_state'].unique()) # 3226\n",
    "verse = verse.replace('', np.nan)\n",
    "# verse.isnull().sum()\n",
    "\n",
    "## CLEANING: Drop empty last_refresh / empty table_name\n",
    "def set_diff(a, b, col):\n",
    "    print(f\"{set(a[col]) - set(b[col])=}\")\n",
    "    print(f\"{set(b[col]) - set(a[col])=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "007ceb79-29df-4c00-b9d9-729dde896b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 621 µs (started: 2021-12-15 05:31:58 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# table_name <> last_refresh = 166 ;\n",
    "# total_objects <> filename_stem <> usps_data_date = 165;\n",
    "    \n",
    "# verse_refresh = verse.dropna(subset=['last_refresh'])\n",
    "# verse_table = verse.dropna(subset=['table_name'])\n",
    "# set_diff(verse_refresh, verse_table)\n",
    "\n",
    "# verse_objects = verse.dropna(subset=['total_objects'])\n",
    "# verse_name = verse.dropna(subset=['filename_stem'])\n",
    "# verse_usps = verse.dropna(subset=['usps_data_date'])\n",
    "# len(verse_objects), len(verse_name), len(verse_usps) # (3067, 3067, 3067)\n",
    "# set_diff(verse_objects, verse_name)\n",
    "# set_diff(verse_usps, verse_name)\n",
    "# set_diff(verse_objects, verse_usps)\n",
    "\n",
    "# set_diff(verse_refresh, verse_objects)\n",
    "# set_diff(verse_table, verse_name)\n",
    "\n",
    "# ONLY DIFFERENCE: id = 10190\n",
    "# set(a['id']) - set(b['id'])=set()\n",
    "\n",
    "# filename_stem = ok_washington_bartlesville, no last_refresh, has 22507 total objects and not found in our boss-geo-data bucket! CAN IGNORE\n",
    "# set(b['id']) - set(a['id'])={'10190'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2eb48d1-e036-45a0-9e96-aa55202d6be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "county     0\n",
       "state      0\n",
       "geoid      0\n",
       "refresh    0\n",
       "name       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 23.4 ms (started: 2021-12-20 13:11:35 -05:00)\n"
     ]
    }
   ],
   "source": [
    "verse_refresh = verse.dropna(subset=['last_refresh'])\n",
    "verse_refresh.shape # (3066, 19)\n",
    "verse_refresh = verse_refresh[['county', 'state', 'geoid', 'last_refresh', 'filename_stem']].copy()\n",
    "verse_refresh = verse_refresh.rename(columns={'last_refresh': 'refresh', 'filename_stem': 'name'})\n",
    "verse_refresh.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bc05a1-5fd7-48f3-aeaf-eebadad1ff66",
   "metadata": {},
   "source": [
    "## 3232 rows, with 3226 distinct counties, and 3066 counties with parcel data (non-empty table_name or last_refresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "b67533b5-8be7-43d8-86f1-f33d42b9797e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 303 µs (started: 2021-12-14 22:09:00 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# verse[verse.duplicated(['county', 'state'], keep=False)].sort_values(['state','county'])\n",
    "# verse[verse.duplicated(['geoid'], keep=False)].sort_values(['state','county'])\n",
    "\n",
    "# len(verse['geoid'].unique()) # 3226\n",
    "# # 3226 geoids from 3232 rows, only valid repeated geoid = 26163 {mi_wayne_detroit and mi_wayne}\n",
    "# len(verse) - (verse['filename_stem'] == '').sum() # 3067\n",
    "# len(verse) - (verse['last_refresh'] == '').sum() # 3066\n",
    "# len(verse) - (verse['table_name'] == '').sum() # 3066"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "e094c8b1-1cf1-4d21-b359-6eefc7ada89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 390 µs (started: 2021-12-14 22:09:03 +00:00)\n"
     ]
    }
   ],
   "source": [
    "### Extra: insufficient cleaning\n",
    "# # extraneous_ids = {'760', '1314', '1322', '1324', '10190', }\n",
    "# rowIds = ['table_name', 'county', 'state']\n",
    "# extra = pd.DataFrame(data= {('','DeKalb','IL'),\n",
    "# ('','Iron','MI'),\n",
    "# ('','Lapeer','MI'),\n",
    "# ('','Lenawee','MI'),\n",
    "# ('','Washington','OK')}, columns=rowIds)\n",
    "\n",
    "# verse_clean = pd.concat([verse, extra]).drop_duplicates(subset=rowIds, keep=False)\n",
    "# verse_clean.shape # (3227, 20)\n",
    "# verse_clean\n",
    "\n",
    "# (verse_clean['path'] == '').sum() # 0\n",
    "# (verse_clean['geoid'] == '').sum() # 0\n",
    "# len(verse_clean['geoid'].unique()) # 3226\n",
    "# # 3226 geoids from 3227 rows, only repeated geoid = 26163 {mi_wayne_detroit and mi_wayne}\n",
    "\n",
    "# len(verse_clean) - (verse_clean['filename_stem'] == '').sum() # 3066\n",
    "# len(verse_clean) - (verse_clean['last_refresh'] == '').sum() # 3066\n",
    "# len(verse_clean) - (verse_clean['table_name'] == '').sum() # 3066"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e132b90-102e-4a4f-b699-739d857f12f6",
   "metadata": {},
   "source": [
    "## Regrid parcels: have 3059 zip files i.e. Regrid has 3059 counties with parcel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3245d4a0-26e9-41f1-89c1-11f524948be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 19.8 ms (started: 2021-12-20 13:11:39 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# with open('extras/geoid_c_r.json', 'r') as f:\n",
    "#     countygeoid = json.load(f)\n",
    "#     countygeoid = pd.DataFrame({'geoid': countygeoid})\n",
    "countygeoid = pd.read_json('~/extras/geoid_c_r.json', typ='dictionary')\n",
    "countygeoid = countygeoid.reset_index()\n",
    "countygeoid = countygeoid.rename(columns = {'index': 'name', 0: 'geoid'})\n",
    "countygeoid['geoid'] = countygeoid['geoid'].astype(str).str.zfill(5)\n",
    "# countygeoid # 3059 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95d11371-9133-49a0-bad6-eecd42a9bce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(a[col]) - set(b[col])={'vi_st-thomas', 'gu_guam', 'mp_rota', 'mp_saipan', 'mp_tinian', 'vi_st-croix', 'vi_st-john'}\n",
      "set(b[col]) - set(a[col])={'tx_nacogdoches'}\n",
      "time: 4.63 ms (started: 2021-12-20 13:11:39 -05:00)\n"
     ]
    }
   ],
   "source": [
    "len(set(verse_refresh['name'])) # 3066\n",
    "len(set(countygeoid['name'])) # 3059\n",
    "set_diff(verse_refresh, countygeoid, 'name')\n",
    "# US territories {'vi_st-john', 'gu_guam', 'vi_st-thomas', 'mp_tinian', 'mp_rota', 'vi_st-croix', 'mp_saipan'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0802e95f-7d2e-40ac-bffb-6b8380cc01cb",
   "metadata": {},
   "source": [
    "## NOTE: rows with filename_stem = \"\" (or last_refresh = \"\"): NEW COUNTY, no data from regird (i.e. no zip files deposited into our boss-geo-data bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2615acc2-841f-422f-968c-d6eb8d52c63c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11 ms (started: 2021-12-20 13:11:58 -05:00)\n"
     ]
    }
   ],
   "source": [
    "ver = verse_refresh.reset_index(drop=True)\n",
    "us_territories_noncoverage= {'vi_st-john', 'gu_guam', 'vi_st-thomas', 'mp_tinian', 'mp_rota', 'vi_st-croix', 'mp_saipan'}\n",
    "ver = ver[~ver['name'].isin(us_territories_noncoverage)]\n",
    "ver['refresh'] = pd.to_datetime(ver['refresh'], format='%Y-%m-%d').dt.date\n",
    "# NOTE: refresh has datetime.date objects https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.date.html\n",
    "# ver.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a804339-8cbc-4abb-ae7f-d5d638aa773c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "refresh\n",
       "2021-10-26    139\n",
       "2021-11-09    157\n",
       "2021-11-23     54\n",
       "2021-12-05      1\n",
       "2021-12-14    218\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.47 ms (started: 2021-12-21 01:24:05 -05:00)\n"
     ]
    }
   ],
   "source": [
    "ver.sort_values('refresh').groupby('refresh').size().tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaba46c-e4be-4514-abdf-6791ffd804c3",
   "metadata": {},
   "source": [
    "# NEW UPDATE ON DEC 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5f933c-8cdd-474a-ab42-f2070564a60e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6cc67678-83ee-440a-a897-97a9c06b9791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2021, 11, 23)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.09 ms (started: 2021-12-21 01:34:24 -05:00)\n"
     ]
    }
   ],
   "source": [
    "datetime.datetime.fromisoformat('2021-11-23').date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2265c2ed-c637-4d74-a8c1-961a637adb97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'today=datetime.date(2021, 12, 3), latest_refresh_date=datetime.date(2021, 12, 14)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.75 ms (started: 2021-12-20 13:12:37 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# datetime.date(2021, 12, 15)\n",
    "today = datetime.datetime.today().date()\n",
    "\n",
    "# datetime.date(2021, 11, 28)\n",
    "latest_refresh_date = ver['refresh'].max()\n",
    "\n",
    "# FOR TESTING // change this afterward\n",
    "today = datetime.date(2021, 12, 3)\n",
    "\n",
    "f\"{today=}, {latest_refresh_date=}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1748568-df27-402b-97e1-259238ec5f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'date_2021-12-03'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.71 ms (started: 2021-12-21 01:39:28 -05:00)\n"
     ]
    }
   ],
   "source": [
    "f\"date_{today}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fd9e4e-29f0-42e2-9bf4-63d4da2df02a",
   "metadata": {},
   "source": [
    "# MAIN FUNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06d80293-8f58-4d5b-bd82-6efc68104442",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.52 ms (started: 2021-12-21 01:41:31 -05:00)\n"
     ]
    }
   ],
   "source": [
    "county_dfs = None\n",
    "if latest_refresh_date >= today:\n",
    "    # NEED UPDATE\n",
    "    # find counties that is refreshed today or after\n",
    "    county_dfs = ver.loc[ver['refresh'] >= today]\n",
    "\n",
    "state_dfs = [x for _, x in county_dfs.groupby('state')]\n",
    "# county_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6fef55c6-ef69-4f3d-b426-627d4cd08184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>geoid</th>\n",
       "      <th>refresh</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Forrest</td>\n",
       "      <td>MS</td>\n",
       "      <td>28035</td>\n",
       "      <td>2021-12-14</td>\n",
       "      <td>ms_forrest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Noxubee</td>\n",
       "      <td>MS</td>\n",
       "      <td>28103</td>\n",
       "      <td>2021-12-14</td>\n",
       "      <td>ms_noxubee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Calhoun</td>\n",
       "      <td>MS</td>\n",
       "      <td>28013</td>\n",
       "      <td>2021-12-14</td>\n",
       "      <td>ms_calhoun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Leake</td>\n",
       "      <td>MS</td>\n",
       "      <td>28079</td>\n",
       "      <td>2021-12-14</td>\n",
       "      <td>ms_leake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Monroe</td>\n",
       "      <td>FL</td>\n",
       "      <td>12087</td>\n",
       "      <td>2021-12-14</td>\n",
       "      <td>fl_monroe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3060</th>\n",
       "      <td>Washington</td>\n",
       "      <td>FL</td>\n",
       "      <td>12133</td>\n",
       "      <td>2021-12-14</td>\n",
       "      <td>fl_washington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3061</th>\n",
       "      <td>Suwannee</td>\n",
       "      <td>FL</td>\n",
       "      <td>12121</td>\n",
       "      <td>2021-12-14</td>\n",
       "      <td>fl_suwannee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3062</th>\n",
       "      <td>Volusia</td>\n",
       "      <td>FL</td>\n",
       "      <td>12127</td>\n",
       "      <td>2021-12-14</td>\n",
       "      <td>fl_volusia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063</th>\n",
       "      <td>Walton</td>\n",
       "      <td>FL</td>\n",
       "      <td>12131</td>\n",
       "      <td>2021-12-14</td>\n",
       "      <td>fl_walton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3064</th>\n",
       "      <td>St. Johns</td>\n",
       "      <td>FL</td>\n",
       "      <td>12109</td>\n",
       "      <td>2021-12-14</td>\n",
       "      <td>fl_st-johns</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>219 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          county state  geoid     refresh           name\n",
       "30       Forrest    MS  28035  2021-12-14     ms_forrest\n",
       "148      Noxubee    MS  28103  2021-12-14     ms_noxubee\n",
       "155      Calhoun    MS  28013  2021-12-14     ms_calhoun\n",
       "176        Leake    MS  28079  2021-12-14       ms_leake\n",
       "205       Monroe    FL  12087  2021-12-14      fl_monroe\n",
       "...          ...   ...    ...         ...            ...\n",
       "3060  Washington    FL  12133  2021-12-14  fl_washington\n",
       "3061    Suwannee    FL  12121  2021-12-14    fl_suwannee\n",
       "3062     Volusia    FL  12127  2021-12-14     fl_volusia\n",
       "3063      Walton    FL  12131  2021-12-14      fl_walton\n",
       "3064   St. Johns    FL  12109  2021-12-14    fl_st-johns\n",
       "\n",
       "[219 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.6 ms (started: 2021-12-21 01:42:20 -05:00)\n"
     ]
    }
   ],
   "source": [
    "county_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b17c8e1b-1a39-4384-a660-d6fd7d737b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.72 ms (started: 2021-12-21 01:43:54 -05:00)\n"
     ]
    }
   ],
   "source": [
    "len(set(county_dfs.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e12d393d-0d1c-4fd4-9fa0-23a7cf9d126d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30         ms_forrest\n",
       "148        ms_noxubee\n",
       "155        ms_calhoun\n",
       "176          ms_leake\n",
       "205         fl_monroe\n",
       "            ...      \n",
       "3060    fl_washington\n",
       "3061      fl_suwannee\n",
       "3062       fl_volusia\n",
       "3063        fl_walton\n",
       "3064      fl_st-johns\n",
       "Name: name, Length: 219, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.99 ms (started: 2021-12-21 01:52:51 -05:00)\n"
     ]
    }
   ],
   "source": [
    "county_dfs.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dfc40fd9-9eb1-48b6-b4ea-60b2c6c145f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>geoid</th>\n",
       "      <th>refresh</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Forrest</td>\n",
       "      <td>MS</td>\n",
       "      <td>28035</td>\n",
       "      <td>2021-12-14</td>\n",
       "      <td>ms_forrest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Noxubee</td>\n",
       "      <td>MS</td>\n",
       "      <td>28103</td>\n",
       "      <td>2021-12-14</td>\n",
       "      <td>ms_noxubee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Calhoun</td>\n",
       "      <td>MS</td>\n",
       "      <td>28013</td>\n",
       "      <td>2021-12-14</td>\n",
       "      <td>ms_calhoun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Leake</td>\n",
       "      <td>MS</td>\n",
       "      <td>28079</td>\n",
       "      <td>2021-12-14</td>\n",
       "      <td>ms_leake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Monroe</td>\n",
       "      <td>FL</td>\n",
       "      <td>12087</td>\n",
       "      <td>2021-12-14</td>\n",
       "      <td>fl_monroe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3060</th>\n",
       "      <td>Washington</td>\n",
       "      <td>FL</td>\n",
       "      <td>12133</td>\n",
       "      <td>2021-12-14</td>\n",
       "      <td>fl_washington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3061</th>\n",
       "      <td>Suwannee</td>\n",
       "      <td>FL</td>\n",
       "      <td>12121</td>\n",
       "      <td>2021-12-14</td>\n",
       "      <td>fl_suwannee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3062</th>\n",
       "      <td>Volusia</td>\n",
       "      <td>FL</td>\n",
       "      <td>12127</td>\n",
       "      <td>2021-12-14</td>\n",
       "      <td>fl_volusia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063</th>\n",
       "      <td>Walton</td>\n",
       "      <td>FL</td>\n",
       "      <td>12131</td>\n",
       "      <td>2021-12-14</td>\n",
       "      <td>fl_walton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3064</th>\n",
       "      <td>St. Johns</td>\n",
       "      <td>FL</td>\n",
       "      <td>12109</td>\n",
       "      <td>2021-12-14</td>\n",
       "      <td>fl_st-johns</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>219 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          county state  geoid     refresh           name\n",
       "30       Forrest    MS  28035  2021-12-14     ms_forrest\n",
       "148      Noxubee    MS  28103  2021-12-14     ms_noxubee\n",
       "155      Calhoun    MS  28013  2021-12-14     ms_calhoun\n",
       "176        Leake    MS  28079  2021-12-14       ms_leake\n",
       "205       Monroe    FL  12087  2021-12-14      fl_monroe\n",
       "...          ...   ...    ...         ...            ...\n",
       "3060  Washington    FL  12133  2021-12-14  fl_washington\n",
       "3061    Suwannee    FL  12121  2021-12-14    fl_suwannee\n",
       "3062     Volusia    FL  12127  2021-12-14     fl_volusia\n",
       "3063      Walton    FL  12131  2021-12-14      fl_walton\n",
       "3064   St. Johns    FL  12109  2021-12-14    fl_st-johns\n",
       "\n",
       "[219 rows x 5 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.79 ms (started: 2021-12-21 02:00:50 -05:00)\n"
     ]
    }
   ],
   "source": [
    "county_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b79ca8a8-06a4-403a-a757-89dcc06f48f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.93 ms (started: 2021-12-21 01:43:00 -05:00)\n"
     ]
    }
   ],
   "source": [
    "len(county_dfs.county.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a234650-75c9-476d-b218-10080d006b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['06', '08', '12', '19', '16', '27', '28', '38', '42', '48', '51', '55']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.27 ms (started: 2021-12-16 21:16:23 -05:00)\n"
     ]
    }
   ],
   "source": [
    "updated_states = []\n",
    "for state_df in state_dfs:\n",
    "    STATE_FIPS_LENGTH = 2\n",
    "    statefips = state_df.iloc[0].geoid[:STATE_FIPS_LENGTH]\n",
    "    updated_states.append(statefips)\n",
    "\n",
    "updated_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c81760d-8ea4-484e-a876-2660b79a7b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>geoid</th>\n",
       "      <th>refresh</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>WI</td>\n",
       "      <td>55079</td>\n",
       "      <td>2021-11-28</td>\n",
       "      <td>wi_milwaukee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         county state  geoid     refresh          name\n",
       "1244  Milwaukee    WI  55079  2021-11-28  wi_milwaukee"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.41 ms (started: 2021-12-16 21:16:25 -05:00)\n"
     ]
    }
   ],
   "source": [
    "state_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab658e0-597f-498f-8ba6-83f1e222ce55",
   "metadata": {},
   "source": [
    "## MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2475be4e-d86b-493c-8eb2-2195f827c90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading input file name='wi_milwaukee' at: input_file='/home/nhat/regrid-bucket/wi_milwaukee.json'\n",
      "Wrote/updated county name='wi_milwaukee' json to output_file='/home/nhat/jq-jsons/wi_milwaukee.json'\n",
      "statefips='55', updated_counties=['/home/nhat/jq-jsons/wi_milwaukee.json']\n",
      "time: 1min 12s (started: 2021-12-16 21:19:03 -05:00)\n"
     ]
    }
   ],
   "source": [
    "updated_counties = []\n",
    "\n",
    "for index, row in state_df.iterrows():\n",
    "    county, geoid, name = row['county'], row['geoid'], row['name']\n",
    "    \n",
    "#     # 1. unzip county name ~/regrid-bucket/name.geojson.zip (in boss-geo-data)\n",
    "#     unzipCmd = f\"unzip -o -d /home/nhat/regrid-bucket/ /home/nhat/regrid-bucket/{name}.geojson.zip\".split()\n",
    "#     run_unzip_res =  subprocess.run(unzipCmd, check=True, capture_output=True, text=True)\n",
    "#     print(f'{run_unzip_res=}')\n",
    "    \n",
    "#     # 2. MAIN FUNC: slow: ijson stream parse ~/regrid-bucket/county.json into ~/jq-jsons/\n",
    "    jq_json = stream_parse(name)\n",
    "    updated_counties.append(jq_json)\n",
    "    \n",
    "# 3. run parcelNumAddr.py to joint point-in-polygon and upload to ES based on given geoid/\n",
    "print(f'{statefips=}, {updated_counties=}')\n",
    "# MAIN FUNC: slow: getting numAddr and upload to ES\n",
    "# es_df = parcel_addr(statefips, updated_counties)\n",
    "\n",
    "# AFTER UNZIPPING geojson.zip, generate script to re-tile mbtiles\n",
    "# 4. MAIN FUNC: slow: re-tile mbtiles for entire states, for each state in updated_states\n",
    "# ['06', '08', '12', '19', '16', '27', '28', '38', '42', '48', '51', '55']\n",
    "tippecanoe_cmdFile = f'/home/nhat/mbtiles/update-commands.txt'\n",
    "gen_tippecanoe_commands(updated_states, tippecanoe_cmdFile)\n",
    "\n",
    "# 5. postgis: \n",
    "# organize by state_abbrev (parcels_ak, parcels_al, etc.)\n",
    "# FIRST: add row filename_stem (from a local saved dict mapping) for all records\n",
    "# remove rows from state table with matching (county) filename_stem\n",
    "# can handle EXCEPTION: geoid = 26163 {mi_wayne_detroit and mi_wayne} :: filename_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "22aa43f5-7dd6-4ff8-9977-140eeeffcb34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b\n",
       "0  1  2\n",
       "1  3  4"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 14.4 ms (started: 2021-12-18 18:53:17 -05:00)\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame([[1,2], [3,4]], columns=['a','b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7b49d5-4af3-41e1-8cc1-b348aa237fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for json in updated_counties:\n",
    "    filename_stem = Path(json).stem\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54fd65c-dbd0-4d70-a93f-744eebb7438e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# AFTER: 4.A External separate script: \n",
    "# cronjob conda activate py39 && python3 verse.py && bash ~/mbtiles/parallel-update.sh && docker restart tileserver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9253648-8675-4e2c-b198-52f67514b7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AFTER: 5.A EXTERNAL separate script:\n",
    "# # RESTART martin after finish updating to POSTGIS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641be449-d3da-4a65-b19c-a9ca37edc1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 519 ms (started: 2021-12-16 21:21:57 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# for updated_statefips in updated_states:\n",
    "updated_statefips = updated_states[-1]\n",
    "state_abbrv = STATE_FIPS_DICT_52[updated_statefips].lower()\n",
    "state_all_counties = glob(f\"{REGRID_BUCKET_DIR}{state_abbrv}_*.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a39eb1-ca9f-4e19-b627-255ea6683fde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c68f65d3-800d-46eb-897c-f1af07a4f18f",
   "metadata": {},
   "source": [
    "#### Experiment with groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "7a1c5f4a-d803-4386-81b7-92c38f76d712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 256 µs (started: 2021-12-15 05:26:18 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# df = pd.DataFrame(data={'a': [1, 2, 3 , 2, 3, 3], 'b': [10, 20, 20, 10, 10, 30], 'c': [13, 13 , 13, 13 , 13, 13]})\n",
    "# # https://stackoverflow.com/a/50866760\n",
    "# dfs = [x for _, x in df.groupby('b')]\n",
    "# dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f586aa7-f83f-4b2d-a39d-e8f372ddc55e",
   "metadata": {},
   "source": [
    "# TOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab61e6dc-6947-4fd3-bfd9-cf5c396fff13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.83 ms (started: 2021-12-16 21:17:36 -05:00)\n"
     ]
    }
   ],
   "source": [
    "def parcel_addr(statefips, updated_counties):\n",
    "    STATE_ABBRV = STATE_FIPS_DICT_52[statefips]\n",
    "    state_abbrv = STATE_ABBRV.lower()\n",
    "    \n",
    "    # assemble state dataframe from county jsonl\n",
    "    frames = []\n",
    "    for jsonl in updated_counties:\n",
    "        df = pd.read_json(jsonl)\n",
    "        if not df.empty:\n",
    "            df['cbg'] = df['cbg'].astype(str).str.zfill(BLOCKGROUP_FIPS_LENGTH)\n",
    "            df['func'] = (df['func'].fillna(0) // 1000).astype(int)\n",
    "            frames.append(df)\n",
    "\n",
    "    state_parcels = pd.concat(frames)\n",
    "    print(f\"{state_parcels.shape=}\")\n",
    "\n",
    "    # READING TIGER SHP: NY: takes 25s, about 15 parcels per census block\n",
    "    tiger_url = \"https://www2.census.gov/geo/tiger/TIGER2019/TABBLOCK/tl_2019_{}_tabblock10.zip\".format(statefips) \n",
    "    print(f'Reading Tiger shp {statefips=} {STATE_ABBRV=}')\n",
    "    state_blocks = gp.read_file(tiger_url)\n",
    "    state_blocks = state_blocks[['GEOID10', 'geometry']]\n",
    "    state_blocks = state_blocks.rename({\"GEOID10\": \"GEOID\"}, axis = 1)\n",
    "    state_blocks['cbg'] = state_blocks['GEOID'].str[:BLOCKGROUP_FIPS_LENGTH]\n",
    "    print(f\"{state_blocks.shape=}\")\n",
    "    \n",
    "    # NY= 2min: long time\n",
    "    state_parcels =  gp.GeoDataFrame(state_parcels, geometry=gp.points_from_xy(state_parcels.lon, state_parcels.lat, crs=state_blocks.crs)) \n",
    "    # BIG TIME BOTTLENECK: NY= 4min: also long time\n",
    "    state_parcels = gp.sjoin(state_parcels, state_blocks, how='left', predicate='within')\n",
    "    \n",
    "\n",
    "    # DISOWNED PARCELS: parcels with (lat, lon) not found within state boundaries i.e. parcels w/o GEOID!\n",
    "    disowned_parcels = state_parcels['GEOID'].isnull().sum()\n",
    "    print(f\"Number of disowned parcels: {disowned_parcels=}, {(disowned_parcels/state_parcels.shape[0] * 100) :.5f}%\")\n",
    "    # DIFF_CBG\n",
    "    diff_cbg = state_parcels.loc[ state_parcels['cbg_left'] != state_parcels['cbg_right']]\n",
    "    diff_cbg.shape # (61580, 8)\n",
    "    print(f\"Percentage of diff_cbg: {(diff_cbg.shape[0] / len(state_parcels) * 100):.2f} %\")\n",
    "    \n",
    "    # only need GEOID and func from now on\n",
    "    state_parcels = state_parcels[['GEOID', 'func']].copy()\n",
    "    \n",
    "    # parcel number addresses per census block\n",
    "    state_blocks['parcelNumAddr'] = state_blocks['GEOID'].map(state_parcels['GEOID'].value_counts()).fillna(value=np.nan)\n",
    "    state_blocks = state_blocks.dropna(subset=['parcelNumAddr'])\n",
    "    state_blocks['parcelNumAddr'] = state_blocks['parcelNumAddr'].astype(int)\n",
    "\n",
    "    def cat_func(func):\n",
    "        if func == 1:               return \"parcelNumResi\"\n",
    "        elif func == 9:             return \"parcelNumAgri\"\n",
    "        elif func in (2,3,5,7,8):   return \"parcelNumCommer\"\n",
    "        elif func in (4,6):         return \"parcelNumInfra\"\n",
    "        return \"parcelNumNull\"\n",
    "\n",
    "    state_parcels['func'] = state_parcels['func'].apply(cat_func)\n",
    "    state_parcels = state_parcels.groupby(['GEOID', 'func']).size().unstack(level=-1)\n",
    "    # Some individual parcelNum cols might be missing; fill them up in this case\n",
    "    parcelNumCols = ['parcelNumAgri', 'parcelNumCommer',  'parcelNumInfra', 'parcelNumNull', 'parcelNumResi']\n",
    "    for col in parcelNumCols:\n",
    "        if col not in state_parcels.columns:\n",
    "            state_parcels[col] = 0\n",
    "\n",
    "    # PROCESS the df to UPLOAD TO ES!\n",
    "    es_df = state_blocks.merge(state_parcels, how='left', left_on=\"GEOID\", right_index=True)\n",
    "    del state_blocks\n",
    "    del state_parcels\n",
    "    es_df = es_df[['GEOID', 'parcelNumAddr', 'parcelNumAgri', 'parcelNumCommer',  'parcelNumInfra', 'parcelNumNull', 'parcelNumResi']]\n",
    "    es_df['parcelNumAgri'] = es_df['parcelNumAgri'].fillna(0).astype(int)\n",
    "    es_df['parcelNumCommer'] = es_df['parcelNumCommer'].fillna(0).astype(int)\n",
    "    es_df['parcelNumInfra'] = es_df['parcelNumInfra'].fillna(0).astype(int)\n",
    "    es_df['parcelNumNull'] = es_df['parcelNumNull'].fillna(0).astype(int)\n",
    "    es_df['parcelNumResi'] = es_df['parcelNumResi'].fillna(0).astype(int)\n",
    "\n",
    "    # # NOTE: [another possibly simpler approach] can also just get the parcelNum individual fields first, then sum up to get parcelNumAddr\n",
    "    parcelNum_sum_check = es_df[['parcelNumAddr', 'parcelNumAgri', 'parcelNumCommer', 'parcelNumInfra', 'parcelNumNull', 'parcelNumResi']].sum()\n",
    "    if (parcelNum_sum_check[0] - sum(parcelNum_sum_check[1:]) != 0):\n",
    "        print(\"DOUBLE CHECK parcelNum fields: got wrong result for breaking down parcelNumAddr into smaller fields\")\n",
    "    else:\n",
    "        print(\"parcelNum: Sum checked is OK\")\n",
    "    \n",
    "\n",
    "    def faster_upload_df(df, index_name):\n",
    "        idCol = 'GEOID'\n",
    "        # updating_dict: a dict of all the data to be updated\n",
    "        updating_dict = df.to_json(orient = \"records\")\n",
    "        updating_dict = json.loads(updating_dict)\n",
    "\n",
    "        # create an actiondf for all actions\n",
    "        actiondf = df[[idCol]].copy()\n",
    "        actiondf['_op_type'] = 'update'\n",
    "        actiondf['_index'] = index_name\n",
    "        actiondf['_id'] = actiondf[idCol]\n",
    "        actiondf['doc_as_upsert'] = True\n",
    "        actiondf['doc'] = updating_dict \n",
    "        actiondf.drop(idCol, axis = 1, inplace = True)\n",
    "\n",
    "        udf = actiondf.to_json(orient = 'records')\n",
    "        # all actions\n",
    "        action_list = json.loads(udf) \n",
    "        print(f\"Start uploading {len(df)} records to {index_name}\")\n",
    "        helpers.bulk(es, action_list)\n",
    "        print(f\"Completed uploading {len(df)} records to {index_name}\")\n",
    "\n",
    "    # # FOR TESTING\n",
    "    # test = es_df[['GEOID', 'parcelNumAddr', \"parcelNumAgri\"]].copy()\n",
    "    # test['parcelNumAddr'] = 44\n",
    "    # test[\"parcelNumResi\"] = 55\n",
    "    # index_name = 'nhat_test_1'\n",
    "    # faster_upload_df(test, index_name) # 45seconds! 16x faster than previous upload method\n",
    "    \n",
    "    # null check before uploading\n",
    "    if sum(es_df.isnull().sum()) == 0:\n",
    "        # ACTUAL UPLOAD\n",
    "        index_name = f'bossdata{statefips}'\n",
    "        faster_upload_df(es_df, index_name) \n",
    "    else:\n",
    "        # save to file\n",
    "        temp = f'/home/nhat/temp/numAddr_{statefips}.json'\n",
    "        es_df.to_json(temp, orient='records')\n",
    "        print(f\"Error: es_df still has {sum(es_df.isnull().sum())} null values; saved es_df to {temp}.\")\n",
    "    \n",
    "    return es_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d155d2f-801c-4f5f-b782-9b08ff8a5a85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
