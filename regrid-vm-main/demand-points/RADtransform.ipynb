{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c78cd5b5-8d43-4e39-b8f9-8827e9d616e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T05:05:04.505272Z",
     "iopub.status.busy": "2022-06-15T05:05:04.504824Z",
     "iopub.status.idle": "2022-06-15T05:05:05.820779Z",
     "shell.execute_reply": "2022-06-15T05:05:05.820316Z",
     "shell.execute_reply.started": "2022-06-15T05:05:04.505249Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import geopandas as gp\n",
    "import h3\n",
    "import h3pandas\n",
    "from placekey.api import PlacekeyAPI\n",
    "from keplergl import KeplerGl\n",
    "\n",
    "from glob import glob\n",
    "from multiprocess import Pool\n",
    "from unsync import unsync\n",
    "import gzip \n",
    "from zipfile import ZipFile as ZF\n",
    "from shapely.geometry import shape\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# 50 states + DC + 6 territories (PR, VI, AS, GU, MP, UM)\n",
    "SF57 = {'01': 'AL', '02': 'AK', '04': 'AZ', '05': 'AR', '06': 'CA', '08': 'CO', '09': 'CT', '10': 'DE', '11': 'DC', '12': 'FL', '13': 'GA', '15': 'HI', '16': 'ID', '17': 'IL', '18': 'IN', '19': 'IA', '20': 'KS', '21': 'KY', '22': 'LA', '23': 'ME', '24': 'MD', '25': 'MA', '26': 'MI', '27': 'MN', '28': 'MS', '29': 'MO', '30': 'MT', '31': 'NE', '32': 'NV', '33': 'NH', '34': 'NJ', '35': 'NM', '36': 'NY', '37': 'NC', '38': 'ND', '39': 'OH', '40': 'OK', '41': 'OR', '42': 'PA', '44': 'RI', '45': 'SC', '46': 'SD', '47': 'TN', '48': 'TX', '49': 'UT', '50': 'VT', '51': 'VA', '53': 'WA', '54': 'WV', '55': 'WI', '56': 'WY', '60': 'AS', '66': 'GU', '69': 'MP', '72': 'PR', '74': 'UM', '78': 'VI'}\n",
    "SF57R = {value : key for (key, value) in SF57.items()}\n",
    "\n",
    "def gen_h3_hex_vectors(lat, lon, res):\n",
    "    return h3.geo_to_h3(lat, lon, res)\n",
    "gen_h3_hex = np.vectorize(gen_h3_hex_vectors)\n",
    "\n",
    "# FYI: h3.h3_indexes_are_neighbors(\"X1\", \"X1\") = False (i.e. a hex cell is not neighbor with itself)\n",
    "# aside: h3.k_ring(\"8843a13687fffff\", 1) # find all neighbors in ring_size=1\n",
    "def h3_nei_conditions(hex1, hex2):\n",
    "    return h3.h3_indexes_are_neighbors(hex1, hex2) # boolean\n",
    "h3_nei_vector = np.vectorize(h3_nei_conditions)\n",
    "\n",
    "\n",
    "attom_sel_cols = ['[ATTOM ID]',     \n",
    "    'LegalDescription', 'OwnerTypeDescription1', 'ParcelNumberRaw', \n",
    "    'PartyOwner1NameFull', 'PartyOwner2NameFull', \n",
    "    'PropertyAddressCity', \n",
    "    'PropertyAddressFull', \n",
    "    'PropertyAddressHouseNumber', 'PropertyAddressStreetDirection', 'PropertyAddressStreetName', \n",
    "    'PropertyAddressStreetPostDirection', 'PropertyAddressStreetSuffix', 'PropertyAddressUnitPrefix', 'PropertyAddressUnitValue', \n",
    "    'PropertyAddressZIP', \n",
    "    'PropertyLatitude', 'PropertyLongitude',]\n",
    "\n",
    "# NOTE: geom = WTK string/object type; geometry = geopandas geometry type\n",
    "CRS_REGRID_PARCELS = \"EPSG:4326\"\n",
    "\n",
    "regrid_sel_cols = ['ll_uuid', \n",
    "    'address', \n",
    "   'address2', # i.e. alternative address for same parcel\n",
    "   # 'original_address', # confirmed: all useless when (~address & original_address)\n",
    "               'legaldesc', 'parcelnumb', \n",
    "    'saddno', 'saddpref', 'saddstr', 'saddsttyp', 'saddstsuf', 'sunit' ,\n",
    "    'scity', 'szip', 'lat', 'lon', \n",
    "    'owner', 'owner2', ]\n",
    "\n",
    "def owner_compare(df_compare, left, right):\n",
    "    # only keep alphanumeric values ; note the additions of symbols\n",
    "    keepchars = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\" + \",& \"\n",
    "    del_chars = ''.join(c for c in map(chr, range(1114111)) if not c in set(keepchars))\n",
    "    # convert uppercases to lowercases\n",
    "    keepchars_table = str.maketrans(keepchars, keepchars.lower(), del_chars)\n",
    "\n",
    "    df_compare['owners'] = df_compare[left].str.translate(keepchars_table).str.split(',|&| ')\n",
    "    df_compare['Owners'] = df_compare[right].str.translate(keepchars_table).str.split(',|&| ')\n",
    "\n",
    "    def owners_combine(owners, Owners):\n",
    "        if owners is not np.nan and Owners is not np.nan:\n",
    "            seta = {own for own in owners if len(own) > 1}\n",
    "            setb = {own for own in Owners if len(own) > 1}\n",
    "            return True if seta.intersection(setb) else False\n",
    "        return True\n",
    "    owners_combine_vectorize = np.vectorize(owners_combine)\n",
    "    return owners_combine_vectorize(df_compare['owners'], df_compare['Owners'])\n",
    "\n",
    "attom_pk_maps = {\n",
    "    'aid' : 'query_id', # unique row id\n",
    "    'Lat' : 'latitude', \n",
    "    'Lon' : 'longitude', \n",
    "    'Address1' : 'street_address', # NOTE: using address1\n",
    "    'ACity' : 'city',\n",
    "    'AZip' : 'postal_code',\n",
    "}\n",
    "\n",
    "regrid_pk_maps = {\n",
    "    'rid' : 'query_id', # unique row id\n",
    "    'lat' : 'latitude', \n",
    "    'lon' : 'longitude', \n",
    "    'address1' : 'street_address', # NOTE: using address1\n",
    "    'scity' : 'city',\n",
    "    'szip' : 'postal_code', # e.g. 48103, 48104-3423\n",
    "}\n",
    "\n",
    "pk_api1 = PlacekeyAPI(\"NDd0VsiPKznvm89NLNj9DHrtU3GVzZ1h\" )\n",
    "pk_api2 = PlacekeyAPI(\"50L6WAI5cSUz1gJ3qzr2AwQxANKP3Ty1\" )\n",
    "\n",
    "#  https://github.com/alex-sherman/unsync#multi-threading-an-io-bound-function\n",
    "# Iterative API calls= slow! Use unsync that simplifies ThreadPoolExecutor's async tasks\n",
    "@unsync\n",
    "def pk_call(df, maps, orig_id, pk_api):\n",
    "    def gen_placekey_df(df, maps):\n",
    "        keep_cols = list(maps.values())\n",
    "        # only need placekey cols\n",
    "        # drop columns with names similar to Placekey required columns\n",
    "        df = df.drop(columns=keep_cols, \n",
    "                     errors='ignore').rename(columns=maps)[keep_cols]\n",
    "\n",
    "        # zipcode = 00000 means null; ATTOM zipcode could be a float, or None, \"\"\n",
    "        # so, need a placeholder value to convert to int, zfill, back to np.nan\n",
    "        NAN_ZIPS = \"00000\"\n",
    "        df['postal_code'] = df['postal_code'].fillna(NAN_ZIPS).astype(int).astype(str).str.zfill(5).replace(NAN_ZIPS, np.nan)\n",
    "        # print(\"Generated pk df \", df.shape)\n",
    "        \n",
    "        # OPTIONAL CLEANING\n",
    "        possible_bad_values = [\"\", \" \", \"null\", \"Null\", \"None\", \"nan\", \"Nan\"]  \n",
    "        for bad_value in possible_bad_values:\n",
    "            df = df.replace(bad_value, np.nan)\n",
    "        # replace NoneType with np.nan    \n",
    "        df.fillna(np.nan, inplace=True)\n",
    "        return df    \n",
    "    \n",
    "    # Placekey API lookup function\n",
    "    \n",
    "    def pk_lookup(df, pk_api):\n",
    "        # add missing hard-coded columns (str type)\n",
    "        df['iso_country_code'] = 'US' \n",
    "        # sf_code has GLOBAL SCOPE\n",
    "        df['region'] = sf_code.upper()    \n",
    "        df = json.loads(df.to_json(orient='records'))\n",
    "        # Rate limit: 100 bulk req per min x 100 addrs per bulk req\n",
    "        # i.e. 10,000 addr per min \n",
    "        responses =  pk_api.lookup_placekeys(df, \n",
    "                                        strict_address_match=False,\n",
    "                                        strict_name_match=False, \n",
    "                                        # verbose=True,\n",
    "                                       )\n",
    "        # Clean the responses\n",
    "        # print(\"number of requests sent: \", len(df))\n",
    "        # print(\"total queries returned:\", len(responses))\n",
    "        # filter out invalid responses\n",
    "        responses_cleaned = [resp for resp in responses if 'query_id' in resp]\n",
    "        # print(\"total successful responses:\", len(responses_cleaned))\n",
    "        return pd.read_json(json.dumps(responses_cleaned), dtype={'query_id':str})\n",
    "    \n",
    "    \n",
    "    # TODO opt: groupby address1+hex7: avoid duplicate Placekey API request!\n",
    "    # assumption: there should be no duplicate address1 within same ahex7 (within 5km2)\n",
    "    # will not filter: same addr & adjacent ahex7 - placekey API will verify!\n",
    "    # FAILED: concat address with zip, eliminate repeated address (https://www.quora.com/Do-any-two-locations-with-the-same-street-address-also-have-the-same-ZIP-code)\n",
    "    # also, groupby fails when zip is null!\n",
    "    df_pk = gen_placekey_df(df, maps)\n",
    "    \n",
    "    # API REQUEST\n",
    "    pk_res =  pk_lookup(df_pk.copy(), pk_api) # # (148_487, 6) around 15min\n",
    "    # Show API responses errors\n",
    "    if \"error\" in set(pk_res):\n",
    "        print(orig_id, \"# responses: \", pk_res.shape, \"; responses errors: \")\n",
    "        print(pk_res.error.value_counts())\n",
    "    # split into 2 components -- only interest in results with pkwhat\n",
    "    # this also filters rows with error i.e. no placekey\n",
    "    pk_res[['pkwhat', 'pkwhere']] = pk_res.placekey.str.split(\n",
    "        \"@\", expand=True).replace(\"\", np.nan)\n",
    "   \n",
    "    # Save API responses!!\n",
    "    pk_res.reset_index(drop=True).to_feather(f'placekeyed/{orig_id}_{sf_code}.ftr')\n",
    "    \n",
    "    # keep only results whith pkwhat components\n",
    "    pk_res = pk_res[pk_res.pkwhat.notna()]\n",
    "    # Merge with original df; keep only rows with placekey results\n",
    "    df = pd.merge(df, pk_res, left_on = orig_id, \n",
    "      right_on=\"query_id\", how='inner').drop(columns= ['query_id', 'error'], errors='ignore')\n",
    "    return df\n",
    "\n",
    "\n",
    "def regrid_landuse_classifier(acti, func, struc, site):\n",
    "    # REGRID LAND USE CLASSIFICATION\n",
    "    if 1 in (acti, func, struc):\n",
    "        return 'resi'\n",
    "    if 2 in (acti, func, struc) or func in set('357') or acti in set('357'):\n",
    "        return 'biz'\n",
    "    if 8 in (acti, struc) or func == 9: \n",
    "        return 'farm'\n",
    "    if 4 in (acti, func) or 6 in (acti, func) or struc in set('34567'):\n",
    "        return 'CAI'\n",
    "    if site != 6: # no developed site on land\n",
    "        return 'vacland'    \n",
    "    return 'rem' # ALL OTHER LANDUSE GROUPS   \n",
    "\n",
    "\n",
    "def rad_fields_vec(rid, aid, address1, addressSub, Address1, AddressSub, lat, lon, Lat, Lon, owner, owner2, Owner, Owner2):\n",
    "    pId = rId = pAddress1 = pAddressSub = pOwner = pLat = pLon = np.nan\n",
    "    \n",
    "    rlist = [rid, address1, addressSub, lat, lon, owner, owner2]\n",
    "    for r, addr1, addrSub, la, lo, own, own2 in zip(*rlist):\n",
    "        pId = rId = r\n",
    "        if addr1 is not None and addr1 == addr1: # not None, not na\n",
    "            pId = rId = r\n",
    "            pAddress1, pAddressSub = addr1, addrSub\n",
    "        if la is not None and lo is not None and la == la and lo == lo:\n",
    "            pLat, pLon = la, lo\n",
    "        if own is not None and own == own:\n",
    "            pOwner = own\n",
    "        elif own2 is not None and own2 == own2:\n",
    "            pOwner = own2\n",
    "        if np.nan not in (pId, rId, pAddress1, pAddressSub, pOwner, pLat, \n",
    "           pLon):\n",
    "            return \"\\t\".join([str(k) for k in [pId, rId, pAddress1, pAddressSub, pOwner, pLat, pLon]])\n",
    "\n",
    "    alist = [aid, Address1, AddressSub, Lat, Lon, Owner, Owner2]\n",
    "    for a, addr1, addrSub, la, lo, own, own2 in zip(*alist):\n",
    "        if pId != pId: # if have seen no regrid parcel \n",
    "            pId = a\n",
    "        if pAddress1 != pAddress1 and addr1 is not None and addr1 == addr1: # not na\n",
    "            pId = a # rId would still be Nan, or equal to a previous rid\n",
    "            pAddress1, pAddressSub = addr1, addrSub\n",
    "        if pLat != pLat and pLon != pLon and la is not None and lo is not None and la == la and lo == lo:\n",
    "            pLat, pLon = la, lo\n",
    "        if pOwner != pOwner and own is not None and own == own:\n",
    "            pOwner = own\n",
    "        elif pOwner != pOwner and own2 is not None and own2 == own2:\n",
    "            pOwner = own2\n",
    "        if np.nan not in (pId, rId, pAddress1, pAddressSub, pOwner, pLat, \n",
    "           pLon):\n",
    "            return \"\\t\".join([str(k) for k in [pId, rId, pAddress1, pAddressSub, pOwner, pLat, pLon]])\n",
    "    return \"\\t\".join([str(k) for k in [pId, rId, pAddress1, pAddressSub, pOwner, pLat, pLon]])\n",
    "\n",
    "def rad_landuse_classifier_single(alanduse, rlanduse):\n",
    "    # Higher to lower prioritization\n",
    "    if alanduse in ('CAI', 'biz', 'resi'): # also in order of priority\n",
    "        return alanduse\n",
    "    if rlanduse in ('CAI', 'biz', 'resi'): # also in order of priority\n",
    "        return rlanduse\n",
    "    for weak in ('farm', 'vacland', 'rem'): # also in order of priority\n",
    "        if weak in set((alanduse, rlanduse)):\n",
    "            return weak\n",
    "\n",
    "SORT_ORDER = {'CAI': 10, 'biz': 9, 'resi': 8, 'farm': 7, 'vacland': 6, 'rem': 5, np.nan: 4}\n",
    "def rad_landuse_classifier_many(uses):\n",
    "    # RAD LAND USE CLASSIFICATION: reconciling [many] ATTOM <> [many] REGRID\n",
    "    c = Counter(uses).most_common()\n",
    "    # note: negative signs! descending by counts, then descending by SORT_ORDER (for breaking tie)\n",
    "    landuse_orders = sorted(c, key = lambda x: (-x[1], -SORT_ORDER[x[0]]))\n",
    "    for value, count in landuse_orders:\n",
    "        if value not in ('vacland', 'rem', np.nan):\n",
    "            return value\n",
    "    if 'vacland' in set([k[0] for k in landuse_orders]): \n",
    "        return 'vacland'\n",
    "    return 'rem'\n",
    "\n",
    "def addr_fields_join(*args):\n",
    "    args = [str(i).strip() for i in args]\n",
    "    return \" \".join(i for i in args if (i and i != 'nan' and i != 'None'))\n",
    "addr_fields_join_vectorize = np.vectorize(addr_fields_join)\n",
    "\n",
    "\n",
    "# only keep alphanumeric values; use to clean:\n",
    "# ['LegalDescription', 'ParcelNumberRaw'] and ['legaldesc', 'parcelnumb']\n",
    "keepchars = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\"\n",
    "del_chars = ''.join(c for c in map(chr, range(1114111)) if not c in set(keepchars))\n",
    "# convert lowercases to uppercases\n",
    "legal_number_translate_table = str.maketrans(keepchars, keepchars.upper(), del_chars)\n",
    "\n",
    "\n",
    "government = [\"Government\", \"Justice\", \"Library\", \"Department\", \"Administration\",\"Dept of\", \"City of\", \"Dept of\", \n",
    "              \"Town of\", \"Commission\", \"National Foundation\",  \"Child Abuse\", \"Courthouse\", \"Department of \", \n",
    "              \"Leadership\", \"Authority\",\"Adoptions\", \"Prison\",\"Veteran\", \"Chamber of\", \"Municipal\",\"Child Support\"]\n",
    "religious = [\"Church\", \"Baptist\",\"Baptist Association\",\"Christ\",\"Family Harvest\"]\n",
    "community = [\"Communications Workers Of America\", \"Veteran\", \"Community Center\", \"Community\"]\n",
    "education = [\"High School\", \"Elementary School\", \"Education\",\"College\", \n",
    "                    \"University\", \"Pre-School\",\"Middle School\", \"School\"]\n",
    "outdoor = [\"Garden\", \"Zoo\", \"Park\", \"Recreation\", \"Stadium\", \"Memorial\", \n",
    "           \"Outlook\", \"Overlook\", \"Pavilion\", \"Square\", \"Field\", \"Resort\"]\n",
    "\n",
    "stopcats = ['PERSONAL SERVICES',  'EATING - DRINKING', 'SHOPPING', \n",
    "       'AUTOMOTIVE SERVICES',  'BANKS - FINANCIAL', 'PET SERVICES']\n",
    "keywords = {\n",
    "    \"health\": [\"Medical Center\",\"Hospital\",\"Clinic\",\"Family Care\", \n",
    "                 # \"Rehab\"\n",
    "                ],\n",
    "    \"education\": education, \"government\": government, \"community\": community, \n",
    "    \"religious\": religious, \"outdoor\": outdoor,\n",
    "}\n",
    "\n",
    "STOP_PARTS = [\"LLC\", \"Llc\", \"inc\", \"Inc\", \"INC\"]\n",
    "stopwords = {\n",
    "    \"health\":     STOP_PARTS + [\"Hospitality\", \"Hospitalities\", \"Schools\", \"Animal\", \"Pet\"],\n",
    "    \"education\":  STOP_PARTS + [\"Hospital\"],\n",
    "    \"government\": STOP_PARTS + [\"Department Store\"],\n",
    "    \"community\":  STOP_PARTS,\n",
    "    \"religious\":  STOP_PARTS,\n",
    "    \"outdoor\":    STOP_PARTS,\n",
    "}\n",
    "caikeys = {\n",
    "    \"health\": [\"Medical Center\",\"Hospital\",\"Family Care\"],\n",
    "    \"education\": education, \"government\": government, \"community\": community, \n",
    "    \"religious\": religious, \"outdoor\": outdoor,\n",
    "}\n",
    "\n",
    "def getcai(dfinput, category):\n",
    "    #STEP 1. use the name key word\n",
    "    df = dfinput[dfinput[\"BUSNAME\"].str.contains(\"|\".join(keywords[category]))]\n",
    "    #2.  remove the ones that contain the stop word\n",
    "    df = df[~df[\"BUSNAME\"].str.contains(\"|\".join(stopwords[category]))]\n",
    "    df = df[~df[\"CATEGORY\"].isin(stopcats)]\n",
    "    # 3. Find the CAI\n",
    "    caidf = df[df[\"BUSNAME\"].str.contains(\"|\".join(caikeys[category]))]\n",
    "    return caidf, df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5af5da0-8ab8-4135-97bf-4f533d4d8e64",
   "metadata": {},
   "source": [
    "# STATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "972d3a95-d55a-42a1-94a8-b850af7f9448",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T04:57:19.524125Z",
     "iopub.status.busy": "2022-06-15T04:57:19.523573Z",
     "iopub.status.idle": "2022-06-15T04:57:19.530530Z",
     "shell.execute_reply": "2022-06-15T04:57:19.530181Z",
     "shell.execute_reply.started": "2022-06-15T04:57:19.524101Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('11', 'DC')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf_code = \"DC\"\n",
    "sf = SF57R[sf_code]\n",
    "sf, sf_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79d6f5d-d58b-4991-80f1-2bfd4fb06ad4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T07:47:26.428670Z",
     "iopub.status.busy": "2022-06-14T07:47:26.428347Z",
     "iopub.status.idle": "2022-06-14T07:47:26.431363Z",
     "shell.execute_reply": "2022-06-14T07:47:26.430970Z",
     "shell.execute_reply.started": "2022-06-14T07:47:26.428645Z"
    }
   },
   "source": [
    "## ATTOM STATE FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0d73761-f3cd-4d65-8836-ad48559e9802",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T04:57:23.874229Z",
     "iopub.status.busy": "2022-06-15T04:57:23.873947Z",
     "iopub.status.idle": "2022-06-15T04:57:25.367002Z",
     "shell.execute_reply": "2022-06-15T04:57:25.366592Z",
     "shell.execute_reply.started": "2022-06-15T04:57:23.874208Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213079, 18)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_feathers = glob(f\"attom/data/attom-feather/{sf_code}_*.ftr\")\n",
    "# print(len(list_of_feathers)) \n",
    "with Pool(16) as pool:\n",
    "    attom = pool.map(lambda feather_file: pd.read_feather(feather_file, columns=attom_sel_cols), list_of_feathers)\n",
    "    attom = pd.concat(attom, ignore_index=True)    \n",
    "attom = attom.rename(columns= {\n",
    "    '[ATTOM ID]': 'aid',\n",
    "    'PropertyAddressFull' : 'Address',\n",
    "    'LegalDescription' : 'Legal', \n",
    "    'ParcelNumberRaw' : 'Numb', \n",
    "    'PartyOwner1NameFull' : \"Owner\",\n",
    "    'PartyOwner2NameFull' : 'Owner2',\n",
    "    'PropertyAddressCity' : \"ACity\",\n",
    "    'PropertyAddressZIP' : 'AZip',\n",
    "    'PropertyLatitude' : 'Lat',\n",
    "    'PropertyLongitude' : 'Lon', \n",
    "})\n",
    "attom.shape # (3_330_480, 18) in 15sec; DC = (213_079, 18) 2sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1dacab0-6352-4548-8ebe-cd3dafdb0476",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T04:57:26.801451Z",
     "iopub.status.busy": "2022-06-15T04:57:26.800938Z",
     "iopub.status.idle": "2022-06-15T04:57:27.712561Z",
     "shell.execute_reply": "2022-06-15T04:57:27.712119Z",
     "shell.execute_reply.started": "2022-06-15T04:57:26.801430Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Address1 and AddressSub columns: 10sec\n",
    "attom['Address1'] = addr_fields_join_vectorize(attom.PropertyAddressHouseNumber,\n",
    "    attom.PropertyAddressStreetDirection,\n",
    "    attom.PropertyAddressStreetName,\n",
    "    attom.PropertyAddressStreetSuffix,\n",
    "    attom.PropertyAddressStreetPostDirection)\n",
    "\n",
    "attom['AddressSub'] = addr_fields_join_vectorize(attom.PropertyAddressUnitPrefix,\n",
    "    attom.PropertyAddressUnitValue,)\n",
    "\n",
    "for col in ['Legal', 'Numb']:\n",
    "    attom[col] = attom[col].str.translate(legal_number_translate_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a684e41-c010-4865-98a7-27b380b75615",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T04:57:27.713599Z",
     "iopub.status.busy": "2022-06-15T04:57:27.713396Z",
     "iopub.status.idle": "2022-06-15T04:57:28.819469Z",
     "shell.execute_reply": "2022-06-15T04:57:28.819033Z",
     "shell.execute_reply.started": "2022-06-15T04:57:27.713582Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for bad_value in [\"\", \"None\"]:\n",
    "    attom.replace(bad_value, np.nan, inplace = True)\n",
    "attom.fillna(np.nan, inplace=True)  # replace python NoneType with np.nan\n",
    "\n",
    "cols = [\"Lat\", \"Lon\"]\n",
    "attom[cols] = attom[cols].astype(float)\n",
    "\n",
    "# Hotfix bad raw data = If Address1 null, set addr = address1\n",
    "attom['Address1'] = np.where(\n",
    "    attom.Address.notna() & attom.Address1.isna(), \n",
    "    attom['Address'], attom['Address1'])\n",
    "# If addr1 = addr, set addr2 = empty\n",
    "attom['AddressSub'] = np.where(\n",
    "    attom.Address == attom.Address1, \n",
    "    np.nan, attom['AddressSub'])\n",
    "\n",
    "\n",
    "# Sanity check: when Address is null, no other addr subfields exist!\n",
    "cols = [\n",
    "    'Address','Address1', 'AddressSub',\n",
    "    'PropertyAddressHouseNumber','PropertyAddressStreetDirection',\n",
    "    'PropertyAddressStreetName','PropertyAddressStreetPostDirection',\n",
    "    'PropertyAddressStreetSuffix','PropertyAddressUnitPrefix','PropertyAddressUnitValue',\n",
    "]\n",
    "check_address = set(attom.query(\"Address != Address\")[cols].count()) == {0} \n",
    "if not check_address:\n",
    "    print(\"ALERT: : when Address is null, no other addr subfields should exist!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1085293-5187-4f72-8be2-9e97179e7acd",
   "metadata": {},
   "source": [
    "# REGRID STATE FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d8a4756-9a8a-4329-a4ae-79bd75529719",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T04:57:29.523615Z",
     "iopub.status.busy": "2022-06-15T04:57:29.523126Z",
     "iopub.status.idle": "2022-06-15T04:57:29.526575Z",
     "shell.execute_reply": "2022-06-15T04:57:29.526227Z",
     "shell.execute_reply.started": "2022-06-15T04:57:29.523593Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('11', 'DC')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf_code = \"DC\"\n",
    "sf = SF57R[sf_code]\n",
    "sf, sf_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a69d4a19-98dc-4f59-bd85-cb593fc9927b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T04:57:29.992086Z",
     "iopub.status.busy": "2022-06-15T04:57:29.991589Z",
     "iopub.status.idle": "2022-06-15T04:57:32.706379Z",
     "shell.execute_reply": "2022-06-15T04:57:32.705943Z",
     "shell.execute_reply.started": "2022-06-15T04:57:29.992063Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137403, 17)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_regrid_feathers = glob(f\"attom/data/regrid-feather/{sf_code.lower()}_*.ftr\")\n",
    "with Pool(16) as pool:\n",
    "    regrid = pool.map(lambda feather_file: pd.read_feather(feather_file, columns=regrid_sel_cols), list_of_regrid_feathers)\n",
    "    regrid = pd.concat(regrid, ignore_index=True)    \n",
    "# when sf_code = DC: no parcel has legaldesc\n",
    "regrid[['legaldesc', 'parcelnumb']] = regrid[['legaldesc', 'parcelnumb']].astype(str) \n",
    "\n",
    "regrid.rename(columns={'ll_uuid' : 'rid', 'sunit' : 'addressSub'}, inplace=True)\n",
    "regrid.fillna(np.nan, inplace=True) \n",
    "\n",
    "# Fix small Bad data#1: paste address2 to adress (7, 17)\n",
    "regrid['address'] = np.where(regrid['address'].isna() & regrid['address2'].notna(),\n",
    "                             regrid['address2'], regrid['address'])\n",
    "mask = regrid.address.isin(['NO ADDRESS ASSIGNED BY COUNTY', 'No Situs Address'])\n",
    "# Fix bad bad data#2: hardcoded empty addresses\n",
    "regrid.loc[mask, \n",
    "    ['address', 'addressSub', 'saddno', 'address2',  \n",
    "     'saddpref', 'saddstr', 'saddsttyp', 'saddstsuf' ]] = np.nan\n",
    "regrid.shape # (3330480, 18) in 15sec ## NEW as of Jun3, (3_219_695, 17); DC = (137_403, 17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b87ed86-4fc8-4409-825b-94adb041990e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T04:57:32.707582Z",
     "iopub.status.busy": "2022-06-15T04:57:32.707369Z",
     "iopub.status.idle": "2022-06-15T04:57:33.835746Z",
     "shell.execute_reply": "2022-06-15T04:57:33.835316Z",
     "shell.execute_reply.started": "2022-06-15T04:57:32.707563Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "regrid['address1'] = addr_fields_join_vectorize(\n",
    "    regrid.saddno, regrid.saddpref, regrid.saddstr, regrid.saddsttyp, regrid.saddstsuf)\n",
    "\n",
    "regrid.address1.replace(\"\", np.nan, inplace=True)\n",
    "# Hotfix inconsistent address fields\n",
    "regrid.loc[regrid.address.isna() & regrid.address1.notna(), \"address\"] = regrid.address1\n",
    "regrid.loc[regrid.address.notna() & regrid.address1.isna() & regrid.address1.isna(), \n",
    "          ['address', 'address1', 'addressSub',]] = np.nan\n",
    "\n",
    "regrid['szip'] = regrid.szip.str.replace(r'\\D+', '', regex = True).str[:5]\n",
    "regrid.szip.mask(regrid.szip.str.len() != 5, inplace=True)\n",
    "\n",
    "# Sanity check: when Address is null, no other addr subfields exist!\n",
    "cols = ['address', 'address1', 'addressSub', 'saddno', 'saddpref', \n",
    "                    'saddstr', 'saddsttyp', 'saddstsuf']\n",
    "check_address = set(regrid.query(\"address != address\")[cols].count()) == {0} \n",
    "if not check_address:\n",
    "    print(\"ALERT: : when Address is null, no other addr subfields should exist!\")\n",
    "\n",
    "# Coords should have float types\n",
    "cols = ['lat', 'lon',]\n",
    "regrid[cols] = regrid[cols].astype(float)\n",
    "\n",
    "for col in ['legaldesc', 'parcelnumb']:\n",
    "    regrid[col] = regrid[col].str.translate(legal_number_translate_table)\n",
    "\n",
    "# At this point, legaldesc and parcelnumb could be \"\"\n",
    "regrid.replace(\"\", np.nan, inplace=True)\n",
    "\n",
    "all_possible_bad_values = [\"\", \" \", \"null\", \"Null\", \"None\", \"NONE\", \"none\", \"nan\", \"Nan\"] \n",
    "for bad_value in all_possible_bad_values:\n",
    "    regrid.replace(bad_value, np.nan, inplace = True)\n",
    "    \n",
    "if regrid[['lat', 'lon']].isna().sum().sum() != 0:\n",
    "    print(\"ALERT: regrid_df contains null coords lat/lon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cfd0f1a5-4f02-4740-80a4-74fb88944ede",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T07:42:09.261954Z",
     "iopub.status.busy": "2022-06-15T07:42:09.261687Z",
     "iopub.status.idle": "2022-06-15T07:42:09.313272Z",
     "shell.execute_reply": "2022-06-15T07:42:09.312806Z",
     "shell.execute_reply.started": "2022-06-15T07:42:09.261933Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aid            0\n",
       "Address1    1602\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attom[['aid', 'Address1']].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a016c6c7-234f-4dd6-8874-911225f31375",
   "metadata": {},
   "source": [
    "# Add h3 hex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9a53569-d55b-495b-af29-eabd4b1982bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T04:57:33.836788Z",
     "iopub.status.busy": "2022-06-15T04:57:33.836586Z",
     "iopub.status.idle": "2022-06-15T04:57:35.076640Z",
     "shell.execute_reply": "2022-06-15T04:57:35.076224Z",
     "shell.execute_reply.started": "2022-06-15T04:57:33.836771Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: ATTOM contains 650 null lat/lon rows, whose h3hex = '0'\n"
     ]
    }
   ],
   "source": [
    "for res in [7, 13]:\n",
    "    # res 7 = length=15, last 6 chars = ffffff; area~5 km2\n",
    "    # MO 24sec\n",
    "    attom[f'ahex{res}']= gen_h3_hex(attom['Lat'], attom['Lon'],  res)\n",
    "    regrid[f'rhex{res}']= gen_h3_hex(regrid['lat'], regrid['lon'],  res)\n",
    "\n",
    "attom_no_coords = attom.groupby(\"ahex7\").size()[0] # 6669\n",
    "if attom_no_coords:\n",
    "    print(f\"NOTE: ATTOM contains {attom_no_coords} null lat/lon rows, whose h3hex = '0'\")\n",
    "\n",
    "# dup columns check\n",
    "if (set(attom.columns.duplicated()), set(regrid.columns.duplicated())) != ({False}, {False}):\n",
    "    print(\"ALERT: attom/regrid contains duplicate column names\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe7736a-676e-4e33-8339-ccf52af26196",
   "metadata": {},
   "source": [
    "# RAD2: reconcile REGRID and ATTOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4ec4e8e7-c1f1-4aec-bc2d-3d3270c52a75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T08:31:40.855931Z",
     "iopub.status.busy": "2022-06-14T08:31:40.855632Z",
     "iopub.status.idle": "2022-06-14T08:31:40.859654Z",
     "shell.execute_reply": "2022-06-14T08:31:40.859295Z",
     "shell.execute_reply.started": "2022-06-14T08:31:40.855907Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((213079, 22), (137403, 20), set())"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attom.shape, regrid.shape, set(attom).intersection(set(regrid)) # set() iff no shared column names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e40d781-aed4-46c2-89cd-c14a6efcd30a",
   "metadata": {},
   "source": [
    "# 1. Uniq legaldesc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5d7ae61-b0b2-4203-9de5-234eae3f02bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T04:57:37.711702Z",
     "iopub.status.busy": "2022-06-15T04:57:37.711431Z",
     "iopub.status.idle": "2022-06-15T04:57:38.023445Z",
     "shell.execute_reply": "2022-06-15T04:57:38.023061Z",
     "shell.execute_reply.started": "2022-06-15T04:57:37.711682Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 42)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IMPORTANT: first, drop the duplicate values\n",
    "regrid_legal_uniq = regrid.drop_duplicates(subset='legaldesc', keep=False)\n",
    "attom_legal_uniq = attom.drop_duplicates(subset='Legal', keep=False)\n",
    "legal_matched = attom_legal_uniq.merge(regrid_legal_uniq, left_on = 'Legal', right_on = 'legaldesc', how = 'inner')\n",
    "del regrid_legal_uniq, attom_legal_uniq\n",
    "# MO (1_620_809, 42), as of Jun3 (1_604_138, 42)\n",
    "# DC (0, 42), because REGRID DC has no legaldesc\n",
    "legal_matched.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fba8e1f9-4ddd-466b-b4cb-5b6207b4067e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T04:57:38.113772Z",
     "iopub.status.busy": "2022-06-15T04:57:38.113514Z",
     "iopub.status.idle": "2022-06-15T04:57:38.118185Z",
     "shell.execute_reply": "2022-06-15T04:57:38.117813Z",
     "shell.execute_reply.started": "2022-06-15T04:57:38.113753Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "legal_diff = pd.DataFrame().reindex_like(legal_matched)\n",
    "if len(legal_matched):\n",
    "    # MO = 13sec\n",
    "    # Create new column that compares owner <> Owner\n",
    "    legal_matched['owner_compare'] = owner_compare(legal_matched, 'owner', 'Owner')\n",
    "    legal_diff = legal_matched.query(\n",
    "        \"parcelnumb.notna() & Numb.notna() & parcelnumb != Numb\" \n",
    "        \"& address.notna() & Address.notna() & address != Address\"\n",
    "        \"& address1.notna() & Address1.notna() & address1 != Address1\"\n",
    "        \"& rhex7 != '0' & ahex7 != '0' & rhex7 != ahex7\" \n",
    "        \"& owner.notna() & Owner.notna() & (~owner_compare)\"    \n",
    "    , engine = \"python\")\n",
    "\n",
    "    print(\"legal_diff shape \", legal_diff.shape) # (87, 45), as of Jun3 (102, 45)\n",
    "    legal_diff[[ 'owner', 'owner2',  'Owner', 'Owner2', 'address1', 'Address1', 'parcelnumb', 'Numb',\n",
    "                ]].sample(3)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0401d7a-2423-4015-8b88-91d1e9755611",
   "metadata": {},
   "source": [
    "# 2. Uniq parcelNumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fbd5834-d48e-4116-ade1-ae768acc7530",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T04:57:39.870983Z",
     "iopub.status.busy": "2022-06-15T04:57:39.870708Z",
     "iopub.status.idle": "2022-06-15T04:57:40.275262Z",
     "shell.execute_reply": "2022-06-15T04:57:40.274880Z",
     "shell.execute_reply.started": "2022-06-15T04:57:39.870960Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((137403, 20), (213079, 22), (0, 42), (130999, 42))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attom2 and regrid2: all rows that have not been legal matched!\n",
    "attom2 = attom[~attom.aid.isin(set(legal_matched.aid))]\n",
    "regrid2 = regrid[~regrid.rid.isin(set(legal_matched.rid))]\n",
    "regrid_parcelnumb = regrid2.drop_duplicates(subset='parcelnumb', keep=False)\n",
    "attom_parcelnumb = attom2.drop_duplicates(subset='Numb', keep=False)\n",
    "num_matched = attom_parcelnumb.merge(regrid_parcelnumb, left_on = 'Numb', right_on = 'parcelnumb', how = 'inner')\n",
    "del regrid2, attom2, regrid_parcelnumb, attom_parcelnumb\n",
    "# jun3 ((3219695, 20), (3330480, 22), (1604138, 45), (1207963, 42))\n",
    "regrid.shape, attom.shape, legal_matched.shape, num_matched.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1115e73d-1a38-40a7-a78b-c4b5f40ffceb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T04:57:40.276269Z",
     "iopub.status.busy": "2022-06-15T04:57:40.276079Z",
     "iopub.status.idle": "2022-06-15T04:57:42.675983Z",
     "shell.execute_reply": "2022-06-15T04:57:42.675552Z",
     "shell.execute_reply.started": "2022-06-15T04:57:40.276252Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 45)\n"
     ]
    }
   ],
   "source": [
    "num_diff = pd.DataFrame().reindex_like(num_matched)\n",
    "if len(num_matched):\n",
    "    num_matched['owner_compare'] = owner_compare(num_matched, 'owner', 'Owner')\n",
    "    # num_matched.query(\"owner_compare == False\").shape # (2918, 45)\n",
    "\n",
    "    num_diff = num_matched.query(\n",
    "           \"address.notna() & Address.notna() & address != Address\" # (86667, 42)\n",
    "           \"& address1.notna() & Address1.notna() & address1 != Address1\" \n",
    "            \"& rhex7 != '0' & ahex7 != '0' & rhex7 != ahex7\" \n",
    "            \"& owner.notna() & Owner.notna() & (~owner_compare)\"      \n",
    "    , engine = \"python\")\n",
    "    print(num_diff.shape) # (112, 45); jun3 (140, 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a03d72e-9aa7-41c9-8619-bee786324a18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T08:42:23.665719Z",
     "iopub.status.busy": "2022-06-14T08:42:23.665428Z",
     "iopub.status.idle": "2022-06-14T08:42:23.668078Z",
     "shell.execute_reply": "2022-06-14T08:42:23.667683Z",
     "shell.execute_reply.started": "2022-06-14T08:42:23.665698Z"
    }
   },
   "source": [
    "# SAVE CHECKPOINTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6cbe7a8-98f6-46cd-8335-4a0bc293b7c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T04:59:33.635372Z",
     "iopub.status.busy": "2022-06-15T04:59:33.635082Z",
     "iopub.status.idle": "2022-06-15T04:59:33.765273Z",
     "shell.execute_reply": "2022-06-15T04:59:33.764727Z",
     "shell.execute_reply.started": "2022-06-15T04:59:33.635352Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "date=\"jun15\"\n",
    "! mkdir -p temp/{date}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25086403-e874-46c8-984b-71a77b5de228",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T04:59:35.883269Z",
     "iopub.status.busy": "2022-06-15T04:59:35.882971Z",
     "iopub.status.idle": "2022-06-15T04:59:36.343343Z",
     "shell.execute_reply": "2022-06-15T04:59:36.342886Z",
     "shell.execute_reply.started": "2022-06-15T04:59:35.883247Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(legal_matched): legal_matched.reset_index(drop=True).to_feather(f'temp/{date}/{sf_code}_legal.ftr')\n",
    "if len(num_matched): num_matched.reset_index(drop=True).to_feather(f'temp/{date}/{sf_code}_num.ftr')\n",
    "if len(legal_diff): legal_diff.reset_index(drop=True).to_feather(f'temp/{date}/{sf_code}_legaldiff.ftr')\n",
    "if len(num_diff): num_diff.reset_index(drop=True).to_feather(f'temp/{date}/{sf_code}_numdiff.ftr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8674c2a2-ee1c-4581-81af-7983df136421",
   "metadata": {},
   "source": [
    "# 3. Matching dup pkwhat-pkwhere on remaining parcels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3da443f4-ed64-4ef4-9686-33dbc6336e5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T04:59:49.273495Z",
     "iopub.status.busy": "2022-06-15T04:59:49.273216Z",
     "iopub.status.idle": "2022-06-15T04:59:49.335303Z",
     "shell.execute_reply": "2022-06-15T04:59:49.334939Z",
     "shell.execute_reply.started": "2022-06-15T04:59:49.273473Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82080, 22)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attom3 = attom[~attom.aid.isin(pd.concat([legal_matched.aid, num_matched.aid]))] \n",
    "attom3.shape # (82080, 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cca879e4-4036-4c86-a4e7-0daa4a5b4d12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T04:59:50.782638Z",
     "iopub.status.busy": "2022-06-15T04:59:50.782349Z",
     "iopub.status.idle": "2022-06-15T04:59:51.023432Z",
     "shell.execute_reply": "2022-06-15T04:59:51.023019Z",
     "shell.execute_reply.started": "2022-06-15T04:59:50.782617Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attom3 regrid3 including na-Address1 (82080, 22) (6404, 20)\n",
      "attom3 regrid3 with valid Address1:  (82015, 22) (5487, 20)\n",
      "Shared columns=  set()\n"
     ]
    }
   ],
   "source": [
    "attom3 = attom[~attom.aid.isin(pd.concat([legal_matched.aid, num_matched.aid]))] # concat 2 series\n",
    "regrid3 = regrid[~regrid.rid.isin(pd.concat([legal_matched.rid, num_matched.rid]))] # concat 2 series\n",
    "# Inner-join columns\n",
    "attom3 = pd.concat([attom3, legal_diff, num_diff], join='inner')\n",
    "regrid3 = pd.concat([regrid3, legal_diff, num_diff], join='inner')\n",
    "print(\"attom3 regrid3 including na-Address1\", attom3.shape, regrid3.shape)\n",
    "\n",
    "# CONFIRMED separately: without address (or address1), there would be no pkwhat \n",
    "# i.e. filter for parcels with non-empty addresses only (We dont need pkwhere, as it is just h3 @res10)\n",
    "attom3 = attom3[attom3.Address1.notna()]\n",
    "regrid3 = regrid3[regrid3.address1.notna()]\n",
    "print(\"attom3 regrid3 with valid Address1: \", attom3.shape, regrid3.shape)\n",
    "print(\"Shared columns= \", set(attom3).intersection(set(regrid3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0823afbf-30e6-41e5-8fb1-bb87f3f7ff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Querying Placekeys API, regrid_df and attom_df separately, using 2 diff API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0569651f-5e50-4e4e-ae9c-210c99f6fe10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T09:47:50.326901Z",
     "iopub.status.busy": "2022-06-15T09:47:50.326332Z",
     "iopub.status.idle": "2022-06-15T09:47:50.329312Z",
     "shell.execute_reply": "2022-06-15T09:47:50.328926Z",
     "shell.execute_reply.started": "2022-06-15T09:47:50.326876Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def temp_main():\n",
    "#     print(\"START\")\n",
    "#     def temp_placekey():\n",
    "#         # 40 MIN!\n",
    "#         # for paralleling api calls/network ops, use async\n",
    "#         pkA = pk_call(attom3.head(1000), attom_pk_maps, 'aid', pk_api1)\n",
    "#         pkR = pk_call(regrid3.head(1000), regrid_pk_maps, 'rid', pk_api2)\n",
    "\n",
    "#         # Unfuture.result() is a blocking operation except ...\n",
    "#         pkA = pkA.result()\n",
    "#         pkR = pkR.result()\n",
    "#         print(\"END temp_placekey() \", pkA.shape, pkR.shape) # ((253555, 25), (170883, 23)); jun3 ((254_306, 25), (172_566, 23))    \n",
    "#         return pkA, pkR\n",
    "    \n",
    "#     pkA, pkR = temp_placekey()    \n",
    "#     print(\"END temp_main()\", pkA.shape, pkR.shape)\n",
    "    \n",
    "# temp_main()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e111ed08-15e0-4229-96c7-4f67f203a4ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T05:08:38.420126Z",
     "iopub.status.busy": "2022-06-15T05:08:38.419826Z",
     "iopub.status.idle": "2022-06-15T05:08:44.088662Z",
     "shell.execute_reply": "2022-06-15T05:08:44.088289Z",
     "shell.execute_reply.started": "2022-06-15T05:08:38.420103Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aid # responses:  (1000, 3) ; responses errors: \n",
      "Invalid address    5\n",
      "Name: error, dtype: int64\n",
      "rid # responses:  (1000, 3) ; responses errors: \n",
      "Invalid address    113\n",
      "Name: error, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((995, 25), (887, 23))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 40 MIN!\n",
    "# for paralleling api calls/network ops, use async\n",
    "pkA = pk_call(attom3, attom_pk_maps, 'aid', pk_api1)\n",
    "pkR = pk_call(regrid3, regrid_pk_maps, 'rid', pk_api2)\n",
    "\n",
    "# Unfuture.result() is a blocking operation except ...\n",
    "pkA = pkA.result()\n",
    "pkR = pkR.result()\n",
    "pkA.shape, pkR.shape # ((253555, 25), (170883, 23)); jun3 ((254_306, 25), (172_566, 23))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f3bea00f-fa38-4f97-b266-9af36fcbb5f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T09:22:11.388434Z",
     "iopub.status.busy": "2022-06-14T09:22:11.388134Z",
     "iopub.status.idle": "2022-06-14T09:22:11.446300Z",
     "shell.execute_reply": "2022-06-14T09:22:11.445760Z",
     "shell.execute_reply.started": "2022-06-14T09:22:11.388411Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((85915, 45), 85915)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "placekey_df = pd.concat([pkA, pkR], ignore_index=True)\n",
    "placekey_df.shape, placekey_df.pkwhat.count() # ((85915, 45), 85915)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6415296b-8467-4fad-aa53-477da7dc89f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T09:26:00.584489Z",
     "iopub.status.busy": "2022-06-14T09:26:00.584188Z",
     "iopub.status.idle": "2022-06-14T09:26:00.727581Z",
     "shell.execute_reply": "2022-06-14T09:26:00.727119Z",
     "shell.execute_reply.started": "2022-06-14T09:26:00.584466Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MUST: SAVE Placekey (bottleneck) CHECKPOINT \n",
    "# placekey_df.to_feather(f'placekeyed/{date}_{sf_code}.ftr')\n",
    "ls -lh placekeyed/{date}_{sf_code}.ftr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a469422e-d885-425e-9252-8abe544b38f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T09:31:01.559081Z",
     "iopub.status.busy": "2022-06-14T09:31:01.558788Z",
     "iopub.status.idle": "2022-06-14T09:31:01.716631Z",
     "shell.execute_reply": "2022-06-14T09:31:01.716249Z",
     "shell.execute_reply.started": "2022-06-14T09:31:01.559059Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((85915, 45), 85915)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "placekey_df = pd.read_feather(f'placekeyed/{date}_{sf_code}.ftr')\n",
    "placekey_df.shape, placekey_df.pkwhat.count() # ((85915, 45), 85915)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e8cfc12e-81d1-42f9-93a5-ab4f842951a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T09:31:17.651073Z",
     "iopub.status.busy": "2022-06-14T09:31:17.650752Z",
     "iopub.status.idle": "2022-06-14T09:31:17.910953Z",
     "shell.execute_reply": "2022-06-14T09:31:17.910479Z",
     "shell.execute_reply.started": "2022-06-14T09:31:17.651048Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove unique placekey values (unique addresses)\n",
    "placekey_df = placekey_df[placekey_df.duplicated(subset=['placekey'], keep=False)].copy()\n",
    "placekey_df.replace(\"\", np.nan, inplace=True)\n",
    "placekey_df.sort_values(['pkwhere', 'pkwhat'], inplace=True)\n",
    "print(f\"Placekey API: reconciled {len(placekey_df)} addresses, \\\n",
    " into {placekey_df.placekey.nunique()} different placekey groups\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d43f5932-3e04-4ba2-905b-ce00c7861406",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T09:38:24.102748Z",
     "iopub.status.busy": "2022-06-14T09:38:24.102450Z",
     "iopub.status.idle": "2022-06-14T09:38:24.118146Z",
     "shell.execute_reply": "2022-06-14T09:38:24.117765Z",
     "shell.execute_reply.started": "2022-06-14T09:38:24.102725Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>aid</th>\n",
       "      <th>address</th>\n",
       "      <th>address1</th>\n",
       "      <th>addressSub</th>\n",
       "      <th>Address</th>\n",
       "      <th>Address1</th>\n",
       "      <th>AddressSub</th>\n",
       "      <th>placekey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6156</th>\n",
       "      <td>None</td>\n",
       "      <td>205759319</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5000 CALL PL SE APT 104</td>\n",
       "      <td>5000 CALL PL SE</td>\n",
       "      <td>APT 104</td>\n",
       "      <td>226@63r-6bt-hyv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26512</th>\n",
       "      <td>None</td>\n",
       "      <td>205759323</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5000 CALL PL SE APT 303</td>\n",
       "      <td>5000 CALL PL SE</td>\n",
       "      <td>APT 303</td>\n",
       "      <td>226@63r-6bt-hyv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26513</th>\n",
       "      <td>None</td>\n",
       "      <td>205759326</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5000 CALL PL SE APT 404</td>\n",
       "      <td>5000 CALL PL SE</td>\n",
       "      <td>APT 404</td>\n",
       "      <td>226@63r-6bt-hyv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28972</th>\n",
       "      <td>None</td>\n",
       "      <td>205759320</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5000 CALL PL SE APT 201</td>\n",
       "      <td>5000 CALL PL SE</td>\n",
       "      <td>APT 201</td>\n",
       "      <td>226@63r-6bt-hyv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31361</th>\n",
       "      <td>None</td>\n",
       "      <td>205759324</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5000 CALL PL SE APT 402</td>\n",
       "      <td>5000 CALL PL SE</td>\n",
       "      <td>APT 402</td>\n",
       "      <td>226@63r-6bt-hyv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rid        aid address address1 addressSub                  Address  \\\n",
       "6156   None  205759319    None     None       None  5000 CALL PL SE APT 104   \n",
       "26512  None  205759323    None     None       None  5000 CALL PL SE APT 303   \n",
       "26513  None  205759326    None     None       None  5000 CALL PL SE APT 404   \n",
       "28972  None  205759320    None     None       None  5000 CALL PL SE APT 201   \n",
       "31361  None  205759324    None     None       None  5000 CALL PL SE APT 402   \n",
       "\n",
       "              Address1 AddressSub         placekey  \n",
       "6156   5000 CALL PL SE    APT 104  226@63r-6bt-hyv  \n",
       "26512  5000 CALL PL SE    APT 303  226@63r-6bt-hyv  \n",
       "26513  5000 CALL PL SE    APT 404  226@63r-6bt-hyv  \n",
       "28972  5000 CALL PL SE    APT 201  226@63r-6bt-hyv  \n",
       "31361  5000 CALL PL SE    APT 402  226@63r-6bt-hyv  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pk_com_cols = [\n",
    "    'rid', 'aid', \n",
    "    'address', 'address1', 'addressSub', \n",
    "    'Address', 'Address1', 'AddressSub',\n",
    "     'placekey',]\n",
    "placekey_df[pk_com_cols].head(1000).tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ba7e82-35b6-47ee-aabb-48157a259a99",
   "metadata": {},
   "source": [
    "# 4. ATTOM points in REGRID polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d0330725-b9d8-42fe-89b7-9144a75b5e16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T09:39:30.476653Z",
     "iopub.status.busy": "2022-06-14T09:39:30.476330Z",
     "iopub.status.idle": "2022-06-14T09:39:30.775637Z",
     "shell.execute_reply": "2022-06-14T09:39:30.775214Z",
     "shell.execute_reply.started": "2022-06-14T09:39:30.476629Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((137403, 20), (213079, 22), (2109, 20), (3778, 22))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attom4 = attom[~attom.aid.isin(\n",
    "    set(legal_matched.aid).union(set(num_matched.aid)).union(set(placekey_df.aid))\n",
    ")]\n",
    "regrid4 = regrid[~regrid.rid.isin(\n",
    "    set(legal_matched.rid).union(set(num_matched.rid)).union(set(placekey_df.rid))\n",
    ")]\n",
    "# REGRID 3.2mil down to 150k;  ATTOM 3.3mil down to 360k\n",
    "# DC jun14: regrid 140k to 2k, attom 210k to 4k\n",
    "regrid.shape, attom.shape, regrid4.shape, attom4.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "461dd304-8e2e-4e4b-afa6-820a341be5a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T09:41:01.775107Z",
     "iopub.status.busy": "2022-06-14T09:41:01.774796Z",
     "iopub.status.idle": "2022-06-14T09:41:01.802898Z",
     "shell.execute_reply": "2022-06-14T09:41:01.802478Z",
     "shell.execute_reply.started": "2022-06-14T09:41:01.775084Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Save checkpoints\n",
    "# attom4.reset_index(drop=True).to_feather(f'temp/{date}_{sf_code}_attom4.ftr')\n",
    "# regrid4.reset_index(drop=True).to_feather(f'temp/{date}_{sf_code}_regrid4.ftr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "bd46eb64-e52c-4d27-80d3-1c07b7c80eee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T09:46:16.295217Z",
     "iopub.status.busy": "2022-06-14T09:46:16.294921Z",
     "iopub.status.idle": "2022-06-14T09:46:16.308176Z",
     "shell.execute_reply": "2022-06-14T09:46:16.307624Z",
     "shell.execute_reply.started": "2022-06-14T09:46:16.295195Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.frame.DataFrame, (3778, 22))"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attom4 = pd.read_feather(f'temp/{date}_{sf_code}_attom4.ftr')\n",
    "type(attom4), attom4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a3629a33-80fa-4f90-9116-2e25d1e782f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T09:46:27.814528Z",
     "iopub.status.busy": "2022-06-14T09:46:27.814217Z",
     "iopub.status.idle": "2022-06-14T09:46:27.823126Z",
     "shell.execute_reply": "2022-06-14T09:46:27.822619Z",
     "shell.execute_reply.started": "2022-06-14T09:46:27.814505Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(geopandas.geodataframe.GeoDataFrame, (3778, 23))"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ATTOM GEOMETRY TYPE\n",
    "attom4_geo = gp.GeoDataFrame(\n",
    "        attom4, geometry=gp.points_from_xy(attom4.Lon, attom4.Lat)).set_crs(CRS_REGRID_PARCELS)\n",
    "type(attom4_geo), attom4_geo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9905c9d3-34cd-4de3-9e82-27aeaf5b78f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T09:46:50.438945Z",
     "iopub.status.busy": "2022-06-14T09:46:50.438638Z",
     "iopub.status.idle": "2022-06-14T09:46:52.431123Z",
     "shell.execute_reply": "2022-06-14T09:46:52.430692Z",
     "shell.execute_reply.started": "2022-06-14T09:46:50.438922Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2109, 20), (2109, 21), geopandas.geodataframe.GeoDataFrame)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# REGRID GEOMETRY TYPE\n",
    "list_of_regrid_feathers = glob(f\"attom/data/regrid-feather/{sf_code.lower()}_*.ftr\")\n",
    "with Pool(16) as pool:\n",
    "    regrid_geom = pool.map(\n",
    "        lambda feather : pd.read_feather(feather, columns=['ll_uuid', 'geometry']), \n",
    "        list_of_regrid_feathers)\n",
    "    regrid_geom = pd.concat(regrid_geom, ignore_index=True)    \n",
    "    \n",
    "regrid_geom.rename(columns={'geometry': 'geom', 'll_uuid': 'rid'}, inplace=True)    \n",
    "# convert pandas df to geopandas df: 1min\n",
    "regrid_geom = gp.GeoDataFrame(regrid_geom, \n",
    "                              geometry=gp.GeoSeries.from_wkt(regrid_geom.geom, crs = CRS_REGRID_PARCELS))\n",
    "regrid_geom = regrid_geom.drop(columns = 'geom')\n",
    "# regrid_geom.merge: to retain geopandas df and CRS \n",
    "regrid4_geo = regrid_geom.merge(regrid4, on = 'rid', how='right')\n",
    "regrid4.shape, regrid4_geo.shape, type(regrid4_geo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80583a0b-9d52-4afa-a571-cef53ebd7549",
   "metadata": {},
   "source": [
    "### SPATIAL JOINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "d97247c1-1902-4784-b737-44084a373a99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:43:14.483888Z",
     "iopub.status.busy": "2022-06-14T10:43:14.483594Z",
     "iopub.status.idle": "2022-06-14T10:43:14.492226Z",
     "shell.execute_reply": "2022-06-14T10:43:14.491756Z",
     "shell.execute_reply.started": "2022-06-14T10:43:14.483866Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 23)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO LATER: rows with address and no lat/lon: \n",
    "## GEOCODE them to get lat, lon before the spatial join!\n",
    "attom4_geo.query('Address1 == Address1 & Lat != Lat').shape # (2017, 10) jun3 (1990, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "d51ea7e0-5783-48ad-bb6b-9bd0195e09a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T09:50:46.170934Z",
     "iopub.status.busy": "2022-06-14T09:50:46.170607Z",
     "iopub.status.idle": "2022-06-14T09:50:46.201503Z",
     "shell.execute_reply": "2022-06-14T09:50:46.201130Z",
     "shell.execute_reply.started": "2022-06-14T09:50:46.170909Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nhat/anaconda3/envs/py39/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3444: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(423, 45)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `inner`: drop anything that didn't contain-within\n",
    "# RETAIN df_left geometry (regrid parcel polygon)\n",
    "df_pip = regrid4_geo.sjoin(attom4_geo, how=\"inner\", op='contains')\n",
    "df_pip['geom'] = df_pip.geometry.to_wkt()\n",
    "df_pip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec8dea4-e50c-4a97-aeca-cb1b1a7f7fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If want to save geodataframe to feather, first convert to df, and drop geometry columns\n",
    "# pd.DataFrame(df_pip.drop(columns='geometry')).reset_index(drop=True).to_feather(f'temp/{date}_{sf_code}_pip.ftr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c657a4aa-4418-4a09-b645-d1edfefecd29",
   "metadata": {},
   "source": [
    "# 5. Last step: h3 hex @res13\n",
    "- hexagon area ~ 2x3 meter, 1/5th size of average home, 1/10th size of average biz premise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "8bc7108e-0896-4c21-b582-11e30a534f01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T09:59:39.325282Z",
     "iopub.status.busy": "2022-06-14T09:59:39.324997Z",
     "iopub.status.idle": "2022-06-14T09:59:39.349032Z",
     "shell.execute_reply": "2022-06-14T09:59:39.348621Z",
     "shell.execute_reply.started": "2022-06-14T09:59:39.325261Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5371, 44)\n",
      "(2865, 44)\n",
      "(2506, 44)\n"
     ]
    }
   ],
   "source": [
    "df_last = pd.concat([attom4[~attom4.aid.isin(df_pip.aid)], \n",
    "                    regrid4[~regrid4.rid.isin(df_pip.rid)]], ignore_index= True)\n",
    "#### hex13 col is union of rhex13 and ahex13\n",
    "df_last['hex13'] = np.where(df_last.rhex13.notna(), df_last.rhex13, df_last.ahex13)\n",
    "print(df_last.shape)\n",
    "\n",
    "# THESE ARE DUPLICATES: repeated hex13\n",
    "df_h3_dup = df_last[df_last.duplicated(subset=['hex13'], keep=False)].copy()\n",
    "df_h3_dup = df_h3_dup.query('hex13 != \"0\"')\n",
    "print(df_h3_dup.shape)\n",
    "\n",
    "# df_rem also contains df_rem_nocoords (below) \n",
    "# For now, consider them as new parcels\n",
    "df_last = df_last[~df_last.hex13.isin(df_h3_dup.hex13)] # i.e. drop_duplicates(subset=['hex13'], keep=False)\n",
    "print(df_last.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca7f2fa-b7f7-4a43-ab99-d657681910c1",
   "metadata": {},
   "source": [
    "# Completed reconciling Regrid and Attom = RAD2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e257256-d92d-4e62-a9d3-e7472a01c1ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:02:48.581559Z",
     "iopub.status.busy": "2022-06-14T10:02:48.581218Z",
     "iopub.status.idle": "2022-06-14T10:02:48.584148Z",
     "shell.execute_reply": "2022-06-14T10:02:48.583722Z",
     "shell.execute_reply.started": "2022-06-14T10:02:48.581534Z"
    }
   },
   "source": [
    "# NEXT: enhance RAD2: add landuse, owner, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8fa584-a34c-4437-b183-93af211cd763",
   "metadata": {},
   "source": [
    "# landuse data input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "ad8d8fb2-a34d-4443-aa5b-b013f85d670a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:09:25.072975Z",
     "iopub.status.busy": "2022-06-14T10:09:25.072663Z",
     "iopub.status.idle": "2022-06-14T10:09:26.243301Z",
     "shell.execute_reply": "2022-06-14T10:09:26.242806Z",
     "shell.execute_reply.started": "2022-06-14T10:09:25.072952Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(213079, 4)\n"
     ]
    }
   ],
   "source": [
    "# ATTOM: state landuse df: maps aid to our standardized landuse\n",
    "with Pool(16) as pool:\n",
    "    alanduse = pool.map(\n",
    "        lambda feather_file : pd.read_feather(\n",
    "            feather_file, columns=['[ATTOM ID]', 'PropertyUseGroup',  'PropertyUseStandardized',]), \n",
    "        glob(f\"attom/data/attom-feather/{sf_code.upper()}_*.ftr\"))\n",
    "    alanduse = pd.concat(alanduse, ignore_index=True)    \n",
    "    \n",
    "alanduse.columns = ['aid', 'group', \n",
    "                    'code', # TODO LATER: use to identify MDU / subclass CAI (into edu/health/gov/commu)\n",
    "                   ]\n",
    "# HOTFIX: group has mixed cases (e.g. both Commercial and COMMERCIAL present in ATTOM raw data)\n",
    "alanduse['group'] = alanduse.group.str.upper()\n",
    "\n",
    "# re-mapping aid-landuse\n",
    "conditions = [ \n",
    "    alanduse.group.eq('AGRICULTURE / FARMING'),\n",
    "    alanduse.group.eq('RESIDENTIAL'),    \n",
    "    alanduse.group.eq('VACANT LAND'),    \n",
    "    alanduse.group.eq('PUBLIC WORKS'),    \n",
    "    alanduse.group.isin(['INDUSTRIAL', 'COMMERCIAL']), ]\n",
    "choices = ['farm', 'resi', 'vacland', 'CAI', 'biz']\n",
    "alanduse['alanduse'] = np.select(conditions, choices, default='rem')\n",
    "alanduse.alanduse.value_counts()\n",
    "print(alanduse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "7863c3a6-c814-4f9e-90f8-cdffd2c2c3c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:10:50.057223Z",
     "iopub.status.busy": "2022-06-14T10:10:50.056905Z",
     "iopub.status.idle": "2022-06-14T10:10:51.026572Z",
     "shell.execute_reply": "2022-06-14T10:10:51.026118Z",
     "shell.execute_reply.started": "2022-06-14T10:10:50.057200Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137403, 6)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# REGRID state landuse: maps rid to our standardized landuse\n",
    "with Pool(16) as pool:\n",
    "    rlanduse = pool.map(\n",
    "        lambda feather_file : pd.read_feather(\n",
    "            feather_file, columns=['ll_uuid', 'lbcs_activity', 'lbcs_function', 'lbcs_structure', 'lbcs_site', ]), \n",
    "        glob(f\"attom/data/regrid-feather/{sf_code.lower()}_*.ftr\"))\n",
    "    rlanduse = pd.concat(rlanduse, ignore_index=True)    \n",
    "    \n",
    "rlanduse.columns = ['rid', 'acti', 'func', 'struc', 'site']\n",
    "# Optimistic: assume parcels with missing lbcs_site: has building onsite i.e. = 6500\n",
    "rlanduse['site'] = rlanduse.site.fillna(\"6500\").astype(float).astype(int) // 1000\n",
    "# NOTE: With structure iff lbcs_site = 6k\n",
    "rlanduse[['acti', 'struc', 'func']] = rlanduse[['acti', 'struc', 'func']].fillna(\"0\").astype(float).astype(int) // 1000\n",
    "\n",
    "rlanduse['rlanduse']= np.vectorize(regrid_landuse_classifier)(\n",
    "    rlanduse['acti'], rlanduse['func'],  rlanduse['struc'], rlanduse['site'])\n",
    "rlanduse.rlanduse.value_counts()\n",
    "rlanduse.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9340103e-bd3f-45af-af9a-abed6b165386",
   "metadata": {},
   "source": [
    "# A. join landuse to RAD different groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "4cf9f4df-3be8-4595-bc79-5b47bc14e613",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:12:44.397391Z",
     "iopub.status.busy": "2022-06-14T10:12:44.397074Z",
     "iopub.status.idle": "2022-06-14T10:12:44.400588Z",
     "shell.execute_reply": "2022-06-14T10:12:44.400180Z",
     "shell.execute_reply.started": "2022-06-14T10:12:44.397369Z"
    }
   },
   "outputs": [],
   "source": [
    "rad_in_cols = ['aid', 'rid', \n",
    "              'address1', 'addressSub', 'Address1', 'AddressSub',\n",
    "              'owner', 'owner2', 'Owner', 'Owner2', \n",
    "              'lat', 'lon', 'Lat', 'Lon', \n",
    "               # 'landuse',  \n",
    "              ]\n",
    "\n",
    "rad_out_cols = ['pId', 'rId', 'pAddress1', 'pAddressSub', 'pOwner', 'pLat', 'pLon']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce1e1f7-34bd-4184-ac43-c11682ff07e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:15:55.251258Z",
     "iopub.status.busy": "2022-06-14T10:15:55.250953Z",
     "iopub.status.idle": "2022-06-14T10:15:55.253642Z",
     "shell.execute_reply": "2022-06-14T10:15:55.253228Z",
     "shell.execute_reply.started": "2022-06-14T10:15:55.251237Z"
    }
   },
   "source": [
    "## 1. RAD1(legal)2(parcelnumb) groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "5fd27e00-f8ce-4f57-8293-925f9d8e34f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:14:45.682399Z",
     "iopub.status.busy": "2022-06-14T10:14:45.682065Z",
     "iopub.status.idle": "2022-06-14T10:14:46.582109Z",
     "shell.execute_reply": "2022-06-14T10:14:46.581645Z",
     "shell.execute_reply.started": "2022-06-14T10:14:45.682368Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Exclude legal_diff (which later had been reviewed in Placekey step) from legal_matched\n",
    "# similarly, exclude num_diff from num_matched\n",
    "rad12 = pd.concat([\n",
    "    legal_matched[~legal_matched.index.isin(legal_diff.index)],\n",
    "    num_matched[~num_matched.index.isin(num_diff.index)],], ignore_index = True)[rad_in_cols]\n",
    "rad12 = rad12.merge(alanduse[['aid', 'alanduse']], on='aid', how='left')\n",
    "rad12 = rad12.merge(rlanduse[['rid', 'rlanduse']], on='rid', how='left')\n",
    "rad12['landuse'] = np.vectorize(rad_landuse_classifier_single)(rad12['alanduse'], rad12['rlanduse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85af2f42-12b8-4f78-ac7f-815c0693ee03",
   "metadata": {},
   "source": [
    "## 2. RAD3(placekey)4(pip)5(h3): placekey and h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "c37adf31-b3a9-4f92-8145-9658aa0a2f72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:20:41.375349Z",
     "iopub.status.busy": "2022-06-14T10:20:41.375034Z",
     "iopub.status.idle": "2022-06-14T10:20:43.086428Z",
     "shell.execute_reply": "2022-06-14T10:20:43.085984Z",
     "shell.execute_reply.started": "2022-06-14T10:20:41.375324Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NOTE: as of now, 2 businesses with different SUITES are mapped to same placekey!\n",
    "# TODO LATER: need to consider addressSub to expand a address1 into multiple addresses, if possible! (and AddressSub to expand Address1) \n",
    "pk_group = placekey_df.copy(deep = True)[rad_in_cols + ['placekey']]\n",
    "# each row (keyed on hex13) comes from either REGRID(has rid), or ATTOM(has aid)\n",
    "h3_group = df_h3_dup.copy(deep = True)[rad_in_cols + ['hex13']]\n",
    "\n",
    "for GROUPBY, group_df in zip(['placekey', 'hex13'], [pk_group, h3_group]):\n",
    "    group_df = group_df.merge(alanduse[[\n",
    "        'aid', 'alanduse']], on='aid', how='left').merge(rlanduse[[\n",
    "        'rid', 'rlanduse']], on='rid', how='left')\n",
    "    group_df = group_df.groupby(GROUPBY).agg({col : list for col in rad_in_cols + ['alanduse', 'rlanduse']})\n",
    "    # Combine 2 list columns with + operator\n",
    "    group_df['landuse'] = np.vectorize(rad_landuse_classifier_many)(group_df['alanduse'] + group_df['rlanduse'])\n",
    "    # Assign back to variables\n",
    "    if GROUPBY == 'placekey':    pk_group = group_df # (142625, 17)\n",
    "    else:                        h3_group = group_df # (5002, 17)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54eeba5-c157-4ad2-bc5a-446824020a85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:18:00.941950Z",
     "iopub.status.busy": "2022-06-14T10:18:00.941652Z",
     "iopub.status.idle": "2022-06-14T10:18:00.944617Z",
     "shell.execute_reply": "2022-06-14T10:18:00.944050Z",
     "shell.execute_reply.started": "2022-06-14T10:18:00.941926Z"
    }
   },
   "source": [
    "## 3. RAD3(placekey)4(pip)5(h3): pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "84db5b39-67b2-4311-96c4-3495252fe28f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:30:40.724109Z",
     "iopub.status.busy": "2022-06-14T10:30:40.723816Z",
     "iopub.status.idle": "2022-06-14T10:30:40.852974Z",
     "shell.execute_reply": "2022-06-14T10:30:40.852524Z",
     "shell.execute_reply.started": "2022-06-14T10:30:40.724087Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# each row (keyed on rid) contains 1 rid and 1 aid\n",
    "pip_group_prev = df_pip.copy(deep=True)[rad_in_cols]\n",
    "pip_group_prev = pip_group_prev.merge(alanduse[['aid', 'alanduse']], on='aid', how='left')\n",
    "pip_group_prev = pip_group_prev.merge(rlanduse[['rid', 'rlanduse']], on='rid', how='left')\n",
    "\n",
    "attom_pip_agg_cols = ['aid', 'Address1', 'AddressSub', 'Owner', 'Owner2', 'Lat', 'Lon']\n",
    "pip_group = pip_group_prev.groupby('rid').agg({ col : list for col in attom_pip_agg_cols + ['alanduse']})\n",
    "pip_group_prev.set_index('rid', inplace=True)\n",
    "# drop duplicate indices\n",
    "pip_group_prev = pip_group_prev[~pip_group_prev.index.duplicated(keep='first')][\n",
    "    ['rlanduse', 'address1', 'addressSub', 'owner', 'owner2', 'lat', 'lon']] \n",
    "# excludes rid, includes rlanduse: turn a regular column into a list column\n",
    "for col in pip_group_prev.columns:\n",
    "    pip_group_prev[col] = pip_group_prev[col].map(lambda x: [x])  \n",
    "\n",
    "pip_group = pip_group.join(pip_group_prev, how = 'left') \n",
    "pip_group['landuse'] = np.vectorize(rad_landuse_classifier_many)(pip_group['alanduse'] + pip_group['rlanduse'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbf5bc6-1405-40da-8702-c552b9bcd65c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:31:11.900950Z",
     "iopub.status.busy": "2022-06-14T10:31:11.900664Z",
     "iopub.status.idle": "2022-06-14T10:31:11.903581Z",
     "shell.execute_reply": "2022-06-14T10:31:11.903017Z",
     "shell.execute_reply.started": "2022-06-14T10:31:11.900929Z"
    }
   },
   "source": [
    "# B. join other fields to RAD different groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "8959b01a-49a1-4bdb-88de-fac00172c969",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:36:00.233507Z",
     "iopub.status.busy": "2022-06-14T10:36:00.233211Z",
     "iopub.status.idle": "2022-06-14T10:36:00.321978Z",
     "shell.execute_reply": "2022-06-14T10:36:00.321542Z",
     "shell.execute_reply.started": "2022-06-14T10:36:00.233484Z"
    }
   },
   "outputs": [],
   "source": [
    "# copy rid to rId\n",
    "rad12['rId'] = rad12[['rid']]\n",
    "# 5 new columns: pId, pAddress1, pAddressSub, pLat, pLon\n",
    "conds = rad12['address1'].isna() & rad12['Address1'].notna()\n",
    "conds_ndarr = np.tile(conds.values[:, None], 3) # repeat conds values 3 times\n",
    "rad12[['pId', 'pAddress1', 'pAddressSub', ]] = np.where(conds_ndarr, \n",
    "                        rad12[['aid', 'Address1', 'AddressSub', ]],\n",
    "                        rad12[['rid', 'address1', 'addressSub', ]],)   \n",
    "rad12['pLat'] = np.where(rad12['lat'].isna() & rad12['Lat'].notna(), \n",
    "                                 rad12['Lat'], rad12['lat'])\n",
    "rad12['pLon'] = np.where(rad12['lon'].isna() & rad12['Lon'].notna(), \n",
    "                                 rad12['Lon'], rad12['lon'])\n",
    "# Hotfix bad owner data: has owner2, but not owner!\n",
    "rad12['owner'] = np.where(rad12['owner'].isna(), rad12['owner2'], rad12['owner'])\n",
    "rad12['Owner'] = np.where(rad12.Owner.isna(), rad12.Owner2, rad12.Owner)\n",
    "# Select pOwner from regrid owner or attom Owner\n",
    "rad12['pOwner'] = np.where(rad12['owner'].notna(), rad12['owner'], rad12['Owner'])\n",
    "# ASIDE: #rows with no owners\n",
    "# rad12.query('pOwner != pOwner')[['owner', 'owner2', 'Owner', 'Owner2', 'pOwner']].shape\n",
    "\n",
    "# pk_group ~ h3_group\n",
    "pk_group['fields'] =  np.vectorize(rad_fields_vec)(\n",
    "    pk_group['rid'],    pk_group['aid'],    pk_group['address1'],    pk_group['addressSub'],    \n",
    "    pk_group['Address1'],    pk_group['AddressSub'],    pk_group['lat'],    pk_group['lon'],    \n",
    "    pk_group['Lat'],    pk_group['Lon'],    \n",
    "    pk_group['owner'],    pk_group['owner2'],    pk_group['Owner'],    pk_group['Owner2'],)\n",
    "# SPLIT fields into subfields\n",
    "pk_group[rad_out_cols] = pk_group.fields.str.split(\"\\t\", expand=True).replace([\"None\", \"nan\"], np.nan)\n",
    "\n",
    "# pk_group ~ h3_group\n",
    "h3_group['fields'] =  np.vectorize(rad_fields_vec)(\n",
    "    h3_group['rid'],    h3_group['aid'],    h3_group['address1'],    h3_group['addressSub'],    \n",
    "    h3_group['Address1'],    h3_group['AddressSub'],    h3_group['lat'],    h3_group['lon'],    \n",
    "    h3_group['Lat'],    h3_group['Lon'],    \n",
    "    h3_group['owner'],    h3_group['owner2'],    h3_group['Owner'],    h3_group['Owner2'],)\n",
    "# SPLIT fields into subfields\n",
    "h3_group[rad_out_cols] = h3_group.fields.str.split(\"\\t\", expand=True).replace([\"None\", \"nan\"], np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "d74ac193-b8eb-4175-8695-c75ff45ecb6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:37:25.146475Z",
     "iopub.status.busy": "2022-06-14T10:37:25.146143Z",
     "iopub.status.idle": "2022-06-14T10:37:25.157618Z",
     "shell.execute_reply": "2022-06-14T10:37:25.157065Z",
     "shell.execute_reply.started": "2022-06-14T10:37:25.146451Z"
    }
   },
   "outputs": [],
   "source": [
    "# pip_group is slightly different from (pk_group ~ h3_group)\n",
    "pip_group.reset_index(inplace=True)\n",
    "pip_group['rid'] = pip_group['rid'].map(lambda cell: [cell])\n",
    "\n",
    "pip_group['fields'] =  np.vectorize(rad_fields_vec)(\n",
    "    pip_group['rid'],    pip_group['aid'],    pip_group['address1'],    pip_group['addressSub'],    \n",
    "    pip_group['Address1'],    pip_group['AddressSub'],    pip_group['lat'],    pip_group['lon'],    \n",
    "    pip_group['Lat'],    pip_group['Lon'],    \n",
    "    pip_group['owner'],    pip_group['owner2'],    pip_group['Owner'],    pip_group['Owner2'],)\n",
    "# SPLIT fields into subfields\n",
    "pip_group[rad_out_cols] = pip_group.fields.str.split(\"\\t\", expand=True).replace([\"None\", \"nan\"], np.nan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ff2d91-1cd1-45d4-ae76-ef8fd3f4252a",
   "metadata": {},
   "source": [
    "# C. [easy peasy] divide last group df_last into: \n",
    "- df_points (remaining ATTOM points) \n",
    "- and df_polys (remaining REGRID parcels)\n",
    "## and join landuse, and other fields to these remaining demand points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "e21f6bd5-9b14-4be8-b916-c0296694c61a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:46:09.114819Z",
     "iopub.status.busy": "2022-06-14T10:46:09.114536Z",
     "iopub.status.idle": "2022-06-14T10:46:09.237071Z",
     "shell.execute_reply": "2022-06-14T10:46:09.236504Z",
     "shell.execute_reply.started": "2022-06-14T10:46:09.114799Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((636, 10), (1870, 10))"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_points = df_last.query('aid == aid')[\n",
    "    ['aid', 'Owner', 'Owner2', 'Address1', 'AddressSub', 'Lat', 'Lon' ,]]\n",
    "df_points = df_points.merge(alanduse[['aid', 'alanduse']], \n",
    "                            on='aid', how='left').rename(columns= {\n",
    "    'aid' : 'pId', 'alanduse' : 'landuse', 'Address1' : 'pAddress1',\n",
    "    'AddressSub' : 'pAddressSub', 'Lat' : 'pLat', 'Lon' : 'pLon',\n",
    "})\n",
    "\n",
    "df_points['pOwner'] = np.where(df_points.Owner.isna(), df_points.Owner2, df_points.Owner)\n",
    "df_points['rId'] = np.nan\n",
    "\n",
    "\n",
    "# regrid_geom.merge(...geometry) # if want kepler visual\n",
    "df_polys = df_last.query('rid == rid')[\n",
    "    ['rid', 'owner', 'owner2', 'address1', 'addressSub', 'lat', 'lon']]\n",
    "df_polys = df_polys.merge(rlanduse[['rid', 'rlanduse']], \n",
    "                          on='rid', how='left').rename(columns= {\n",
    "    'rid' : 'pId', 'rlanduse' : 'landuse',\n",
    "    'address1' : 'pAddress1', 'addressSub' : 'pAddressSub',\n",
    "    'lat' : 'pLat', 'lon' : 'pLon',\n",
    "})\n",
    "df_polys['pOwner'] = np.where(df_polys.owner.isna(), df_polys.owner2, df_polys.owner)\n",
    "df_polys['rId'] = df_polys['pId']\n",
    "\n",
    "df_points.shape, df_polys.shape \n",
    "\n",
    "# # ASIDE: has coords, but no address\n",
    "# # Remained here because these points had not been mapped to any polygons in PIP step\n",
    "# df_points.query('pAddress1 != pAddress1 & pLat == pLat').shape # (26401, 10) jun3 (26728, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c469af38-8cd5-43d8-bc18-411c21a18f6e",
   "metadata": {},
   "source": [
    "# Last merge: putting groups together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "76b2aa14-d98f-4136-9ecd-3f06d361a4eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:51:34.283841Z",
     "iopub.status.busy": "2022-06-14T10:51:34.283533Z",
     "iopub.status.idle": "2022-06-14T10:51:34.445727Z",
     "shell.execute_reply": "2022-06-14T10:51:34.445282Z",
     "shell.execute_reply.started": "2022-06-14T10:51:34.283819Z"
    }
   },
   "outputs": [],
   "source": [
    "# add alternative ids as a list column\n",
    "rad12['altIds'] = list(zip(rad12.rid, rad12.aid))\n",
    "pk_group['altIds'] = pk_group[['rid', 'aid']].apply(lambda row: [v for l in row for v in l if v is not np.nan], axis=1)\n",
    "h3_group['altIds'] = h3_group[['rid', 'aid']].apply(lambda row: [v for l in row for v in l if v is not np.nan], axis=1)\n",
    "pip_group['altIds'] = pip_group[['rid', 'aid']].apply(lambda row: [v for l in row for v in l if v is not np.nan], axis=1)\n",
    "# these groups altIds is simply pId (as a list of length 1)\n",
    "df_points['altIds'] = df_points['pId'].map(lambda cell: [cell])\n",
    "df_polys['altIds'] = df_polys['pId'].map(lambda cell: [cell])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "5972ca29-5b00-4aa8-8ad3-4624889a1b63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:51:43.084221Z",
     "iopub.status.busy": "2022-06-14T10:51:43.083934Z",
     "iopub.status.idle": "2022-06-14T10:51:43.087724Z",
     "shell.execute_reply": "2022-06-14T10:51:43.087197Z",
     "shell.execute_reply.started": "2022-06-14T10:51:43.084200Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pId', 'rId', 'pAddress1', 'pAddressSub', 'pOwner', 'pLat', 'pLon', 'altIds', 'landuse']\n"
     ]
    }
   ],
   "source": [
    "outcols = rad_out_cols + ['altIds', 'landuse']\n",
    "print(outcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "017c5f75-f2cc-4a6d-91cb-d575a97798a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:52:38.458864Z",
     "iopub.status.busy": "2022-06-14T10:52:38.458575Z",
     "iopub.status.idle": "2022-06-14T10:52:38.519713Z",
     "shell.execute_reply": "2022-06-14T10:52:38.519156Z",
     "shell.execute_reply.started": "2022-06-14T10:52:38.458843Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((213079, 22), (137403, 20), (139663, 11))"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rad2 = pd.concat([rad12[outcols], \n",
    "            pk_group[outcols].reset_index(),\n",
    "            h3_group[outcols].reset_index(),\n",
    "            pip_group[outcols], # index=rid=rId=pId\n",
    "            df_points[outcols],\n",
    "            df_polys[outcols],])\n",
    "attom.shape, regrid.shape, rad2.shape # (3316869, 10); jun3 (3320097, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "56a99a96-87ca-4e32-b868-19047534def4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:55:49.263727Z",
     "iopub.status.busy": "2022-06-14T10:55:49.263454Z",
     "iopub.status.idle": "2022-06-14T10:55:49.344019Z",
     "shell.execute_reply": "2022-06-14T10:55:49.343455Z",
     "shell.execute_reply.started": "2022-06-14T10:55:49.263706Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139663, 12)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ADD SOURCE COLUMN\n",
    "# len of pId==36 = from Regrid, under10 = from Attom\n",
    "set(rad2.pId.str.len()) # {6, 7, 8, 9, 36}\n",
    "\n",
    "# REGRID = primary info from REGRID\n",
    "# ATTOM>REGRID = both REGRID and ATTOM cover, but ATTOM has more info\n",
    "# ATTOM = new points from ATTOM (REGRID miss-coverage)\n",
    "rad2['source'] = np.where(rad2.pId.str.len() == 36, \n",
    "                          'REGRID', \n",
    "                          np.where(rad2.rId.notna(), 'ATTOM>REGRID', 'ATTOM'))\n",
    "rad2.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "44b46a82-7777-4b6f-88d4-80f20ea937da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:56:29.376173Z",
     "iopub.status.busy": "2022-06-14T10:56:29.375880Z",
     "iopub.status.idle": "2022-06-14T10:56:29.390178Z",
     "shell.execute_reply": "2022-06-14T10:56:29.389687Z",
     "shell.execute_reply.started": "2022-06-14T10:56:29.376149Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REGRID          137192\n",
       "ATTOM             2433\n",
       "ATTOM>REGRID        38\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rad2.source.value_counts() # of course, most of RAD2 comes from REGRID!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baec9fc9-9f57-4e45-9f05-001ac12d5a3c",
   "metadata": {},
   "source": [
    "# SAVING a BIG CHECKPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "a3e46507-0f02-4ce7-a14e-6b0cbd80c6cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:59:41.601000Z",
     "iopub.status.busy": "2022-06-14T10:59:41.600700Z",
     "iopub.status.idle": "2022-06-14T10:59:42.081576Z",
     "shell.execute_reply": "2022-06-14T10:59:42.081128Z",
     "shell.execute_reply.started": "2022-06-14T10:59:41.600977Z"
    }
   },
   "outputs": [],
   "source": [
    "rad2.reset_index(drop=True).astype(str).to_feather(f'temp/{date}_{sf_code}_rad2.ftr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd1c8e6-f342-4e18-bcec-5fa33926b327",
   "metadata": {},
   "source": [
    "# Process ATTOM POI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "982d1191-3094-403c-aa43-94e31974d012",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T12:12:08.961318Z",
     "iopub.status.busy": "2022-06-14T12:12:08.961058Z",
     "iopub.status.idle": "2022-06-14T12:12:09.473330Z",
     "shell.execute_reply": "2022-06-14T12:12:09.472871Z",
     "shell.execute_reply.started": "2022-06-14T12:12:08.961299Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "poi = pd.read_feather(f'temp/jun10_poi_{sf_code}.ftr') # read from a saved feather\n",
    "poi = poi.drop(columns=['STATENAME', 'STATE', 'INDUSTRY', 'FRANCHISE', 'PRIMARY', 'COUNTY3', 'OBID', 'GEO_MATCH_CODE_TEXT'])\n",
    "poi = poi.query(\"BUSNAME == BUSNAME\") # not nan\n",
    "poi['NAMESTREETZIP'] = poi['BUSNAME'].str.strip() + \" @ \" + poi['STREET'].str.strip() + \" @ \" + poi['ZIP'].str.strip()\n",
    "poi = poi.drop_duplicates([\"NAMESTREETZIP\"], keep='first').reset_index(drop=True)\n",
    "poi.shape\n",
    "\n",
    "cai_health, health_df = getcai(poi, \"health\")\n",
    "cai_gov, gov_df = getcai(poi, \"government\")\n",
    "cai_comm, comm_df = getcai(poi, \"community\")\n",
    "cai_edu, edu_df = getcai(poi, \"education\")\n",
    "cai_relig, relig_df = getcai(poi, \"religious\")\n",
    "cai_outdoor, outdoor_df = getcai(poi, \"outdoor\")\n",
    "# Dont need, @yuan what are these for?\n",
    "del cai_health, cai_gov, cai_comm, cai_edu, cai_relig, cai_outdoor \n",
    "\n",
    "poi[\"DPtype\"] = \"commercial\"\n",
    "poi[\"DPtype\"] = np.where(poi[\"BUSNAME\"].isin(outdoor_df[\"BUSNAME\"]), \"outdoor\", poi[\"DPtype\"])\n",
    "# religious POI belongs to community\n",
    "poi[\"DPtype\"] = np.where(poi[\"BUSNAME\"].isin(relig_df[\"BUSNAME\"]), \"community\", poi[\"DPtype\"])\n",
    "poi[\"DPtype\"] = np.where(poi[\"BUSNAME\"].isin(edu_df[\"BUSNAME\"]), \"education\", poi[\"DPtype\"])\n",
    "poi[\"DPtype\"] = np.where(poi[\"BUSNAME\"].isin(comm_df[\"BUSNAME\"]), \"community\", poi[\"DPtype\"])\n",
    "poi[\"DPtype\"] = np.where(poi[\"BUSNAME\"].isin(gov_df[\"BUSNAME\"]), \"government\", poi[\"DPtype\"])\n",
    "poi[\"DPtype\"] = np.where(poi[\"BUSNAME\"].isin(health_df[\"BUSNAME\"]), \"health\", poi[\"DPtype\"])\n",
    "poi[\"CAIsubtype\"] = np.where(poi[\"DPtype\"].isin([\"community\",\"education\",\"government\",\"health\"]), poi[\"DPtype\"], \"notCAI\")\n",
    "poi[\"DPtype\"] = np.where(poi[\"CAIsubtype\"] == 'notCAI', poi[\"DPtype\"], \"CAI\")\n",
    "\n",
    "\n",
    "# ASSUMPTION: no 2 biz/POIs occupies same hexagon ~ 2x3meter \n",
    "res = 14  \n",
    "poi = poi.rename(columns={\"LONGITUDE\" : 'lng', 'LATITUDE' : 'lat', 'DPtype': 'landuse'})\n",
    "poi = poi.h3.geo_to_h3(res).reset_index()\n",
    "\n",
    "# GENERATE ID from other values in the row\n",
    "# concat string columns using sum(axis=1); then map to hash values, using hash function\n",
    "poi['pId'] = poi[['NAMESTREETZIP', 'h3_14']].sum(axis=1).map(hash)\n",
    "# confirm all unique id\n",
    "if not (poi.shape[0] == poi.pId.count()== poi.pId.nunique()): # ((286050, 18), 286050, 286050)\n",
    "    print(\"ALERT: missing unique id\")\n",
    "    \n",
    "poi['landuse'] = poi['landuse'].replace({\"commercial\" : 'biz'})\n",
    "\n",
    "poi_keep_cols = ['pId', 'BUSNAME', 'PHONE', \n",
    "        'STREET', 'CITY', 'ZIP', \n",
    "        'lng', 'lat', 'SIC', 'CATEGORY', \n",
    "        'landuse', 'CAIsubtype', 'h3_14',]\n",
    "poi = poi[poi_keep_cols].rename(columns={'STREET': 'pAddress1', 'CITY': 'pCity', 'ZIP': 'pZip', \n",
    "                      'BUSNAME': 'pOwner', 'CATEGORY' : 'pIndustry', 'SIC': 'pSIC'})\n",
    "poi['source'] = 'POI'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e6c123-b498-44bf-bf27-4a9b665dad01",
   "metadata": {},
   "source": [
    "# Add ATTOM POI to RAD = RAD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "ca92fa84-ce8f-4706-9a39-72f66f9dba65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T12:14:58.103378Z",
     "iopub.status.busy": "2022-06-14T12:14:58.103075Z",
     "iopub.status.idle": "2022-06-14T12:14:58.106708Z",
     "shell.execute_reply": "2022-06-14T12:14:58.106288Z",
     "shell.execute_reply.started": "2022-06-14T12:14:58.103356Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "d0b2d84c-34d5-4442-ac3a-baaefbc3535f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T15:35:25.237573Z",
     "iopub.status.busy": "2022-06-14T15:35:25.237049Z",
     "iopub.status.idle": "2022-06-14T15:35:26.056474Z",
     "shell.execute_reply": "2022-06-14T15:35:26.055910Z",
     "shell.execute_reply.started": "2022-06-14T15:35:25.237549Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((139663, 13), (48758, 14), (142533, 20))"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add h3_14 column\n",
    "rad2_with_dup = pd.DataFrame(rad2).rename(columns={'pLat' : 'lat', 'pLon' : 'lng'})\n",
    "rad2_with_dup[['lat', 'lng']] = rad2_with_dup[['lat', 'lng']].astype(float)\n",
    "rad2_with_dup = rad2_with_dup.h3.geo_to_h3(res).reset_index()\n",
    "rad2_with_dup['CAIsubtype'] = np.where(rad2_with_dup['landuse'] == 'CAI', 'parcelCAI', 'notCAI')\n",
    "rad3_with_dup = pd.concat([poi, rad2_with_dup], ignore_index=True)\n",
    "uniq_poi = rad3_with_dup.drop_duplicates(subset=[f'h3_{res}'], keep=False, ignore_index=True)\n",
    "uniq_poi = uniq_poi.query('source == \"POI\"')\n",
    "rad3 = pd.concat([uniq_poi, rad2_with_dup], ignore_index=True)\n",
    "rad2.shape, poi.shape, rad3.shape, # ((139663, 13), (48758, 14), (142533, 20))\n",
    "# 3_320_097 + 286_050 + h3 deduped = 3_389_890"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092c6cf7-92d0-4731-a030-19d8abf1eef9",
   "metadata": {},
   "source": [
    "# SPATIAL JOIN rad3 with TIGER/CB2019 (i.e. map points to GEOID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "f9d248d6-b057-4c52-a633-1b29339a2c49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T15:36:09.537627Z",
     "iopub.status.busy": "2022-06-14T15:36:09.537051Z",
     "iopub.status.idle": "2022-06-14T15:36:09.724601Z",
     "shell.execute_reply": "2022-06-14T15:36:09.724156Z",
     "shell.execute_reply.started": "2022-06-14T15:36:09.537605Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tiger = pd.read_feather(f'tigerCB2019/{sf_code}.ftr')\n",
    "tiger.columns = ['GEOID', 'geom']\n",
    "# convert pandas df to geopandas df\n",
    "tiger = gp.GeoDataFrame(tiger, \n",
    "          geometry = gp.GeoSeries.from_wkt(tiger.geom, crs = CRS_REGRID_PARCELS))\n",
    "\n",
    "# convert pandas df to geopandas df\n",
    "rad3CB = gp.GeoDataFrame(rad3, \n",
    "           geometry = gp.points_from_xy(rad3.lng, rad3.lat, crs = CRS_REGRID_PARCELS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "3d5aea38-e1bb-4970-8d86-230426cda61f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T15:36:12.405617Z",
     "iopub.status.busy": "2022-06-14T15:36:12.405343Z",
     "iopub.status.idle": "2022-06-14T15:36:13.144638Z",
     "shell.execute_reply": "2022-06-14T15:36:13.144066Z",
     "shell.execute_reply.started": "2022-06-14T15:36:12.405595Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: number of demand points fallen outside of CB boundaries =  127\n"
     ]
    }
   ],
   "source": [
    "rad3CB = gp.sjoin(rad3CB, tiger, how=\"left\", \n",
    "    predicate='within').rename(columns={'geom': 'wktCB'}).drop(\n",
    "    columns=['index_right', 'hex13', 'geometry']).replace('nan', np.nan)\n",
    "\n",
    "print(f\"NOTE: number of demand points fallen outside of CB boundaries = \\\n",
    " {rad3CB.query('GEOID != GEOID').shape[0]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "3d752915-d8d2-4814-a19c-aca8cdd05972",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T16:19:03.367194Z",
     "iopub.status.busy": "2022-06-14T16:19:03.366934Z",
     "iopub.status.idle": "2022-06-14T16:19:03.370476Z",
     "shell.execute_reply": "2022-06-14T16:19:03.370120Z",
     "shell.execute_reply.started": "2022-06-14T16:19:03.367173Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142533, 20)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rad3CB.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037be196-4282-4de1-8f30-b51d54e2d011",
   "metadata": {},
   "source": [
    "# add speedRank column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "e8e6e37a-ec65-431a-a364-eba902c892be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T16:23:58.331406Z",
     "iopub.status.busy": "2022-06-14T16:23:58.331091Z",
     "iopub.status.idle": "2022-06-14T16:23:58.334171Z",
     "shell.execute_reply": "2022-06-14T16:23:58.333786Z",
     "shell.execute_reply.started": "2022-06-14T16:23:58.331383Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Download ES speedRankReadyRaw\n",
    "# # RUN ONCE: 10 minutes\n",
    "# from elasticsearch import Elasticsearch, helpers\n",
    "# ES_DEV = Elasticsearch(['https://3d6a9dd50c7c49c9ab5d23b6891bc03e.us-central1.gcp.cloud.es.io:9243'], \n",
    "#                     http_auth=('elastic', 'WMzYk5RXyzE7MRShwPVwHzPX'), timeout=30)\n",
    "\n",
    "# BASE_COLS = ['GEOID', ]\n",
    "# OTHER_COLS = [ 'speedRankReadyRaw',] \n",
    "# ES_DOWNLOAD_COLS = BASE_COLS + OTHER_COLS \n",
    "\n",
    "# def download_ES(index_name):\n",
    "#     print('Start downloading ES index ', index_name)\n",
    "#     match_query = {\n",
    "#         \"query\": {\"match_all\": {}},\n",
    "#         \"_source\": {\n",
    "#             \"includes\": ES_DOWNLOAD_COLS\n",
    "#         },\n",
    "#     }\n",
    "#     res_gen = helpers.scan(ES_DEV, query= match_query, index= index_name) # 3 x faster than (match_all)\n",
    "#     df = pd.DataFrame([record['_source'] for record in res_gen])\n",
    "#     if len(df):\n",
    "#         sf_code = SF57[index_name[-2:]]\n",
    "#         df.to_feather(f'ESrank/{date}_{sf_code}.ftr') \n",
    "#         print(f'Completed saving ES index {index_name}, {df.shape=} to ftr')\n",
    "#     return\n",
    "\n",
    "# # Download speedRank and save to ftr for all sf\n",
    "# index_list = [f\"bossdata{sf}\" for sf in SF57]\n",
    "# with Pool(16) as pool: # Execution started at 2022-06-02 18:35:10\n",
    "#     pool.map(download_ES, index_list)       \n",
    "\n",
    "\n",
    "# ERROR: NotFoundError: NotFoundError(404, 'index_not_found_exception', 'no such index [bossdata74]', bossdata74, index_or_alias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "e9d1a2bd-4dd7-418f-b9db-99dde7855835",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T16:17:03.837278Z",
     "iopub.status.busy": "2022-06-14T16:17:03.836974Z",
     "iopub.status.idle": "2022-06-14T16:17:04.016508Z",
     "shell.execute_reply": "2022-06-14T16:17:04.015973Z",
     "shell.execute_reply.started": "2022-06-14T16:17:03.837255Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [
    "ls ESrank | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "02f427f0-b9bd-494d-a76e-bafd8452e486",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T16:17:06.680404Z",
     "iopub.status.busy": "2022-06-14T16:17:06.680065Z",
     "iopub.status.idle": "2022-06-14T16:17:06.684071Z",
     "shell.execute_reply": "2022-06-14T16:17:06.683692Z",
     "shell.execute_reply.started": "2022-06-14T16:17:06.680375Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('DC', '11', 'jun14')"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf_code, sf, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "8bbe7a79-310c-4a0e-92b5-e2a1e580fb8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T16:18:35.868129Z",
     "iopub.status.busy": "2022-06-14T16:18:35.867843Z",
     "iopub.status.idle": "2022-06-14T16:18:35.973304Z",
     "shell.execute_reply": "2022-06-14T16:18:35.972933Z",
     "shell.execute_reply.started": "2022-06-14T16:18:35.868107Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142406, 21)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ESdf = pd.read_feather(f'ESrank/{date}_{sf_code}.ftr').rename(columns={\n",
    "                            'speedRankReadyRaw': 'rank'})\n",
    "# dont need demand points fallen outside state censusblock boundaries\n",
    "rad3CB_rank = rad3CB.dropna(subset='GEOID').merge(ESdf[['GEOID', 'rank']], on='GEOID', how='left')\n",
    "\n",
    "rad3CB_rank.shape # (3386316, 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "577d52a2-ff37-4c1f-a66f-dff04e35b2e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T16:22:14.287984Z",
     "iopub.status.busy": "2022-06-14T16:22:14.287712Z",
     "iopub.status.idle": "2022-06-14T16:22:14.298250Z",
     "shell.execute_reply": "2022-06-14T16:22:14.297900Z",
     "shell.execute_reply.started": "2022-06-14T16:22:14.287961Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5495, 6507)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Even RAD3 doesn't cover all CENSUSBLOCK\n",
    "rad3CB_rank.GEOID.nunique(), tiger.GEOID.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8143cd1a-f693-4d32-badc-761162ec9359",
   "metadata": {},
   "source": [
    "# Save to mbtiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "4f260a11-fdba-4107-a101-de0d843bdfa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T16:34:49.230961Z",
     "iopub.status.busy": "2022-06-14T16:34:49.230687Z",
     "iopub.status.idle": "2022-06-14T16:34:49.263500Z",
     "shell.execute_reply": "2022-06-14T16:34:49.263075Z",
     "shell.execute_reply.started": "2022-06-14T16:34:49.230939Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rad3CB_rank['pId'] = rad3CB_rank['pId'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "2edaacc4-fae0-4610-8904-5a2fa3ed654e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T16:34:51.140186Z",
     "iopub.status.busy": "2022-06-14T16:34:51.139652Z",
     "iopub.status.idle": "2022-06-14T16:34:51.822589Z",
     "shell.execute_reply": "2022-06-14T16:34:51.822120Z",
     "shell.execute_reply.started": "2022-06-14T16:34:51.140156Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save to ftr\n",
    "rad3CB_rank.to_feather(f'rad3_complete/{date}_{sf_code}.ftr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "228da7af-b6b6-45d5-ba07-3c32d19f9409",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T16:27:19.644445Z",
     "iopub.status.busy": "2022-06-14T16:27:19.644132Z",
     "iopub.status.idle": "2022-06-14T16:27:19.648208Z",
     "shell.execute_reply": "2022-06-14T16:27:19.647854Z",
     "shell.execute_reply.started": "2022-06-14T16:27:19.644422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pId', 'pOwner', 'PHONE', 'pAddress1', 'pCity', 'pZip', 'lng', 'lat',\n",
       "       'pSIC', 'pIndustry', 'landuse', 'CAIsubtype', 'h3_14', 'source', 'rId',\n",
       "       'pAddressSub', 'altIds', 'placekey', 'GEOID', 'wktCB', 'rank'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rad3CB_rank.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "7bbf452a-8bbf-47be-94de-81478f97d2f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T17:02:40.769005Z",
     "iopub.status.busy": "2022-06-14T17:02:40.768692Z",
     "iopub.status.idle": "2022-06-14T17:02:41.995493Z",
     "shell.execute_reply": "2022-06-14T17:02:41.995051Z",
     "shell.execute_reply.started": "2022-06-14T17:02:40.768979Z"
    }
   },
   "outputs": [],
   "source": [
    "rad3CB_rank.drop(columns=['h3_14', 'wktCB', 'placekey']).rename(\n",
    "    columns={'rank': 'speedRankReadyRaw'}).to_csv(\n",
    "    f'rad3_complete/{date}_{sf_code}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "f130f9f2-ba10-43b5-b3f4-c13023fe5c6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T17:04:30.424816Z",
     "iopub.status.busy": "2022-06-14T17:04:30.424541Z",
     "iopub.status.idle": "2022-06-14T17:04:30.427983Z",
     "shell.execute_reply": "2022-06-14T17:04:30.427452Z",
     "shell.execute_reply.started": "2022-06-14T17:04:30.424793Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/tippecanoe -zg -Z6 --extend-zooms-if-still-dropping --drop-densest-as-needed --force -o /home/nhat/update-regrid/data/rad3_dc.mbtiles -l rad3_dc /home/nhat/demand-points/rad3_complete/jun14_DC.csv\n"
     ]
    }
   ],
   "source": [
    "print(f\"/usr/local/bin/tippecanoe -zg -Z6 --extend-zooms-if-still-dropping --drop-densest-as-needed --force -o \\\n",
    "/home/nhat/update-regrid/data/rad3_{sf_code.lower()}.mbtiles -l rad3_{sf_code.lower()} \\\n",
    "/home/nhat/demand-points/rad3_complete/{date}_{sf_code}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5925f9fd-b58f-4706-a934-73c9925f845c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711ef353-7692-4913-bc1f-d0a365ba5e10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7597d0e3-c91f-48be-9450-eb7fda9dbf2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
